<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>c7w 的博客</title>
  
  <subtitle>是一只 c7w 的博客</subtitle>
  <link href="https://www.c7w.tech/atom.xml" rel="self"/>
  
  <link href="https://www.c7w.tech/"/>
  <updated>2022-02-13T17:12:26.296Z</updated>
  <id>https://www.c7w.tech/</id>
  
  <author>
    <name>c7w</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>LaTeX 从入坑到退坑</title>
    <link href="https://www.c7w.tech/latex/"/>
    <id>https://www.c7w.tech/latex/</id>
    <published>2022-02-13T08:43:16.000Z</published>
    <updated>2022-02-13T17:12:26.296Z</updated>
    
    <content type="html"><![CDATA[<p>虽然 Markdown 很好用，但是生成的 pdf 文档看起来就是<s>没有范</s>不够正式。此外，使用 LaTeX 也是我们之后写论文的必备技能。</p><p>本教程主要涉及已对 Markdown 较为熟识之后的迁移学习。</p><a id="more"></a><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><ul><li>Markdown 入门</li><li>Markdown 编写数学公式的方法</li></ul><h2 id="LaTeX-简介"><a href="#LaTeX-简介" class="headerlink" title="LaTeX 简介"></a>LaTeX 简介</h2><p>我们首先解决以下几个问题：</p><ul><li>LaTeX 是什么？</li><li>LaTeX 怎样运作？</li><li>我该在哪里写 LaTex？</li></ul><p>在解决上述几个问题之后，我们再详细介绍该怎么写 LaTeX 的问题。</p><h3 id="LaTeX-是什么？"><a href="#LaTeX-是什么？" class="headerlink" title="LaTeX 是什么？"></a>LaTeX 是什么？</h3><p>相信你读到这里已经做好觉悟要被灌输一系列关键词和其对应概念了。让我们开始：</p><blockquote><p>历史回溯到 Knuth 教授的巨著 The Art of Computer Programming 将要出版之际，当出版商将他们排版的书稿草样交给 Knuth 教授的时候，他对于其中复杂数学公式的排版处理十分不满。其排版之粗糙，已达到了会影响人们理解原书内容的程度。因此，对于复杂的数学和物理公式，我们急需一种能够将其在互联网上传输的编码格式，使得人能阅读的公式和机器能存储的公式之间达到一种互相转化。</p></blockquote><ul><li><strong>TeX</strong>：一种排版引擎，也是该引擎使用的标记语言的名称。引擎是指能够断行、分页的程序，标记语言是控制命令和文本结合的格式。可以类比理解成你写的 C++ 源代码或者更底层的机器指令码，如输入 <script type="math/tex">2^6</script>。</li><li><strong>LaTeX</strong>：是一个基于 TeX 的排版系统，将用户按照它的格式编写的文档解释成 TeX 引擎能理解的形式并交付给 TeX 引擎处理，再将最终结果返回给用户。可以类比理解成 g++ 编译器，将上述代码渲染为 $2^6$。</li><li><strong>pdfTeX</strong> 与 <strong>pdfLaTeX</strong>：原版 TeX 系统生成的文件是 <code>dvi</code> 格式，而 pdfTeX 系统下生成的文件是 <code>pdf</code> 格式。</li><li><strong>XeTeX</strong> 与 <strong>XeLaTeX</strong>：上述 TeX 系统生成的字符集只支持 ASCII 字符。在 XeTeX 出现之前，我们曾使用过引用引入 CJK 宏库（解决不支持中日韩字符问题的一个库）手段来处理中文字符的问题。但是这个排版系统对所有 Unicode 字符都实现了支持。</li><li><strong>LuaTeX</strong> 与 <strong>LuaLaTeX</strong>：<code>pdfTeX</code> 系统的继承者，支持使用一些用户自定义脚本来实现之前需要写成 TeX 的功能。支持 Unicode，内联 lua，支持 OpenType。</li></ul><p>这里我们推荐使用 <code>XeTeX</code> 系统来进行我们日常的工作，我们后续的教程也围绕这个排版系统展开。为了简洁起见，我们后续不再区分上述概念，统一使用 <code>TeX</code>，<code>LaTeX</code> 来表述我们在说的这个话题。</p><h3 id="LaTeX-怎样运作？"><a href="#LaTeX-怎样运作？" class="headerlink" title="LaTeX 怎样运作？"></a>LaTeX 怎样运作？</h3><p>LaTeX 排版系统的输入是含有我们敲的文本和控制命令的 <code>tex</code> 文件，输出是一份 <code>pdf</code> 文件。我们只需要负责在 <code>tex</code> 文件中写下源码，然后剩下的编译和生成工作全部交给 LaTeX 即可。</p><p>有时我们还可以把一个 LaTeX 项目组织成一个文件夹，此时还是一份 <code>tex</code> 文件决定一个 <code>pdf</code> 的生成，但是我们还可以在这个文件夹中引入其他一些文件，如字体文件，图片文件，<code>.cls</code> 文件（文档模板类文件）等等。此外，我们还可以在这个文件夹中编写多个 <code>tex</code> 文件，以共享文件夹中的其他资源。此时不同的 <code>tex</code> 文件之间甚至可以项目包含（类比于 C++ 的 <code>#include</code> 包含）。</p><h3 id="在哪里编写-LaTeX？"><a href="#在哪里编写-LaTeX？" class="headerlink" title="在哪里编写 LaTeX？"></a>在哪里编写 LaTeX？</h3><p>我们有离线和在线两种模式来撰写 LaTeX。</p><p>离线模式就是安装一个 LaTeX 排版系统，类比我们想写 Markdown 的时候装了一个 Typora 软件一样，我们可以安装相应的软件来辅助我们工作，如：</p><ul><li>TeXworks</li><li>TeXstudio</li></ul><p>而使用这种方式安装带来的问题是可能安装包过于臃肿，优点是不用受到网络环境等等因素的干扰，也不用受到网络环境存储容量或运行时环境的限制。其安装方式在网络上搜索“LaTeX 入门”便可找到堆积如山的<a href="https://www.zhihu.com/question/62943097">教程</a>。</p><p>而我们这里推崇的方式就是使用在线方式来编写。如 <code>Overleaf</code> 在内的托管网站会将你的每个 TeX 项目组织成一个仓库的形式，并允许你在其中进行在线编辑：</p><p><img src="https://s2.loli.net/2022/02/14/JcqCKNfs31vxm2u.png" alt="image-20220213203750216"></p><p><img src="https://s2.loli.net/2022/02/13/IKAPDlYTmFEu5S1.png" alt="image-20220213204115880"></p><p>左上角是我们当前仓库的文件清单，较左侧窗口是编辑器，右侧窗口是即时预览窗口。类似于 <code>Overleaf</code> 的网站甚至还提供了仓库权限管理系统，你可以邀请其他人一起编辑，或是导入别人编辑好的模板继续你的编辑等等。值得一提的是许多学术会议都会给出他们接受的论文的模板。</p><p>鉴于 <code>Overleaf</code> 需要科学上网才能访问：</p><ul><li>贵校 TUNA 协会维护了一份 <a href="https://overleaf.tsinghua.edu.cn/login">Tsinghua Overleaf</a>，需要使用清华统一认证登录; </li><li>贵校贵系贵协网络部维护了一份自己的基于 <code>Overleaf</code>  的 LaTeX 在线编辑网站 <a href="https://stu.cs.tsinghua.edu.cn/tex9/">TeX9</a>，<u>需要使用酒井 ID 才能进行登录</u>。</li></ul><p>我们接下来的演示便是基于 TeX9。</p><h2 id="LaTeX-编写基础"><a href="#LaTeX-编写基础" class="headerlink" title="LaTeX 编写基础"></a>LaTeX 编写基础</h2><p>说是编写基础，接下来我们就要像介绍 Markdown 一样，先简单罗列一些简单的文档控制命令。在基础篇中我们先仅仅介绍怎样实现从 Markdown 到 LaTeX 的迁移。对于其中一些文档控制命令，我们将会在后续教程详细说明。</p><p>这里提供 CheatSheet 供查阅：</p><p><img src="https://s2.loli.net/2022/02/14/KP5yeuotcJhTlVO.png" alt="image-20220214004156979"></p><p><img src="https://s2.loli.net/2022/02/14/j3EHglvqhoetRi4.png" alt="image-20220214004207594"></p><h3 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello, World!"></a>Hello, World!</h3><p><img src="https://s2.loli.net/2022/02/13/HPCaZJUtNOj74uF.png" alt="image-20220213205714169"></p><p>上述便是一份 <code>tex</code> 文件的示例，我们推荐你新建一个项目，然后将下面我们要介绍的内容一一尝试。</p><h3 id="支持中文字符"><a href="#支持中文字符" class="headerlink" title="支持中文字符"></a>支持中文字符</h3><p>首先，我们上述已经介绍过，支持中文字符的方式有二，一种是引入 <code>CJK</code> 宏包，另一种是使用 XeLaTeX 编译器并对源码做适当修改。这里我们采用第二种方式。</p><p>首先，按下你项目左上角的 Menu 按钮，然后在 Compiler 选项中选择 XeLaTeX 选项。</p><p>然后，输入以下内容：</p><pre class="language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\documentclass</span><span class="token punctuation">[</span>UTF8<span class="token punctuation">]</span><span class="token punctuation">&#123;</span><span class="token keyword">ctexart</span><span class="token punctuation">&#125;</span><span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">document</span><span class="token punctuation">&#125;</span>你好，world!<span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">document</span><span class="token punctuation">&#125;</span></code></pre><p>这样我们就完成了中文字符的引入。至于 <code>documentclass</code> 是什么，我们将在后续介绍。</p><h3 id="导言与文档信息"><a href="#导言与文档信息" class="headerlink" title="导言与文档信息"></a>导言与文档信息</h3><pre class="language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\documentclass</span><span class="token punctuation">[</span>UTF8<span class="token punctuation">]</span><span class="token punctuation">&#123;</span><span class="token keyword">ctexart</span><span class="token punctuation">&#125;</span><span class="token function selector">\title</span><span class="token punctuation">&#123;</span>Sample Document<span class="token punctuation">&#125;</span><span class="token function selector">\author</span><span class="token punctuation">&#123;</span>c7w<span class="token punctuation">&#125;</span><span class="token function selector">\date</span><span class="token punctuation">&#123;</span><span class="token function selector">\today</span><span class="token punctuation">&#125;</span><span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">document</span><span class="token punctuation">&#125;</span><span class="token comment">% 这条控制命令会读取导言部分的文档相关信息</span><span class="token comment">% 并将其渲染到文档中</span><span class="token comment">% 事实上可以参考相关宏包的 Doc：</span><span class="token comment">% http://texdoc.net/texmf-dist/doc/latex/titling/titling.pdf</span><span class="token function selector">\maketitle</span> 你好，world!<span class="token punctuation">[</span>在这里你就开始写你的作业第一题了<span class="token punctuation">]</span><span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">document</span><span class="token punctuation">&#125;</span></code></pre><p><img src="https://s2.loli.net/2022/02/13/IbNdaCD2wFXVlAq.png" alt="image-20220213210910831"></p><h3 id="章节与段落"><a href="#章节与段落" class="headerlink" title="章节与段落"></a>章节与段落</h3><pre class="language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\documentclass</span><span class="token punctuation">[</span>UTF8<span class="token punctuation">]</span><span class="token punctuation">&#123;</span><span class="token keyword">ctexart</span><span class="token punctuation">&#125;</span><span class="token function selector">\title</span><span class="token punctuation">&#123;</span>Sample Document<span class="token punctuation">&#125;</span><span class="token function selector">\author</span><span class="token punctuation">&#123;</span>c7w<span class="token punctuation">&#125;</span><span class="token function selector">\date</span><span class="token punctuation">&#123;</span><span class="token function selector">\today</span><span class="token punctuation">&#125;</span><span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">document</span><span class="token punctuation">&#125;</span><span class="token function selector">\maketitle</span><span class="token function selector">\section</span><span class="token punctuation">&#123;</span><span class="token headline class-name">我是 Section 标题</span><span class="token punctuation">&#125;</span>我是 Section 介绍。<span class="token function selector">\subsection</span><span class="token punctuation">&#123;</span><span class="token headline class-name">我是 Subsection 标题</span><span class="token punctuation">&#125;</span>我是 Subsection 介绍。<span class="token function selector">\subsubsection</span><span class="token punctuation">&#123;</span><span class="token headline class-name">我是 Subsubsection 标题</span><span class="token punctuation">&#125;</span>我是 Subsubsection 介绍。<span class="token comment">% \subsubsubsection&#123;不能继续套 sub 了，到底了&#125;</span><span class="token function selector">\paragraph</span><span class="token punctuation">&#123;</span><span class="token headline class-name">我是 Paragraph 标题</span><span class="token punctuation">&#125;</span>我是 Paragraph 后面跟着写的东西。本人也是经过了深思熟虑，在每个日日夜夜思考这个问题。我们都知道，只要有意义，那么就必须慎重考虑。这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。要想清楚，一天掉多少根头发，到底是一种怎么样的存在。贝多芬曾经说过，卓越的人一大优点是：在不利与艰难的遭遇里百折不饶。<span class="token function selector">\subparagraph</span><span class="token punctuation">&#123;</span><span class="token headline class-name">我是 Subparagraph 标题</span><span class="token punctuation">&#125;</span>我是 Subparagraph 后面跟着写的东西。这不禁令我深思既然如何，一天掉多少根头发的发生，到底需要如何做到，不一天掉多少根头发的发生，又会如何产生。 总结的来说， 所谓一天掉多少根头发，关键是一天掉多少根头发需要如何写。 生活中，若一天掉多少根头发出现了，我们就不得不考虑它出现了的事实。 郭沫若曾经说过，形成天才的决定因素应该是勤奋。这不禁令我深思这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 我们一般认为，抓住了问题的关键，其他一切则会迎刃而解。<span class="token function selector">\subsection</span><span class="token punctuation">&#123;</span><span class="token headline class-name">这是第二节</span><span class="token punctuation">&#125;</span><span class="token function selector">\paragraph</span><span class="token punctuation">&#123;</span><span class="token headline class-name">第二节</span><span class="token punctuation">&#125;</span> 的首段。<span class="token function selector">\subparagraph</span><span class="token punctuation">&#123;</span><span class="token headline class-name">第二节</span><span class="token punctuation">&#125;</span>的第二段。<span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">document</span><span class="token punctuation">&#125;</span></code></pre><p><img src="https://s2.loli.net/2022/02/13/kIeOlBjF7uzJ5ZH.png" alt="image-20220213211528785"></p><p>在文档类 <code>article</code>/<code>ctexart</code> 中（文档类的概念我们会在进阶篇中提供指导），我们使用这些控制序列来调整行文组织结构。他们分别是：</p><ul><li><code>\section&#123;·&#125;</code></li><li><code>\subsection&#123;·&#125;</code></li><li><code>\subsubsection&#123;·&#125;</code></li><li><code>\paragraph&#123;·&#125;</code></li><li><code>\subparagraph&#123;·&#125;</code></li></ul><h3 id="文档目录"><a href="#文档目录" class="headerlink" title="文档目录"></a>文档目录</h3><p>我们尝试在渲染区 <code>\maketitle</code> 后加入如下控制命令：</p><pre class="language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\tableofcontents</span></code></pre><p>没错，正如你所想的，这就会生成文档的 TOC：</p><p><img src="https://s2.loli.net/2022/02/13/sSI8byUWJjYLkPw.png" alt="image-20220213211830033"></p><h3 id="数学公式"><a href="#数学公式" class="headerlink" title="数学公式"></a>数学公式</h3><h4 id="行内公式与行间公式"><a href="#行内公式与行间公式" class="headerlink" title="行内公式与行间公式"></a>行内公式与行间公式</h4><p>首先引入相应包 <strong>amsmath</strong>，然后我们简单介绍公式的引入：</p><pre class="language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\documentclass</span><span class="token punctuation">[</span>UTF8<span class="token punctuation">]</span><span class="token punctuation">&#123;</span><span class="token keyword">ctexart</span><span class="token punctuation">&#125;</span><span class="token function selector">\usepackage</span><span class="token punctuation">&#123;</span><span class="token keyword">amsmath</span><span class="token punctuation">&#125;</span> <span class="token comment">% 注意这里引入相应包</span><span class="token function selector">\title</span><span class="token punctuation">&#123;</span>Sample Document<span class="token punctuation">&#125;</span><span class="token function selector">\author</span><span class="token punctuation">&#123;</span>c7w<span class="token punctuation">&#125;</span><span class="token function selector">\date</span><span class="token punctuation">&#123;</span><span class="token function selector">\today</span><span class="token punctuation">&#125;</span><span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">document</span><span class="token punctuation">&#125;</span><span class="token function selector">\maketitle</span><span class="token function selector">\tableofcontents</span><span class="token function selector">\section</span><span class="token punctuation">&#123;</span><span class="token headline class-name">我是 Section 标题</span><span class="token punctuation">&#125;</span>我是 Section 介绍。<span class="token function selector">\subsection</span><span class="token punctuation">&#123;</span><span class="token headline class-name">这个 Section 我们介绍数学公式的写法</span><span class="token punctuation">&#125;</span><span class="token function selector">\subsubsection</span><span class="token punctuation">&#123;</span><span class="token headline class-name">行内公式</span><span class="token punctuation">&#125;</span><span class="token comment">% 行内公式基本可以照搬 Markdown 的模式。</span>初始处理 1 - 5 位的初始字符串集合需要处理 <span class="token equation string">$18 + 18^2 + 18^3 + 18^4 + 18^5 = 2*10^6$</span> 的数据，因此需要 <span class="token equation string">$O(T)$</span> 的时间，这里 <span class="token equation string">$T=2*10^6$</span>。<span class="token function selector">\subsubsection</span><span class="token punctuation">&#123;</span><span class="token headline class-name">行间公式</span><span class="token punctuation">&#125;</span><span class="token comment">% 行间公式用 $$ $$ 或者 \[ \] 来框住都可以，但在 LaTeX 中前者会改变行文的默认行间距，因此不推荐采用。</span><span class="token equation string">\[<span class="token equation-command regex">\text</span>&#123;dp&#125;[i] = <span class="token equation-command regex">\text</span>&#123;dp&#125;[next[i]]+1, next[i] > 0.\]</span><span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">document</span><span class="token punctuation">&#125;</span></code></pre><p><img src="https://s2.loli.net/2022/02/13/CI2hzmUEwluDp6s.png" alt="image-20220213213336585"></p><h4 id="上下标、根式与分式"><a href="#上下标、根式与分式" class="headerlink" title="上下标、根式与分式"></a>上下标、根式与分式</h4><ul><li>上下标请使用 <code>^</code> 与 <code>_</code></li><li>根式与分式请使用 <code>\sqrt&#123;·&#125;</code> 与 <code>\frac&#123;·&#125;&#123;·&#125;</code><ul><li>在行间公式和行内公式中，分式的输出效果是有差异的。如果要强制行内模式的分式显示为行间模式的大小，可以使用 <code>\dfrac</code>, 反之可以使用 <code>\tfrac</code></li></ul></li></ul><h4 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h4><p>一些小的运算符，可以在数学模式下直接输入；另一些需要用控制序列生成，如</p><pre class="language-none"><code class="language-none">\[ \pm\; \times \; \div\; \cdot\; \cap\; \cup\;\geq\; \leq\; \neq\; \approx \; \equiv \]</code></pre><p>连加、连乘、极限、积分等大型运算符分别用 <code>\sum</code>, <code>\prod</code>, <code>\lim</code>, <code>\int</code> 生成。他们的上下标在行内公式中被压缩，以适应行高。我们可以用 <code>\limits</code> 和 <code>\nolimits</code> 来强制显式地指定是否压缩这些上下标。例如：</p><pre class="language-none"><code class="language-none">$ \sum_&#123;i&#x3D;1&#125;^n i\quad \prod_&#123;i&#x3D;1&#125;^n $$ \sum\limits _&#123;i&#x3D;1&#125;^n i\quad \prod\limits _&#123;i&#x3D;1&#125;^n $\[ \lim_&#123;x\to0&#125;x^2 \quad \int_a^b x^2 dx \]\[ \lim\nolimits _&#123;x\to0&#125;x^2\quad \int\nolimits_a^b x^2 dx \]</code></pre><p>多重积分可以使用 <code>\iint</code>, <code>\iiint</code>, <code>\iiiint</code>, <code>\idotsint</code> 等命令输入。</p><pre class="language-none"><code class="language-none">\[ \iint\quad \iiint\quad \iiiint\quad \idotsint \]</code></pre><p><img src="https://s2.loli.net/2022/02/13/VeI1zToC3JfAyK9.png" alt="image-20220213214301901"></p><h4 id="定界符"><a href="#定界符" class="headerlink" title="定界符"></a>定界符</h4><p>各种括号用 <code>()</code>, <code>[]</code>, <code>\&#123;\&#125;</code>, <code>\langle\rangle</code> 等命令表示；注意花括号通常用来输入命令和环境的参数，所以在数学公式中它们前面要加 <code>\</code>。</p><p>因为 LaTeX 中 <code>|</code> 和 <code>\|</code> 的应用过于随意，amsmath 宏包推荐用 <code>\lvert\rvert</code> 和 <code>\lVert\rVert</code> 取而代之。</p><p>为了调整这些定界符的大小，amsmath 宏包推荐使用 <code>\big</code>, <code>\Big</code>, <code>\bigg</code>, <code>\Bigg</code> 等一系列命令放在上述括号前面调整大小。</p><h4 id="省略号"><a href="#省略号" class="headerlink" title="省略号"></a>省略号</h4><p>省略号用 <code>\dots</code>, <code>\cdots</code>, <code>\vdots</code>, <code>\ddots</code> 等命令表示。<code>\dots</code> 和 <code>\cdots</code> 的纵向位置不同，前者一般用于有下标的序列。</p><h4 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h4><p><code>amsmath</code> 的 <code>pmatrix</code>, <code>bmatrix</code>, <code>Bmatrix</code>, <code>vmatrix</code>, <code>Vmatrix</code> 等环境可以在矩阵两边加上各种分隔符。</p><pre class="language-none"><code class="language-none">\[ \begin&#123;pmatrix&#125; a&amp;b\\c&amp;d \end&#123;pmatrix&#125; \quad\begin&#123;bmatrix&#125; a&amp;b\\c&amp;d \end&#123;bmatrix&#125; \quad\begin&#123;Bmatrix&#125; a&amp;b\\c&amp;d \end&#123;Bmatrix&#125; \quad\begin&#123;vmatrix&#125; a&amp;b\\c&amp;d \end&#123;vmatrix&#125; \quad\begin&#123;Vmatrix&#125; a&amp;b\\c&amp;d \end&#123;Vmatrix&#125; \]</code></pre><p><img src="https://s2.loli.net/2022/02/14/uix67cYI4UaXvK9.jpg" alt="img"></p><h4 id="多行公式"><a href="#多行公式" class="headerlink" title="多行公式"></a>多行公式</h4><p>可以用 <code>aligned</code> 环境来实现，用 <code>&amp;</code> 实现位置对齐。</p><pre class="language-latex" data-language="latex"><code class="language-latex"><span class="token equation string">\[<span class="token equation-command regex">\begin</span>&#123;aligned&#125;x = a+b+c+ <span class="token equation-command regex">\\</span>+d+e+f+g+d+d+d+d+d+d+d+d+d+d+d+d <span class="token equation-command regex">\\</span>+h+i <span class="token equation-command regex">\\</span>+1 <span class="token equation-command regex">\\</span><span class="token equation-command regex">\end</span>&#123;aligned&#125;\]</span><span class="token equation string">\[<span class="token equation-command regex">\begin</span>&#123;aligned&#125;x &amp;= a+b+c+ <span class="token equation-command regex">\\</span>&amp; +d+e+f+g+d+d+d+d+d+d+d+d+d+d+d+d <span class="token equation-command regex">\\</span>&amp; +h+i <span class="token equation-command regex">\\</span>&amp; +1 <span class="token equation-command regex">\\</span><span class="token equation-command regex">\end</span>&#123;aligned&#125;\]</span></code></pre><p>效果：</p><p><img src="https://s2.loli.net/2022/02/14/oZugGY2MF78Lk9t.png" alt="image-20220214001008550"></p><p>若想要公式自带编号，可以用 <code>gather</code> 和 <code>align</code> 环境，其中 <code>gather</code> 环境将公式分行渲染，<code>align</code> 同上述 <code>aligned</code>，可以控制对齐：</p><pre class="language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">gather</span><span class="token punctuation">&#125;</span><span class="token equation string">a = b+c+d <span class="token equation-command regex">\\</span>x = y+z <span class="token equation-command regex">\\</span> p = a_1 + a_2 + a_3 + <span class="token equation-command regex">\dots</span> + a_&#123;200&#125;</span><span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">gather</span><span class="token punctuation">&#125;</span><span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">align</span><span class="token punctuation">&#125;</span><span class="token equation string">a &amp;= b+c+d <span class="token equation-command regex">\\</span>x &amp;= y+z <span class="token equation-command regex">\\</span>p &amp;= a_1 + a_2 + a_3 + <span class="token equation-command regex">\dots</span> + a_&#123;200&#125;</span><span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">align</span><span class="token punctuation">&#125;</span></code></pre><p><img src="https://s2.loli.net/2022/02/14/5tZcTngyKSIsWxV.png" alt="image-20220214001355079"></p><p>若想使用分段函数，可以使用 <code>cases</code> 环境：</p><pre class="language-latex" data-language="latex"><code class="language-latex"><span class="token equation string">\[y= <span class="token equation-command regex">\begin</span>&#123;cases&#125;-x,<span class="token equation-command regex">\quad</span> x<span class="token equation-command regex">\leq</span> 0 <span class="token equation-command regex">\\</span>x,<span class="token equation-command regex">\quad</span> x>0<span class="token equation-command regex">\end</span>&#123;cases&#125; \]</span></code></pre><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>数学公式是在引入了 <strong>amsmath</strong> 包之后，利用其提供的各种各样次环境来实现了较为复杂的公式的编辑。整体来说，与 Mathjax 的风格相差不大，因此迁移学习起来也十分方便。</p><p>这里我们再提供辅助工具：</p><ul><li><a href="https://mathpix.com/">https://mathpix.com/</a> 能够 OCR 手写体或是印刷体公式，而后将图片中的公式转换成 LaTeX 数学公式的代码。</li></ul><h3 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h3><p><code>tabular</code> 环境提供了最简单的表格功能。它用 <code>\hline</code> 命令表示横线，在列格式中用 <code>|</code> 表示竖线；用 <code>&amp;</code> 来分列，用 <code>\\</code> 来换行；每列可以采用居左、居中、居右等横向对齐方式，分别用 <code>l</code>、<code>c</code>、<code>r</code> 来表示。</p><pre class="language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">tabular</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#123;</span>|l|c|r|<span class="token punctuation">&#125;</span> <span class="token function selector">\hline</span>操作系统<span class="token punctuation">&amp;</span> 发行版<span class="token punctuation">&amp;</span> 编辑器<span class="token function selector">\\</span> <span class="token function selector">\hline</span>Windows <span class="token punctuation">&amp;</span> MikTeX <span class="token punctuation">&amp;</span> TexMakerX <span class="token function selector">\\</span> <span class="token function selector">\hline</span>Unix/Linux <span class="token punctuation">&amp;</span> teTeX <span class="token punctuation">&amp;</span> Kile <span class="token function selector">\\</span> <span class="token function selector">\hline</span>Mac OS <span class="token punctuation">&amp;</span> MacTeX <span class="token punctuation">&amp;</span> TeXShop <span class="token function selector">\\</span> <span class="token function selector">\hline</span>通用<span class="token punctuation">&amp;</span> TeX Live <span class="token punctuation">&amp;</span> TeXworks <span class="token function selector">\\</span> <span class="token function selector">\hline</span><span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">tabular</span><span class="token punctuation">&#125;</span></code></pre><p><img src="https://s2.loli.net/2022/02/14/ytG5hReFbjWClwg.jpg" alt="img"></p><h3 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h3><p>在 LaTeX 中插入图片，有很多种方式。最好用的应当属利用 <code>graphicx</code> 宏包提供的 <code>\includegraphics</code> 命令。比如你在你的 TeX 源文件同目录下，有名为 <code>a.jpg</code> 的图片，你可以用这样的方式将它插入到输出文档中：</p><pre class="language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\documentclass</span><span class="token punctuation">&#123;</span><span class="token keyword">article</span><span class="token punctuation">&#125;</span><span class="token function selector">\usepackage</span><span class="token punctuation">&#123;</span><span class="token keyword">graphicx</span><span class="token punctuation">&#125;</span><span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">document</span><span class="token punctuation">&#125;</span><span class="token function selector">\includegraphics</span><span class="token punctuation">&#123;</span>a.jpg<span class="token punctuation">&#125;</span><span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">document</span><span class="token punctuation">&#125;</span></code></pre><p>想要了解更多，参见 <code>graphicx</code> 的文档：<a href="http://texdoc.net/texmf-dist/doc/latex/graphics/graphicx.pdf。">http://texdoc.net/texmf-dist/doc/latex/graphics/graphicx.pdf。</a></p><blockquote><p><strong>浮动体环境</strong></p><p>什么是浮动体环境：<code>table</code> 与 <code>figure</code>，两种浮动体环境可以替代上述的表格和图片环境，实现为表格或图片自动安排位置。</p><p>想了解更多有关浮动体环境的内容，详见<a href="https://liam.page/series/#LaTeX-%E4%B8%AD%E7%9A%84%E6%B5%AE%E5%8A%A8%E4%BD%93">这里</a>。</p></blockquote><h3 id="页面设置"><a href="#页面设置" class="headerlink" title="页面设置"></a>页面设置</h3><h4 id="页边距"><a href="#页边距" class="headerlink" title="页边距"></a>页边距</h4><p>设置页边距，推荐使用 <code>geometry</code> 宏包。可以在<a href="http://texdoc.net/texmf-dist/doc/latex/geometry/geometry.pdf">这里</a>查看它的说明文档。</p><p>比如我希望，将纸张的长度设置为 20cm、宽度设置为 15cm、左边距 1cm、右边距 2cm、上边距 3cm、下边距 4cm，可以在导言区加上这样几行：</p><pre class="language-none"><code class="language-none">\usepackage&#123;geometry&#125;\geometry&#123;papersize&#x3D;&#123;20cm,15cm&#125;&#125;\geometry&#123;left&#x3D;1cm,right&#x3D;2cm,top&#x3D;3cm,bottom&#x3D;4cm&#125;</code></pre><h4 id="页眉页脚"><a href="#页眉页脚" class="headerlink" title="页眉页脚"></a>页眉页脚</h4><p>设置页眉页脚，推荐使用 <code>fancyhdr</code> 宏包。可以在<a href="http://texdoc.net/texmf-dist/doc/latex/fancyhdr/fancyhdr.pdf">这里</a>查看它的说明文档。</p><p>比如我希望，设置自定义页眉；页脚的正中写上页码；页眉和正文之间有一道宽为 0.4pt 的横线分割，可以在导言区加上如下几行：</p><pre class="language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\usepackage</span><span class="token punctuation">&#123;</span><span class="token keyword">fancyhdr</span><span class="token punctuation">&#125;</span><span class="token function selector">\pagestyle</span><span class="token punctuation">&#123;</span>fancy<span class="token punctuation">&#125;</span><span class="token function selector">\lhead</span><span class="token punctuation">&#123;</span>页眉左侧<span class="token punctuation">&#125;</span><span class="token function selector">\chead</span><span class="token punctuation">&#123;</span>页眉中间<span class="token punctuation">&#125;</span><span class="token function selector">\rhead</span><span class="token punctuation">&#123;</span>页眉右侧<span class="token punctuation">&#125;</span><span class="token function selector">\lfoot</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token function selector">\cfoot</span><span class="token punctuation">&#123;</span><span class="token function selector">\thepage</span><span class="token punctuation">&#125;</span><span class="token function selector">\rfoot</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token function selector">\renewcommand</span><span class="token punctuation">&#123;</span><span class="token function selector">\headrulewidth</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#123;</span>0.4pt<span class="token punctuation">&#125;</span><span class="token function selector">\renewcommand</span><span class="token punctuation">&#123;</span><span class="token function selector">\headwidth</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#123;</span><span class="token function selector">\textwidth</span><span class="token punctuation">&#125;</span><span class="token function selector">\renewcommand</span><span class="token punctuation">&#123;</span><span class="token function selector">\footrulewidth</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#123;</span>0pt<span class="token punctuation">&#125;</span></code></pre><h4 id="段间距"><a href="#段间距" class="headerlink" title="段间距"></a>段间距</h4><p>我们可以通过修改长度 <code>\parskip</code> 的值来调整段间距。例如在导言区添加以下内容</p><pre class="language-none"><code class="language-none">\addtolength&#123;\parskip&#125;&#123;.4em&#125;</code></pre><p>则可以在原有的基础上，增加段间距 0.4em。如果需要减小段间距，只需将该数值改为负值即可。</p><h3 id="引用与尾注脚注"><a href="#引用与尾注脚注" class="headerlink" title="引用与尾注脚注"></a>引用与尾注脚注</h3><h4 id="交叉引用"><a href="#交叉引用" class="headerlink" title="交叉引用"></a>交叉引用</h4><p>交叉引用设置方法：</p><ul><li>给对象命名：<code>\label&#123;name&#125;</code></li><li>引用对象：<code>\ref&#123;name&#125;</code></li></ul><p>注意，在引用对象时，<code>\ref&#123;name&#125;</code> 会被替换会被引用对象的编号。举个例子，如果被引用对象在文档中是第 5 个被命名的，那么这里就会被替换为 5.</p><p>要想避免图/表/论文等等引用在计数上互相影响，你可以在命名时命名为 <code>tag:name</code> 的格式，引用时使用 <code>tag:name</code> 的格式来引用。具体来说，这些 tag 有：</p><div class="table-container"><table><thead><tr><th>Tag</th><th>Description</th></tr></thead><tbody><tr><td><strong><code>ch:</code></strong></td><td>chapter</td></tr><tr><td><strong><code>sec:</code></strong></td><td>section</td></tr><tr><td><strong><code>subsec:</code></strong></td><td>subsection</td></tr><tr><td><strong><code>fig:</code></strong></td><td>figure</td></tr><tr><td><strong><code>tab:</code></strong></td><td>table</td></tr><tr><td><strong><code>eq:</code></strong></td><td>equation</td></tr><tr><td><strong><code>lst:</code></strong></td><td>code listing</td></tr><tr><td><strong><code>itm:</code></strong></td><td>enumerated list item</td></tr><tr><td><strong><code>alg:</code></strong></td><td>algorithm</td></tr><tr><td><strong><code>app:</code></strong></td><td>appendix subsection</td></tr></tbody></table></div><h4 id="尾注脚注"><a href="#尾注脚注" class="headerlink" title="尾注脚注"></a>尾注脚注</h4><p>尾注直接在最后写就行，记得设置引用。</p><p>脚注可以使用 <code>\footnote&#123;角注内容&#125;</code> 来声明。</p><blockquote><p>想了解该如何更好地引入参考文献，请学习 BibTeX 宏包。</p><ul><li><a href="https://zh.wikipedia.org/wiki/BibTeX">https://zh.wikipedia.org/wiki/BibTeX</a></li></ul></blockquote><h3 id="列表与枚举"><a href="#列表与枚举" class="headerlink" title="列表与枚举"></a>列表与枚举</h3><pre class="language-latex" data-language="latex"><code class="language-latex"><span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">enumerate</span><span class="token punctuation">&#125;</span>    <span class="token function selector">\item</span> <span class="token function selector">\LaTeX</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span> 好 处 都 有 啥        <span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">description</span><span class="token punctuation">&#125;</span>            <span class="token function selector">\item</span><span class="token punctuation">[</span>好 用<span class="token punctuation">]</span> 体 验 好 才 是 真 的 好            <span class="token function selector">\item</span><span class="token punctuation">[</span>好 看<span class="token punctuation">]</span> 强 迫 症 的 福 音            <span class="token function selector">\item</span><span class="token punctuation">[</span>开 源<span class="token punctuation">]</span> 众 人 拾 柴 火 焰 高        <span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">description</span><span class="token punctuation">&#125;</span>    <span class="token function selector">\item</span> 还 有 呢?        <span class="token function selector">\begin</span><span class="token punctuation">&#123;</span><span class="token keyword">itemize</span><span class="token punctuation">&#125;</span>            <span class="token function selector">\item</span> 好 处 1            <span class="token function selector">\item</span> 好 处 2    <span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">itemize</span><span class="token punctuation">&#125;</span><span class="token function selector">\end</span><span class="token punctuation">&#123;</span><span class="token keyword">enumerate</span><span class="token punctuation">&#125;</span></code></pre><p><img src="https://s2.loli.net/2022/02/14/U3E8uCBy4RKxfSL.png" alt="image-20220214004408507"></p><h2 id="LaTeX-后续学习"><a href="#LaTeX-后续学习" class="headerlink" title="LaTeX 后续学习"></a>LaTeX 后续学习</h2><h3 id="更多宏包"><a href="#更多宏包" class="headerlink" title="更多宏包"></a>更多宏包</h3><p>宏包一般都会提供相应的文档供我们阅读使用。</p><p>这里提供查询宏包对应文档的网站：</p><ul><li><a href="https://texdoc.org/index.html">https://texdoc.org/index.html</a></li></ul><p><img src="https://s2.loli.net/2022/02/14/jkVbA8vBeY9FsUR.png" alt="image-20220214003834121"></p><h3 id="制作自己的模板"><a href="#制作自己的模板" class="headerlink" title="制作自己的模板"></a>制作自己的模板</h3><p>详见参考资料中 <code>.cls</code> 文件详解部分。我们同时推荐读者可以去多读一读其他已存在的 Template 的 <code>.cls</code> 内容。</p><h3 id="制作幻灯片"><a href="#制作幻灯片" class="headerlink" title="制作幻灯片"></a>制作幻灯片</h3><p>使用 Beamer 宏包可以制作幻灯片。详见：</p><ul><li><a href="https://www.overleaf.com/learn/latex/Beamer">https://www.overleaf.com/learn/latex/Beamer</a></li></ul><p>同时，校内也提供了一些适用于各种 pre 的 Beamer 模板。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li>（推荐）一份其实很短的 LaTeX 入门文档：<a href="https://liam.page/2014/09/08/latex-introduction/">https://liam.page/2014/09/08/latex-introduction/</a></li><li>（推荐）如何使用 LaTeX 排版论文：<a href="https://github.com/tuna/thulib-latex-talk">https://github.com/tuna/thulib-latex-talk</a></li><li>（<code>.cls</code> 文件详解）How to write a LaTeX class file and design your own CV： <a href="https://www.overleaf.com/learn/latex/How_to_write_a_LaTeX_class_file_and_design_your_own_CV_(Part_1">https://www.overleaf.com/learn/latex/How_to_write_a_LaTeX_class_file_and_design_your_own_CV_(Part_1</a>)</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;虽然 Markdown 很好用，但是生成的 pdf 文档看起来就是&lt;s&gt;没有范&lt;/s&gt;不够正式。此外，使用 LaTeX 也是我们之后写论文的必备技能。&lt;/p&gt;
&lt;p&gt;本教程主要涉及已对 Markdown 较为熟识之后的迁移学习。&lt;/p&gt;</summary>
    
    
    
    <category term="技术" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="技术/综合" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF-%E7%BB%BC%E5%90%88/"/>
    
    
    <category term="Latex" scheme="https://www.c7w.tech/tags/Latex/"/>
    
  </entry>
  
  <entry>
    <title>Django + ElasticSearch 实现搜索网站纪实</title>
    <link href="https://www.c7w.tech/elasticsearch/"/>
    <id>https://www.c7w.tech/elasticsearch/</id>
    <published>2022-02-11T15:04:10.000Z</published>
    <updated>2022-02-11T15:09:08.533Z</updated>
    
    <content type="html"><![CDATA[<p>事实上是挑战杯要搭一个文书搜索网站…暂时需要用 BM25 算法顶一下。</p><p>搜索的对象是…数目约在 $10^8$ 规模左右的文档…</p><p>嘛嘛，反正都是大调库。缝合就完事了。</p><a id="more"></a><h2 id="索引算法"><a href="#索引算法" class="headerlink" title="索引算法"></a>索引算法</h2><p>我们首先介绍下 Sparse Retrieval 的主要算法，TF-IDF 算法和 BM25 算法。</p><h3 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h3><p>TF 是指归一化的词频，IDF 是指逆文档频率。给定文档集合 $D$，有 $d_i \in D, 1 \le i \le n$. </p><p>文档集合总共包含 $m$​ 个词，去除一些十分常见的词作为停用词（Stop Words），有 $w_i \in W, 1 \le i \le m$​.</p><p>定义 TF 如下，即一篇文档中某个词出现的频率：</p><script type="math/tex; mode=display">\text{TF}(q_i, d_j) = \dfrac {f_{i, d_j}}{ |d_j| }</script><p>TF 只能描述词在文档中的频率，但假设现在有个词为“我们”，这个词可能在文档集 $D$ 中每篇文档中都会出现，并且有较高的频率。那么这一类词就不具有很好的区分文档的能力，为了降低这种通用词的作用，引入了 IDF：</p><script type="math/tex; mode=display">\text{IDF}(q_i) = \ln \dfrac {|D|}{|\{d_i  : q_i \in d_i \}|}</script><p>于是我们综合这两部分， 便可以得到 TF-IDF：</p><script type="math/tex; mode=display">\text{TF-IDF} = \text{TF} * \text{IDF}</script><p>TF 可以计算在一篇文档中词出现的频率，而 IDF 可以降低一些通用词的作用。因此对于一篇文档我们可以用文档中每个词的 TF−IDF 组成的向量来表示该文档，再根据余弦相似度这类的方法来计算文档之间的相关性。</p><h3 id="BM25"><a href="#BM25" class="headerlink" title="BM25"></a>BM25</h3><p>BM25 是信息索引领域用来计算 query 与文档相似度得分的经典算法。</p><p>不同于 TF-IDF，BM25 的公式主要由三个部分组成：</p><ol><li>query 中每个单词 $q_i$ 与文档 $d$ 之间的相关性</li><li>单词 $q_i$ 与 query 之间的相似性</li><li>每个单词的权重</li></ol><p>BM25 算法的一般公式：</p><script type="math/tex; mode=display">score(Q,d) = \sum_i^n W_i R(q_i, d)</script><p>其中 $Q$ 表示 query，$q_i \in Q$，$d$​ 表示 document.</p><p>下展开介绍各部分公式：</p><ul><li><strong>$W_i$</strong></li></ul><script type="math/tex; mode=display">W_i = IDF(q_i) = \ln \dfrac {N-df_i+0.5}{df_i+0.5}</script><p>其中 $N$​​ 是 document 总数，$df_i$​ 表示含有 $q_i$​ 的文档总数。</p><p>依据 IDF 的作用，对于某个 $q_i$​ ，包含 $q_i$ 的文档数越多，说明 $q_i$ 重要性越小，或者区分度越低，IDF 越小，因此 IDF 可以用来刻画 $q_i$ 与文档的相似性。</p><ul><li><strong>$R(q_i, d)$​</strong></li></ul><p>BM25 的设计依据一个重要的发现：<strong>词频和相关性之间的关系是非线性的</strong>，也就是说，每个词对于文档的相关性分数不会超过一个特定的阈值，当词出现的次数达到一个阈值后，其影响就不在线性增加了，而这个阈值会跟文档本身有关。</p><script type="math/tex; mode=display">R(q_i, d) = \dfrac {f_i \cdot (k_1+1)}{f_i+K} \cdot \dfrac {qf_i \cdot(k_2+1)}{qf_i+k_2}</script><p>我们可以分成两部分来看待上述公式，其中 $f_i$​ 为 $q_i$​ 在 $d$​ 中出现的次数，$k_1, k_2, K$​ 是常数。</p><p>后一部分 $\dfrac {qf_i \cdot(k_2+1)}{qf_i+k_2}$ 在控制 $q_i$​ 和 Query 的相似度。</p><p>前一部分在计算 $q_i$ 与 $d$​ 的相似度，其中 $K = k_1 \cdot (1-b+b\cdot \dfrac {|d|}{AVG_n(|d|)})$，参数 $b$ 在调节文本长度对相关性的影响。</p><p>不失一般性地我们可以取 $k_1 = 2, k_2 = 0, b = 0.75$​.</p><p>反正在接下来的运用也是大调库，参数不调问题不大（x</p><h2 id="网站搭建纪实"><a href="#网站搭建纪实" class="headerlink" title="网站搭建纪实"></a>网站搭建纪实</h2><h3 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h3><blockquote><p><strong>Elasticsearch</strong> is the distributed <strong>search and analytics engine</strong> at the heart of the Elastic Stack. <em>Logstash</em> and <em>Beats</em> facilitate collecting, aggregating, and enriching your data and storing it in Elasticsearch. <em>Kibana</em> enables you to interactively explore, visualize, and share insights into your data and manage and monitor the stack. <strong>Elasticsearch is where the indexing, search, and analysis magic happens.</strong></p><p>Elasticsearch 是一个开源的搜索引擎，建立在一个全文搜索引擎库 Apache Lucene™ 基础之上。</p><p>那 Lucene 又是什么？Lucene 可能是目前存在的，不论开源还是私有的，拥有最先进，高性能和全功能搜索引擎功能的库，但也仅仅只是一个库。</p><p>要用上 Lucene，我们需要编写 Java 并引用 Lucene 包才可以，而且我们需要对信息检索有一定程度的理解才能明白 Lucene 是怎么工作的，反正用起来没那么简单。</p><p>那么为了解决这个问题，Elasticsearch 就诞生了。Elasticsearch 也是使用 Java 编写的，它的内部使用 Lucene 做索引与搜索，但是它的目标是使全文检索变得简单，相当于 Lucene 的一层封装，它提供了一套简单一致的 RESTful API 来帮助我们实现存储和检索。</p><p>所以 Elasticsearch 仅仅就是一个简易版的 Lucene 封装吗？那就大错特错了，Elasticsearch 不仅仅是 Lucene，并且也不仅仅只是一个全文搜索引擎。它可以被下面这样准确的形容：</p><ul><li>一个分布式的实时文档存储，每个字段可以被索引与搜索</li><li>一个分布式实时分析搜索引擎</li><li>能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据</li></ul><p>总之，是一个相当牛逼的搜索引擎，维基百科、Stack Overflow、GitHub 都纷纷采用它来做搜索。</p></blockquote><p>总之我们先来到了下载网站看看：<a href="https://www.elastic.co/cn/downloads/elasticsearch。为了">https://www.elastic.co/cn/downloads/elasticsearch。为了</a><s>避免麻烦</s>防止污染服务器环境遂决定用 Docker 安装：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html</a></p><p>首先自然是 <code>docker pull</code>：</p><pre class="language-bash" data-language="bash"><code class="language-bash">docker pull docker.elastic.co/elasticsearch/elasticsearch:8.0.0</code></pre><p> // TODO: 写到这里去补 Docker 挂载了</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://www.cnblogs.com/jiangxinyang/p/10516302.html">https://www.cnblogs.com/jiangxinyang/p/10516302.html</a></li><li><a href="https://zhuanlan.zhihu.com/p/79202151">https://zhuanlan.zhihu.com/p/79202151</a></li><li><a href="https://www.elastic.co/cn/downloads/elasticsearch">https://www.elastic.co/cn/downloads/elasticsearch</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html</a></li><li><a href="https://cuiqingcai.com/6214.html">https://cuiqingcai.com/6214.html</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;事实上是挑战杯要搭一个文书搜索网站…暂时需要用 BM25 算法顶一下。&lt;/p&gt;
&lt;p&gt;搜索的对象是…数目约在 $10^8$ 规模左右的文档…&lt;/p&gt;
&lt;p&gt;嘛嘛，反正都是大调库。缝合就完事了。&lt;/p&gt;</summary>
    
    
    
    <category term="技术" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="技术/后端" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF-%E5%90%8E%E7%AB%AF/"/>
    
    
    <category term="ElasticSearch" scheme="https://www.c7w.tech/tags/ElasticSearch/"/>
    
  </entry>
  
  <entry>
    <title>Docker 使用指北</title>
    <link href="https://www.c7w.tech/docker/"/>
    <id>https://www.c7w.tech/docker/</id>
    <published>2022-02-11T14:00:29.000Z</published>
    <updated>2022-02-11T15:03:07.659Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2022/02/11/MbaA67dgptL9YBc.png" alt="img"></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>软件开发最大的麻烦事之一，就是环境配置。用户计算机的环境不同，可能导致软件在开发环境中能运行，而到了生产环境无法运行的情况。</p><p>用户必须保证两件事：操作系统的设置，各种库和组件的安装。只有它们都正确，软件才能运行。举例来说，安装一个 Python 应用，计算机必须有 Python 引擎，还必须有各种依赖，可能还要配置环境变量。</p><p>环境配置如此麻烦，换一台机器，就要重来一次，旷日费时。很多人想到，能不能从根本上解决问题，软件可以带环境安装？也就是说，<strong>安装的时候，把原始环境一模一样地复制过来</strong>。</p><p>这个问题的一种解决方式是使用<strong>虚拟机</strong>，比如我们常用的 WSL，就是在 Windows 系统中运行 Linux 虚拟系统的例子。但是，这样做的资源占用多，要重新配置一个全新操作系统的冗余步骤多，启动起来也十分缓慢。于是，Linux 发展出了另一种虚拟化技术：<strong>虚拟容器</strong>。</p><p><strong>Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。</strong>或者说，在正常进程的外面套了一个保护层。对于容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离。</p><p><strong>Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。</strong>它是目前最流行的 Linux 容器解决方案。</p><p>Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。</p><p>总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。</p><a id="more"></a><h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><ul><li>Windows <a href="https://docs.docker.com/desktop/windows/install/">https://docs.docker.com/desktop/windows/install/</a></li><li>Linux <a href="https://docs.docker.com/engine/install/ubuntu/">https://docs.docker.com/engine/install/ubuntu/</a></li></ul><h2 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h2><ol><li>镜像（Image）：类似于虚拟机中的镜像，是一个包含有文件系统的面向 Docker 引擎的只读模板。任何应用程序运行都需要环境，而镜像就是用来提供这种运行环境的。例如一个 Ubuntu 镜像就是一个包含 Ubuntu 操作系统环境的模板，同理在该镜像上装上 Apache 软件，就可以称为 Apache 镜像。</li><li>容器（Container）：类似于一个轻量级的沙盒，可以将其看作一个极简的 Linux 系统环境（包括 root 权限、进程空间、用户空间和网络空间等），以及运行在其中的应用程序。Docker 引擎利用容器来运行、隔离各个应用。容器是镜像创建的应用实例，可以创建、启动、停止、删除容器，各个容器之间是是相互隔离的，互不影响。注意：<strong>镜像本身是只读的，容器从镜像启动时，Docker 在镜像的上层创建一个可写层，镜像本身不变。</strong></li><li>仓库（Repository）：类似于代码仓库，这里是镜像仓库，是 Docker 用来集中存放镜像文件的地方。注意与注册服务器（Registry）的区别：注册服务器是存放仓库的地方，一般会有多个仓库；而仓库是存放镜像的地方，一般每个仓库存放一类镜像，每个镜像利用 tag 进行区分，比如 Ubuntu 仓库存放有多个版本（12.04、14.04 等）的 Ubuntu 镜像。</li></ol><h2 id="Images"><a href="#Images" class="headerlink" title="Images"></a>Images</h2><p>对镜像的基本操作总结：</p><ul><li>官方注册服务器（Registry）：<a href="https://hub.docker.com/">https://hub.docker.com/</a></li><li>搜索某个镜像：<code>docker search &lt;image&gt;</code></li><li>将某个镜像下载到本地：<ul><li><code>docker pull &lt;image&gt;</code>// 如果不加 tag 默认使用 latest 镜像</li><li><code>docker pull &lt;image&gt;:&lt;tag&gt;</code></li></ul></li><li>查看当前下载的镜像信息：<code>docker images</code></li><li>新建自定义镜像的方法</li></ul><p><strong>方法 1：利用镜像启动一个容器后修改，再进行 commit</strong></p><pre class="language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@xxx ~<span class="token punctuation">]</span><span class="token comment"># docker run -it centos:latest /bin/bash    # 启动一个容器</span><span class="token punctuation">[</span>root@72f1a8a0e394 /<span class="token punctuation">]</span><span class="token comment">#    # 这里命令行形式变了，表示已经进入了一个新环境</span><span class="token punctuation">[</span>root@72f1a8a0e394 /<span class="token punctuation">]</span><span class="token comment"># git --version    # 此时的容器中没有 git</span>bash: git: <span class="token builtin class-name">command</span> not found<span class="token punctuation">[</span>root@72f1a8a0e394 /<span class="token punctuation">]</span><span class="token comment"># yum install git    # 利用 yum 安装 git</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">[</span>root@72f1a8a0e394 /<span class="token punctuation">]</span><span class="token comment"># git --version   # 此时的容器中已经装有 git 了</span><span class="token function">git</span> version <span class="token number">1.8</span>.3.1</code></pre><p>然后按下 Ctrl+D 或者输入 exit 退出容器，然后查看当前所有容器：<code>docker ps -a</code>。这里将容器转化为一个镜像，即执行 commit 操作，完成后可使用 docker images 查看：</p><pre class="language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@xxx ~<span class="token punctuation">]</span><span class="token comment"># docker ps -a</span>CONTAINER ID  IMAGE    COMMAND      CREATED   STATUS   PORTS    NAMES72f1a8a0e394  centos:latest <span class="token string">"/bin/bash"</span>  <span class="token number">9</span> minutes ago   Exited <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token number">3</span> minutes ago      angry_hodgkin<span class="token punctuation">[</span>root@xxx ~<span class="token punctuation">]</span><span class="token comment"># docker commit -m "Commit Message" -a "UserInfo" &lt;Container ID> &lt;user>/&lt;repo>:&lt;tag></span><span class="token punctuation">[</span>root@xxx ~<span class="token punctuation">]</span><span class="token comment"># docker images</span>REPOSITORY       TAG    IMAGE ID         CREATED             SIZE<span class="token operator">&lt;</span>user<span class="token operator">></span>/<span class="token operator">&lt;</span>repo<span class="token operator">></span>    <span class="token function">git</span>    52166e4475ed     <span class="token number">5</span> seconds ago       <span class="token number">358.1</span> MBcentos           latest 0584b3d2cf6d     <span class="token number">9</span> days ago          <span class="token number">196.5</span> MB</code></pre><p>此时 Docker 引擎中就有了我们新建的镜像 <code>&lt;user&gt;/&lt;repo&gt;:&lt;tag&gt;</code>，此镜像和原有的 CentOS 镜像区别在于多了个 Git 工具。此时我们利用新镜像创建的容器，本身就自带 Git 了。</p><p><strong>方法 2：使用 <code>Dockerfile</code></strong></p><p>Dockerfile 可以理解为一种配置文件，用来告诉 <code>docker build</code> 命令应该执行哪些操作。一个简易的 <code>Dockerfile</code> 文件如下所示：</p><pre class="language-dockerfile" data-language="dockerfile"><code class="language-dockerfile"># 说明该镜像以哪个镜像为基础FROM centos:latest# 构建者的基本信息MAINTAINER &lt;user&gt;# 在 build 这个镜像时执行的操作 RUN yum updateRUN yum install -y git# 拷贝本地文件到镜像中COPY .&#x2F;* &#x2F;usr&#x2F;share&#x2F;gitdir&#x2F;# Expose 对应端口，允许外部连接EXPOSE 3000</code></pre><p>官方教程链接：<a href="https://docs.docker.com/engine/reference/builder/">https://docs.docker.com/engine/reference/builder/</a></p><p>有了 <code>Dockerfile</code> 之后，就可以利用 <code>build</code> 命令<strong>构建镜像</strong>了：</p><pre class="language-text" data-language="text"><code class="language-text">[root@xxx ~]# docker build -t="&lt;user>/&lt;repo>:&lt;tag>" .</code></pre><p>其中 -t 用来指定新镜像的用户信息、tag 等。最后的点表示在当前目录寻找 <code>Dockerfile</code>。</p><ul><li><p>删除容器或镜像</p><ul><li>删除容器：<code>docker rm container_name/container_id</code></li><li>删除镜像：<code>docker rmi image_name/image_id</code></li><li>删除镜像前必须先删除以此镜像为基础的容器。</li></ul></li><li><p>镜像的保存与加载</p><ul><li>保存镜像：<code>docker save -o centos.tar &lt;user&gt;/&lt;repo&gt;:&lt;tag&gt;</code></li><li>加载镜像：<code>docker load -i centos.tar</code></li></ul></li></ul><h2 id="Containers"><a href="#Containers" class="headerlink" title="Containers"></a>Containers</h2><ul><li>启动容器：<code>docker run [Options] &lt;Image&gt; [Command]</code><ul><li><code>-d</code>：Run container in background and print container ID</li><li><code>-e</code>：Set environment variables</li><li><code>-i</code>：Keep STDIN open even if not attached</li><li><code>-p &lt;host&gt;:&lt;container&gt;</code>：Publish a container’s port to the host</li><li><code>-t</code>：Allocate a pseudo-TTY</li><li><code>--name</code>：Assign a name to the container</li><li><code>-v &lt;host&gt;:&lt;container&gt;</code>：Mount host_path to container_path </li><li>常用命令：<code>docker run -itd centos:latest /bin/bash</code></li><li>如果想让容器一直运行，而不是停止，可以使用快捷键 Ctrl+P Ctrl+Q 退出，此时容器的状态为 Up。</li></ul></li><li>启动容器：<code>docker start &lt;container&gt;</code></li><li>停止容器：<code>docker stop container&gt;</code></li><li>重启容器：<code>docker restart &lt;container&gt;</code></li><li>进入已启动的容器：<code>docker attach &lt;container&gt;</code></li><li>复制文件：<code>docker cp &lt;container&gt;:&lt;path&gt; &lt;host_path&gt;</code></li></ul><h2 id="Repositories"><a href="#Repositories" class="headerlink" title="Repositories"></a>Repositories</h2><ul><li>官方镜像服务器：<a href="https://hub.docker.com">https://hub.docker.com</a></li><li>登录 DockerHub：<code>docker login</code></li><li>推送本地镜像：<code>docker push &lt;username&gt;/&lt;repo&gt;:&lt;tag&gt;</code><ul><li><code>username</code> 必须与你 Docker Hub 中的用户名一致</li></ul></li><li>拉取远端镜像：<code>docker pull &lt;username&gt;/&lt;repo&gt;:&lt;tag&gt;</code></li></ul><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html">https://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html</a></li><li><a href="https://zhuanlan.zhihu.com/p/23599229">https://zhuanlan.zhihu.com/p/23599229</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2022/02/11/MbaA67dgptL9YBc.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;p&gt;软件开发最大的麻烦事之一，就是环境配置。用户计算机的环境不同，可能导致软件在开发环境中能运行，而到了生产环境无法运行的情况。&lt;/p&gt;
&lt;p&gt;用户必须保证两件事：操作系统的设置，各种库和组件的安装。只有它们都正确，软件才能运行。举例来说，安装一个 Python 应用，计算机必须有 Python 引擎，还必须有各种依赖，可能还要配置环境变量。&lt;/p&gt;
&lt;p&gt;环境配置如此麻烦，换一台机器，就要重来一次，旷日费时。很多人想到，能不能从根本上解决问题，软件可以带环境安装？也就是说，&lt;strong&gt;安装的时候，把原始环境一模一样地复制过来&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;这个问题的一种解决方式是使用&lt;strong&gt;虚拟机&lt;/strong&gt;，比如我们常用的 WSL，就是在 Windows 系统中运行 Linux 虚拟系统的例子。但是，这样做的资源占用多，要重新配置一个全新操作系统的冗余步骤多，启动起来也十分缓慢。于是，Linux 发展出了另一种虚拟化技术：&lt;strong&gt;虚拟容器&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。&lt;/strong&gt;或者说，在正常进程的外面套了一个保护层。对于容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。&lt;/strong&gt;它是目前最流行的 Linux 容器解决方案。&lt;/p&gt;
&lt;p&gt;Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。&lt;/p&gt;
&lt;p&gt;总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。&lt;/p&gt;</summary>
    
    
    
    <category term="技术" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="技术/后端" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF-%E5%90%8E%E7%AB%AF/"/>
    
    
    <category term="Docker" scheme="https://www.c7w.tech/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Solving Wordle Using Information Theory 字幕及截图</title>
    <link href="https://www.c7w.tech/solving-wordle-using-infomation-theory/"/>
    <id>https://www.c7w.tech/solving-wordle-using-infomation-theory/</id>
    <published>2022-02-09T07:35:22.000Z</published>
    <updated>2022-02-09T08:29:03.579Z</updated>
    
    <content type="html"><![CDATA[<p>视频链接：<a href="https://www.youtube.om/watch?v=v68zYyaEmEA">https://www.youtube.om/watch?v=v68zYyaEmEA</a></p><p>The game Wordle has gone pretty viral in the last month or two, and never one to overlook an opportunity for a math lesson, it occurs to me that this game makes for a very good central example in a lesson about information theory, and in particular a topic known as entropy.</p><p><img src="https://s2.loli.net/2022/02/09/qEurwPIfFleZXxH.png" alt="image-20220209153901098"></p><p>You see like a lot of people I got kind of sucked into the puzzle, and like a lot of programmers I also got sucked into trying to write an algorithm that would play the game as optimally as it could.</p><a id="more"></a><p>What I thought I’d do here is just talk through with you some of my process in that, and explain some of the math that went into it, since the whole algorithm centers on this idea of entropy.</p><p><img src="https://s2.loli.net/2022/02/09/ZRVUzqtEAgydulF.png" alt="image-20220209153936071"></p><h2 id="What-is-Wordle"><a href="#What-is-Wordle" class="headerlink" title="What is Wordle?"></a>What is Wordle?</h2><p>First things first, in case you haven’t heard of it, what is Wordle? And to kill two birds with one stone here while we go through the rules of the game, let me also preview where we’re going with this, which is to develop a little algorithm that will basically play the game for us.</p><p>I haven’t done today’s Wordle, this is February 4th, and we’ll see how the bot does.</p><p><strong>The goal of Wordle is to guess a mystery five-letter word, and you’re given six different chances to guess.</strong></p><p>For example, my wordlebot suggests that I start with the guess “crane”.</p><p><strong>Each time that you make a guess, you get some information about how close your guess is to the true answer.</strong></p><p><img src="https://s2.loli.net/2022/02/09/VcihA67oex9HlEK.png" alt="image-20220209154123515"></p><p><strong>Here the gray box is telling me there’s no c in the actual answer, the yellow box is telling me there is an r but it’s not in that position. The green box is telling me that the secret word does have an a and it’s in the third position. And then there’s no ‘n’ and there’s no ‘e’.</strong></p><p>Let me just go in and tell the wordlebot about that information… we started with “crane”, we got gray yellow green grey grey…</p><p><img src="https://s2.loli.net/2022/02/09/yYrJl2hP39o8kMV.png" alt="image-20220209154314214"></p><p>Don’t worry about all the data that it’s showing right now, I’ll explain that in due time. Its top suggestion for our second pick is “shtik”. Your guess does have to be an actual five-letter word, but as you’ll see it’s pretty liberal with what it will actually let you guess.</p><p>In this case we try stick and…all right! Things are looking pretty good.</p><p>We hit the ‘s’ and the ‘h’, so we know the first three letters, and we know that there’s an ‘r’.</p><p>So it’s going to be like s-h-a something r or s-h-a-r-something.</p><p>And it looks like the Wordle-bot knows that it’s down to just two possibilities, either “shard” or “sharp”.</p><p><img src="https://s2.loli.net/2022/02/09/K2LFqOyxtXe1njI.png" alt="image-20220209154423328"></p><p>I’s kind of a toss-up between them at this point, so I guess probably just because it’s alphabetical it goes with shard, which…hooray! It is the actual answer.</p><p><img src="https://s2.loli.net/2022/02/09/Nk1zK8PglIqtGno.png" alt="image-20220209154457213"></p><p>So we got it in three. If you’re wondering if that’s any good, the way I heard one person phrase it is that with Wordle, four is par and three is birdie, which I think is a pretty apt analogy.</p><p>You have to be consistently on your game to be getting four but it’s certainly not crazy. But when you get it in three, it just feels great. </p><h2 id="Initial-Ideas"><a href="#Initial-Ideas" class="headerlink" title="Initial Ideas"></a>Initial Ideas</h2><p>If you’re down for it what I’d like to do here is just talk through my thought process from the beginning for how I approach the wordlebot. And like I said really it’s an excuse for an information theory lesson, <strong>the main goal is to explain what is information and what is entropy</strong>. </p><p>My first thought in approaching this was to take a look at the relative frequencies of different letters in the english language.</p><p><img src="https://s2.loli.net/2022/02/09/tTjM6GAB5wrPKmV.png" alt="image-20220209154730755"></p><p>I thought, okay, is there an opening guess or an opening pair of guesses that hits a lot of these most frequent letters.</p><p>Once that I was pretty fond of was doing “other” followed by “nails”.</p><p><img src="https://s2.loli.net/2022/02/09/gYUZmdHpfyucPz6.png" alt="image-20220209154803058"></p><p>The thought is that if you hit a letter, you know you get a green or a yellow, that always feels good, it feels like you’re getting information.But in these cases even if you don’t hit and you always get greys, that’s still giving you a lot of information, since it’s pretty rare to find a word that doesn’t have any of these letters.</p><p>But even still that doesn’t feel super systematic, because for example it does nothing to consider the order of the letters.</p><p>Why type “nails” when I could type “snail”.</p><p>Is it better to have that s at the end? I’m not really sure. Now a friend of mine said that he liked to open with the word “weary”, which kind of surprised me because it has some uncommon letters in there like the ‘w’ and the ‘y’.</p><p>But who knows, maybe that is a better opener.</p><p><strong>Is there some kind of quantitative score that we can give to judge the quality of a potential guess?</strong> To set up for the way that we’re going to rank possible guesses, let’s go back and add a little clarity to how exactly the game is set up.</p><p>There’s a list of words that it will allow you to enter, that are considered valid guesses, that’s just about 13,000 words long.</p><p>But when you look at it there’s a lot of really uncommon things things like “aahed” or “aalii” and “aargh”.</p><p>The kind of words that bring about family arguments in a game of Scrabble.</p><p>But the vibe of the game is that the answer is always going to be a decently common word, and in fact there’s another list of around 2,300 words that are the possible answers.</p><p><img src="https://s2.loli.net/2022/02/09/KrcWQZMwJhz73mq.png" alt="image-20220209154934933"></p><p>This is a human-curated list, I think specifically by the game creator’s girlfriend which is kind of fun. <strong>But what I would like to do, our challenge for this project, is to see if we can write a program solving Wordle that doesn’t incorporate previous knowledge about this list (Answer list).</strong></p><p>For one thing there’s plenty of pretty common five letter words that you won’t find in that list, so it would be better to write a program that’s a little more resilient and would play Wordle against anyone, not just what happens to be the official website.</p><p>And also, the reason that we know what this list of possible answers is is because it’s visible in the source code, but the way that it’s visible in the source code is in the specific order in which answers come up from day to day, so you could always just look up what tomorrow’s answer will be.</p><p>So clearly there’s some sense in which using the list is cheating, and what makes for a more interesting puzzle and a richer information theory lesson is to instead use some more universal data, like relative word frequencies in general, to capture this intuition of having a preference for more common words.</p><p>So! Of these 13,000 possibilities, how should we choose the opening guess? For example if my friend proposes “weary”, how should we analyze its quality? Well the reason he said he likes that unlikely ‘w’ is that he likes the long shot nature of just how good it feels if you do hit that ‘w’.</p><p>For example if the first pattern revealed was something like this, then it turns out there are only 58 words in this giant lexicon that match that pattern, so that’s a huge reduction from 13,000.</p><p>But the flip side of that, of course, is that it’s very uncommon to get a pattern like this.</p><p>Specifically, if each word was equally likely to be the answer, the probability of hitting this pattern would be 58 divided by around 13,000. Of course, they’re not equally likely to be answers, most of these are very obscure and even questionable words, but at least for our first pass at all of this let’s assume that they’re all equally likely, then refine that a bit later.</p><p>The point is the pattern with a lot of information is by its very nature unlikely to occur.</p><p><strong>In fact what it means to be informative is that it’s unlikely.</strong></p><p>A much more probable pattern to see with this opening would be something like this, where of course there’s not a ‘w’ in it, maybe there’s an ‘e’ and maybe there’s no ‘a’, there’s no ‘r’, and there’s no ‘y’.</p><p>In this case there are 1,400 possible matches.</p><p>So if all were equally likely, it works out to be a probability of about 11% that this is the pattern you would see.</p><p><strong>So the most likely outcomes are also the least informative.</strong> To get a more global view here, let me show you the full distribution of probabilities across all of the different patterns that you might see.</p><p><img src="https://s2.loli.net/2022/02/09/Wf9udeVOsp76Phm.png" alt="image-20220209155232751"></p><p>Each bar that you’re looking at corresponds to a possible pattern of colors that could be revealed, of which there are 3^5 possibilities. And they’re organized from left to right, most common to least common.</p><p>So the most common possibility here is that you get all grays, that happens about 14% of the time.</p><p>What you’re hoping for when you make a guess is that you end up somewhere out in this long tail, like over here where there’s only 18 possibilities for what matches this pattern, that evidently look like this.</p><p>Or if we venture a little farther to the left…you know maybe we go all the way over here…okay here’s a good puzzle for you.</p><p>What are the three words in the english language that start with a ‘w’ end with a ‘y’ and have an ‘r’ somewhere in them? It turns out the answers are…</p><p>let’s see…”wordy” “wormy” and “wrily”. </p><p>To judge how good this word is overall, we want some kind of measure of the expected amount of information that you’re going to get from this distribution.</p><p>If we go through each pattern and we multiply its probability of occurring times something that measures how informative it is, that can maybe give us an objective score.</p><p><img src="https://s2.loli.net/2022/02/09/Av92qkau3UCL5Vn.png" alt="image-20220209155405454"></p><p>Now your first instinct for what that something should be might be the number of matches, you know you want a lower average number of matches, but instead I’d like to use a more universal measurement that we often ascribe to information, and one that will be more flexible once we have a different probability assigned to each of these 13,000 words for whether or not they’re actually the answer.</p><h2 id="Information-Theory-Basics"><a href="#Information-Theory-Basics" class="headerlink" title="Information Theory Basics"></a>Information Theory Basics</h2><p>The standard unit of information is the bit, which has a little bit of a funny formula, but it’s really intuitive if we just look at examples.</p><p>If you have an observation that cuts your space of possibilities in half, we say that it has one bit of information. In our example the space of possibilities is all possible words, and it turns out about half of the five letter words have an ‘s’, a little less than that but about half.</p><p><img src="https://s2.loli.net/2022/02/09/pnDBUbVrWLX87zO.png" alt="image-20220209155501486"></p><p>So that observation would give you one bit of information.</p><p>If instead a new fact chops down that space of possibilities by a factor of four, we say that it has two bits of information.</p><p>For example it turns out about a quarter of these words have a ‘t’.</p><p>If the observation cuts that space by a factor of eight, we say it has three bits of information, and so on and so forth.</p><p>Four bits cuts it into a sixteenth, five bits cuts it into a 32nd.</p><p><img src="https://s2.loli.net/2022/02/09/EZtzMDXKNHLu1bj.png" alt="image-20220209155530333"></p><p>So now is when you might want to take a moment to pause and ask for yourself, what is the formula for information, for the number of bits in terms of the probability of an occurrence? Well, what we’re saying here is basically that when you take one half to the number of bits, that’s the same thing as the probability, which is the same thing as saying 2 to the power of the number of bits is 1 over the probability, which rearranges further to saying the information is the log base 2 of 1 divided by the probability.</p><p><img src="https://s2.loli.net/2022/02/09/r9mxnBdh6Kv7tpQ.png" alt="image-20220209155601625"></p><p>And sometimes you see this with one more rearrangement still, where the information is the negative log base 2 of the probability.</p><script type="math/tex; mode=display">I = - \log_2(p)</script><p>Expressed like this it can look a little bit weird to the uninitiated, but it really is just the very intuitive idea of asking how many times you’ve cut down your possibilities in half.</p><p>Now if you’re wondering, you know, I thought we were just playing a fun word game why are logarithms entering the picture? One reason this is a nicer unit is it just a lot easier to talk about very unlikely events.</p><p>Much easier to say that an observation has 20 bits of information than it is to say that the probability of such and such occurring is 0.00000095.</p><p>But a more substantive reason that this logarithmic expression turned out to be a very useful addition to the theory of probability is the way that <strong>information adds together</strong>.</p><p>For example if one observation gives you two bits of information, cutting your space down by four, and then a second observation, like your second guess in Wordle, gives you another three bits of information, chopping you down further by another factor of eight, the two together give you five bits of information.</p><p><img src="https://s2.loli.net/2022/02/09/26ZwfmLz4W7CDIE.png" alt="image-20220209155733905"></p><p>In the same way that probabilities like to multiply, Information likes to add.</p><p>So as soon as we’re in the realm of something like an expected value, where we’re adding a bunch of numbers up, the logs make it a lot nicer to deal with.Let’s go back to our distribution for weary and add another little tracker on here showing us how much information there is for each pattern.</p><p>The main thing I want you to notice is that <strong>the higher the probability, as we get to those more likely patterns, the lower the information, the fewer bits you gain.</strong></p><p><img src="https://s2.loli.net/2022/02/09/Jj7mgwP2xGFpV8d.png" alt="image-20220209155818230"></p><p>The way we measure the quality of this guess will be to take the expected value of this information, where we go through each pattern, we say how probable is it, and then we multiply that by how many bits of information do we get.</p><p><img src="https://s2.loli.net/2022/02/09/obpnzMEUHyArOs6.png" alt="image-20220209155839919"></p><p>And in the example of weary, that turns out to be 4.9 bits. So on average, the information you get from this opening guess is as good as chopping your space of possibilities in half about five times.</p><p>By contrast, an example of a guess with a higher expected information value would be something like “slate”.</p><p>In this case you’ll notice the distribution looks a lot flatter, in particular the most probable occurrence of all grays only has about a 6% chance of occurring.</p><p><img src="https://s2.loli.net/2022/02/09/rnp6IsjAbRkEHae.png" alt="image-20220209155905333"></p><p>So at minimum you’re getting, evidently, 3.9 bits of information. But that’s a minimum, more typically you’d get something better than that.</p><p>And it turns out when you crunch the numbers on this one and you add up all of the relevant terms, the average information is about 5.8.</p><p><img src="https://s2.loli.net/2022/02/09/jq79CUDv3tNucnp.png" alt="image-20220209160058972"></p><p>So in contrast with weary your space of possibilities will be about half as big after this first guess, on average. There’s actually a fun story about the name for this expected value of information quantity.</p><p>You see information theory was developed by Claude Shannon, who was working at Bell labs in the 1940s.</p><p>He was talking about some of his yet-to-be-published ideas with John von Neumann, who was this intellectual giant of the time, a very prominent in math and physics and the beginnings of what was becoming computer science.</p><p>And when he mentioned that he didn’t really have a good name for this expected value of information quantity, von Neumann supposedly said, so the story goes, “well you should call it <strong>Entropy</strong>, and for two reasons.</p><p>In the first place your uncertainty function has been used in statistical mechanics under that name, so it already has a name.</p><p>And in the second place, and more important, nobody knows what entropy really is, so in a debate you’ll always have the advantage.”So if the name seems a little bit mysterious, and if this story is to be believed, that’s kind of by design.</p><p>Also, if you’re wondering about its relation to all of that second law of thermodynamics stuff from physics, there definitely is a connection, but in its origins Shannon was just dealing with pure probability theory.</p><p>And for our purposes here, when I use the word entropy, I just want you to think the expected information value of a particular guess.You can think of entropy as measuring two things simultaneously.</p><p>The first one is how flat is the distribution. The closer a distribution is to uniform, the higher that entropy will be.</p><p>In our case, where there are 3^5 total patterns, for a uniform distribution, observing any one of them would have information log_2(3^5), which happens to be 7.92.</p><p>So that is the absolute maximum that you could possibly have for this entropy.</p><p><img src="https://s2.loli.net/2022/02/09/nA6pmjhPRetwYLD.png" alt="image-20220209160237737"></p><p>But entropy is also kind of a measure of how many possibilities there are in the first place.</p><p>For example if you happen to have some word where there’s only 16 possible patterns, and each one is equally likely, this entropy, this expected information, would be four bits.</p><p>But if you have another word where there are 64 possible patterns that could come up, and they’re all equally likely, then the entropy would work out to be six bits.</p><p>So if you see some distribution out in the wild that has an entropy of six bits, it’s sort of like it’s saying there’s as much variation and uncertainty in what’s about to happen as if there were 64 equally likely outcomes.</p><p>For my first pass at the worldbot, I basically had it just do this. It goes through all of the different possible guesses that you could have, all 13,000 words.</p><p><strong>It computes the entropy for each one, or more specifically the entropy of the distribution across all patterns that you might see for each one, and then it picks the highest, since that’s the one that’s likely to chop down your space of possibilities as much as possible. And even though I’ve only been talking about the first guess here it does the same thing for the next few guesses.</strong></p><p>For example, after you see some pattern on that first guess, which would restrict you to a smaller number of possible words based on what matches with that, you just play the same game with respect to that smaller set of words.</p><p>For a proposed second guess, you look at the distribution of all patterns that could occur from that more restricted set of words.</p><p>You search through all 13,000 possibilities, and you find the one that maximizes that entropy. To show you how this works in action let me just pull up a little variant of Wordle that I wrote that shows the highlights of this analysis in the margins.</p><p>So after doing all its entropy calculations, on the right here it’s showing us which ones have the highest expected information.</p><p><img src="https://s2.loli.net/2022/02/09/psOiFTtw4RazxgV.png" alt="image-20220209160445358"></p><p>It turns out the top answer, at least at the moment we’ll refine this later, is “tares”, which means…um…of course, a vetch the most common vetch.Each time we make a guess here, where maybe I kind of ignore its recommendations and go with slate, because I like slate, we can see how much expected information it had.</p><p>But then on the right of the word here it’s showing us how much actual information we got given this particular pattern.</p><p>So here it looks like we were a little unlucky.</p><p>We were expected to get 5.8, but we happened to get something with less than that.</p><p>And then on the left side here it’s showing us all of the different possible words given where we are now.</p><p>The blue bars are telling us how likely it thinks each word is, so at the moment it’s assuming each word is equally likely to occur, but we’ll refine that in a moment.</p><p><img src="https://s2.loli.net/2022/02/09/p1UQW4CPo7uyMLD.png" alt="image-20220209160549360"></p><p>And then this uncertainty measurement is telling us the entropy of this distribution across the possible words, which right now, because it’s a uniform distribution, is just a needlessly complicated way to count the number of possibilities.</p><p>For example, if we were to take 2 to the power of 13.66, that should be around the 13,000 possibilities.</p><p>It’ a little bit off here, but only because I’m not showing all the decimal places.At the moment that might feel redundant, and like it’s overly complicating things, but you’ll see why it’s useful to have both numbers in a minute. Here it looks like it’s suggesting the highest entropy for our second guess is “ramin”, which again…just really doesn’t feel like a word.</p><p>So to take the moral high ground here I’m going to go ahead and type in “rains”.</p><p>Again it looks like we were a little unlucky, we were expecting 4.3 bits and we only got 3.39 bits of information.</p><p>So that takes us down to 55 possibilities. And here maybe I’ll just actually go with what it’s suggesting, which is “kombu”, whatever that means.</p><p>Okay! This is actually a good chance for a puzzle.</p><p>It’s telling us this pattern gives us 4.78 bits of information, but over on the left before we see that pattern there were 5.78 bits of uncertainty.</p><p><img src="https://s2.loli.net/2022/02/09/JlVRyZmhEcN7g9K.png" alt="image-20220209160719833"></p><p>So as a quiz for you, what does that mean about the number of remaining possibilities? Well it means that we’re reduced down to 1 bit of uncertainty, which is the same thing as saying that there’s two possible answers, it’s a 50/50 choice.</p><p>And from here, because you and I know which words are more common, we know that the answer should be “abyss”.</p><p>But as it’s written right now the program doesn’t know that, so it just keeps going trying to gain as much information as it can until there’s only one possibility left, and then it guesses it.</p><p>So obviously we need a better endgame strategy, but let’s say we call this version one of our Wordle solver and then we go and run some simulations to see how it does.</p><p>The way this is working is it’s playing every possible Wordle game, it’s going through all of those 2,315 words that are the actual Wordle answers, it’s basically using that as a testing set, and with this naive method of not considering how common a word is and just trying to maximize the information at each step along the way until it gets down to one and only one choice, by the end of the simulation the average score works out to be about 4.124.</p><p>Which…you know it’s not bad.</p><p>To be honest I kind of expected to do worse. But the people who play Wordle will tell you that they can usually get it in four.</p><p>The real challenge is to get as many in three as you can.</p><p>It’s a pretty big jump between the score four and the score of three.</p><p>The obvious low-hanging fruit here is to somehow incorporate whether or not a word is common, and how exactly do we do that?</p><h2 id="Incorporating-Word-Frequencies"><a href="#Incorporating-Word-Frequencies" class="headerlink" title="Incorporating Word Frequencies"></a>Incorporating Word Frequencies</h2><p>The way I approached it is to get a list of the relative frequencies for all of the words in the english language.</p><p>I just used Mathematica’s word frequency data function, which itself pulls from the google books english n-gram public dataset.</p><p>And it’s kind of fun to look at, for example if we sort it from the most common words to the least common words, evidently these are the most common five letter words in the english language.</p><p><img src="https://s2.loli.net/2022/02/09/WKVlt4IXGFPySqD.png" alt="image-20220209161017067"></p><p>Or rather, “these” is the eighth most common.</p><p>First is “which” after which there’s “there” and “their”.</p><p>“First” itself is not first but ninth, and it makes sense that these other words could come about more often, where those after “first” are “after,” “where”, and “those”, being just a little bit less common.</p><p>Now, in using this data to model how likely each of these words is to be the final answer, it shouldn’t just be proportional to the frequency.</p><p>Because for example “which” is given a score of 0.002 in this data set, whereas the word “braid” is in some sense about a thousand times less likely.</p><p><img src="https://s2.loli.net/2022/02/09/g2QwhfeLoIFs3Ak.png" alt="image-20220209161048640"></p><p>But both of these are common enough words that they’re almost certainly worth considering, so we want more of a binary cutoff.</p><p>The way I went about it is to imagine taking this whole sorted list of words, and then arranging it on an x-axis, and then applying the sigmoid function, which is the standard way to have a function whose output is basically binary, it’s either zero or it’s one, but there’s a smoothing in between for that region of uncertainty.</p><p><img src="https://s2.loli.net/2022/02/09/iNd4FsV3zk2ZtoD.png" alt="image-20220209161137592"></p><p>So essentially the probability that I’m assigning to each word for being in the final list will be the value of the sigmoid function above wherever it sits on the x-axis.</p><p>Now obviously this depends on a few parameters, for example how wide a space on the x-axis those words fill determines how gradually or steeply we drop off from one to zero, and where we situate them left to right determines the cut off. (取决于输入维度的区间宽度及范围)</p><p>And to be honest the way I did this was kind of just licking my finger and sticking it into the wind.</p><p>I looked through the sorted list and tried to find a window where when I looked at it, I figured about half of these words are more likely than not to be the final answer. And I use that as the cutoff. </p><p><img src="https://s2.loli.net/2022/02/09/MTYE4pyde8aNinZ.png" alt="image-20220209161310497"></p><p>Now once we have a distribution like this across the words, it gives us another situation where entropy becomes this really useful measurement. For example let’s say we were playing a game and we start with my old openers which were “other” and “nails”, and we end up with a situation where there’s four possible words that match it.</p><p>And let’s say we consider them all equally likely.</p><p><img src="https://s2.loli.net/2022/02/09/DwzTrXiO8jM241U.png" alt="image-20220209161353273"></p><p>Let me ask you, what is the entropy of this distribution? Well the information associated with each one of these possibilities is going to be the log_2(4), since each one is 1/4, and that’s 2.</p><p>It’s two bits of information, 4 possibilities, all very well and good. But! What if I told you that actually there are more than four matches.</p><p>In reality, when we look through the full word list, there are 16 words that match it.</p><p>But suppose our model puts a really low probability on those other 12 words of actually being the final answer, something like one in a thousand, because they’re really obscure.</p><p>Now let me ask you, what is the entropy of this distribution? If entropy was purely measuring the number of matches here, then you might expect it to be something like the log_2(16), which would be 4. Two more bits of uncertainty than we had before.</p><p>But of course, the actual uncertainty is not really that different from what we had before.</p><p>Just because there’s these 12 really obscure words doesn’t mean that it would be all that more surprising to learn that the final answer is “charm”, for example.</p><p>So when you actually do the calculation here, and you add up the probability of each occurrence times the corresponding information, what you get is 2.11 bits.</p><p><img src="https://s2.loli.net/2022/02/09/lfBS7JXdjD2M4ao.png" alt="image-20220209161502273"></p><p>It’s saying it’s basically two bits, it’s basically those four possibilities, but there’s a little more uncertainty because of all of those highly unlikely events though if you did learn them you’d get a ton of information from it.</p><p>So zooming out, this is part of what makes Wordle such a nice example for an information theory lesson.</p><p><strong>We have these two distinct feeling applications for entropy, the first one telling us what’s the expected information we’ll get from a given guess, and the second one saying can we measure the remaining uncertainty among all of the words that are possible.</strong></p><p>And I should emphasize, in that first case where we’re looking at the expected information of a guess, once we have an unequal weighting to the words, that affects the entropy calculation.</p><p>For example let me pull up that same case we were looking at earlier of the distribution associated with “weary”, but this time using a non-uniform distribution across all possible words.</p><p>So let me see if I can find a part here that illustrates it pretty well…uh okay, here, this is pretty good.</p><p>Here we have two adjacent patterns that are about equally likely but one of them, we’re told, has 32 possible words that match it.</p><p>And if we check what they are, these are those 32, which are all just very unlikely words.</p><p><img src="https://s2.loli.net/2022/02/09/GDQVr1hBYo5P7W6.png" alt="image-20220209161706837"></p><p>As you scan your eyes over them it’s hard to find any that feel like plausible answers.</p><p>Maybe “yells”? But if we look at the neighboring pattern in the distribution, which is considered just about as likely, we’re told that it only has eight possible matches.</p><p>So a quarter as many matches, but it’s about as likely.</p><p>And when we pull up those matches, we can see why.</p><p><img src="https://s2.loli.net/2022/02/09/ayRoFKzOZTmAWjH.png" alt="image-20220209161727181"></p><p>Some of these are actual plausible answers like “wring” or “wrath” or “wraps”.</p><p>To illustrate how we incorporate all that, let me pull up version 2 of the wordlebot here. There are two or three main differences from the first one that we saw.</p><p>First off, like I just said, the way that we’re computing these entropies, these expected values of information, is now using the more refined distributions across the patterns that incorporates the probability that a given word would actually be the answer. As it happens, “tares” is still number one, though the ones following are a bit different. </p><p><img src="https://s2.loli.net/2022/02/09/HevyU5hxcwrXpKQ.png" alt="image-20220209161825240"></p><p>Second, when it ranks its top picks, it’s now going to keep a model of the probability that each word is the actual answer, and it’ll incorporate that into its decision, which is easier to see once we have a few guesses on the table.</p><p>Again ignoring its recommendation, because we can’t let machines rule our lives…And I suppose I should mention another thing different here is over on the left, that uncertainty value, that number of bits, is no longer just redundant with the number of possible matches.</p><p>Now if we pull it up, and you know, we calculated, say, 2 to the 8.02, which would be a little above 256…I guess 259.</p><p><img src="https://s2.loli.net/2022/02/09/2jCnzwULoJIKV1i.png" alt="image-20220209161923324"></p><p>What it’s saying is even though there are 526 total words that actually match this pattern, the amount of uncertainty it has is more akin to what it would be if there were 259 equally likely outcomes.</p><p>You could think of it like this, it knows “borks” is not the answer same with “yortz” and “zoril” and “zorus”.</p><p>So it’s a little less uncertain than it was in the previous case, this number of bits will be smaller.</p><p>And if I keep playing the game, I’ll refining this down with a couple guesses that are apropos of what I would like to explain here…By the fourth guess, if you look over at its top picks, you can see it’s no longer just maximizing the entropy.</p><p>At this point, there’s technically seven possibilities, but the only ones with a meaningful chance are “dorms” and “words”, and you can see it ranks choosing both of those above all of these other values that, strictly speaking, would give more information.</p><p><img src="https://s2.loli.net/2022/02/09/wpbVlZ5EDegxfOY.png" alt="image-20220209162134927"></p><p>The very first time I did this I just added up these two numbers to measure the quality of each guess, which actually worked better than you might suspect.</p><p>But it really didn’t feel systematic.</p><p>I’m sure there are other approaches people could take, but here’s the one I landed on.</p><p>If we’re considering the prospect of a next guess, like in this case “words”, what we really care about is the expected score of our game if we do that.</p><p>And to calculate that expected score, we say “what’s the probability that ‘words’ is the actual answer?”, which at the moment it ascribes 58% to.</p><p>So we say with a 58% chance, our score in this game would be four, and then with the probability of one minus that 58 percent, our score will be more than that four.How much more? We don’t know, but we can estimate it based on how much uncertainty there’s likely to be once we get to that point.</p><p><img src="https://s2.loli.net/2022/02/09/SKobMxvZHJB4pP2.png" alt="image-20220209162242496"></p><p>Specifically, at the moment there are 1.44 bits of uncertainty, if we guess “words” it’s telling us the expected information we’ll get is 1.27 bits, so if we guess “words” this difference represents how much uncertainty we’re likely to be left with after that happens.</p><p>What we need is some kind of function, which I’m calling $f$ here, that associates this uncertainty with an expected score.</p><p>The way I went about this was to just plot a bunch of the data from previous games based on version one of the bot, to say “hey what was the actual score after various points with certain very measurable amounts of uncertainty?” For example, these data points here that are sitting above a value that’s around 8.7 or so are saying “for some games, after a point at which there were 8.7 bits of uncertainty, it took two guesses to get the final answer.</p><p><img src="https://s2.loli.net/2022/02/09/CH8We4Z9a7hm2PS.png" alt="image-20220209162411016"></p><p>For other games it took three guesses, for other games it took four guesses.”If we shift over to the left here, all the points over zero are saying “whenever there are zero bits of uncertainty, which is to say there’s only one possibility, then the number of guesses required is always just one”, which is reassuring.</p><p>Whenever there was one bit of uncertainty, meaning it was essentially just down to two possibilities, then sometimes it required one more guess sometimes it required two more guesses, and so on and so forth.</p><p>Here, maybe a slightly easier way to visualize this data is to bucket it together and take averages.</p><p><img src="https://s2.loli.net/2022/02/09/Kcf2tdrQmqRPC3l.png" alt="image-20220209162433488"></p><p>For example, this bar here is saying “among all the points where we had one bit of uncertainty, on average the number of new guesses required was about 1.5.”And the bar over here saying “among all of the different games were at some point the uncertainty was a little above 4 bits, which is like narrowing it down to 16 different possibilities, then on average it requires a little more than two guesses from that point forward”.</p><p>And from here I just did a regression to fit a function that seemed reasonable to this.And remember the whole point of doing any of that is so that we can quantify this intuition that the more information we gain from a word, the lower the expected score will be.</p><h2 id="Final-Performance"><a href="#Final-Performance" class="headerlink" title="Final Performance"></a>Final Performance</h2><p>So with this as version 2.0, if we go back and we run the same set of simulations, having it play against all 2,315 possible Wordle answers, how does it do? Well in contrast to our first version, it’s definitely better, which is reassuring. All said and done, the average is around 3.6.</p><p>Although unlike the first version, there are a couple times that it loses and requires more than six in this circumstance, presumably because there are times when it’s making that trade-off to actually go for the goal, rather than maximizing information.</p><p>So can we do better than 3.6? We definitely can. I said at the start that it’s most fun to try not incorporating the true list of Wordle answers into the way that it builds its model.</p><p>But if we do incorporate it, the best performance I could get was around 3.43.</p><p><img src="https://s2.loli.net/2022/02/09/KPkag9GVXID2nlW.png" alt="image-20220209162714823"></p><p>So if we try to get more sophisticated than just using word frequency data to choose this prior distribution, this 3.43 probably gives a max at how good we could get with that. Or at least how good I could get with that.</p><p>That best performance essentially just uses the ideas that I’ve been talking about here, but it goes a little farther.</p><p>Like it does a search for the expected information two steps forward, rather than just one.</p><p>Originally I was planning on talking more about that, but I realize we’ve actually gone quite long as it is.</p><p><img src="https://s2.loli.net/2022/02/09/rOoiW9mEnjU7PRu.png" alt="image-20220209162754003"></p><p>The one thing I’ll say is after doing this two-step search, and then running a couple sample simulations in the top candidates, so far for me at least it’s looking like “crane” is the best opener.</p><p>Who would have guessed?Also if you use the true word list to determine your space of possibilities then the uncertainty you start with is a little over 11 bits.</p><p>And it turns out, just from a brute force search, the maximum possible expected information after the first two guesses is around 10 bits, which suggests that, best case scenario after your first two guesses, with perfectly optimal play, you’ll be left with around one bit of uncertainty, which is the same as being down to two possible guesses.</p><p>So I think it’s fair, and probably pretty conservative, to say that you could never possibly write an algorithm that gets this average as low as 3, because with the words available to you there’s simply not room to get enough information after only two steps to be able to guarantee the answer in the third slot every single time without fail.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;视频链接：&lt;a href=&quot;https://www.youtube.om/watch?v=v68zYyaEmEA&quot;&gt;https://www.youtube.om/watch?v=v68zYyaEmEA&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The game Wordle has gone pretty viral in the last month or two, and never one to overlook an opportunity for a math lesson, it occurs to me that this game makes for a very good central example in a lesson about information theory, and in particular a topic known as entropy.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2022/02/09/qEurwPIfFleZXxH.png&quot; alt=&quot;image-20220209153901098&quot;&gt;&lt;/p&gt;
&lt;p&gt;You see like a lot of people I got kind of sucked into the puzzle, and like a lot of programmers I also got sucked into trying to write an algorithm that would play the game as optimally as it could.&lt;/p&gt;</summary>
    
    
    
    <category term="理论" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/"/>
    
    <category term="理论/信息论" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/%E7%90%86%E8%AE%BA-%E4%BF%A1%E6%81%AF%E8%AE%BA/"/>
    
    
    <category term="信息论" scheme="https://www.c7w.tech/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>VSCode 配置指北</title>
    <link href="https://www.c7w.tech/vscode/"/>
    <id>https://www.c7w.tech/vscode/</id>
    <published>2022-02-09T03:49:16.000Z</published>
    <updated>2022-02-13T08:44:35.991Z</updated>
    
    <content type="html"><![CDATA[<p>VSCode 是一款<strong>轻量级</strong>的<strong>代码编辑器</strong>，可以通过安装各种各样不同<strong>扩展</strong>的方式来实现开发者所需要的功能。</p><blockquote><p>区分：代码编辑器（Editor）与集成开发环境（IDE, Integrated Development Environment）</p><p>代码编辑器事实上我们可以看成是一个记事本（没错，如果是 Windows 用户，就是你按下 Win+R 输入 notepad 回车之后的那个记事本），其最基本的功能是文档编辑。不过之所以将其称为是<strong>代码编辑器</strong>，是因为它虽然继承自一般的文档编辑器，又具备了一些一般的文档编辑器所不具备的功能。具体来说，例如自动语法高亮，自动补全，甚至是自动代码重构等等。</p><p>集成开发环境（IDE）是一种用于构建应用程序的软件，<strong>可将常用的开发人员工具合并到单个图形用户界面</strong>（GUI）中。具体来说，我们只需要简单的点击按钮，可能就可以完成程序的编译、链接、运行、调试等等工作。而这些工作在最初都是需要人手工在命令行中完成的。我们在《程序设计基础》课程中最初使用的 Dev-C++ 便是一个集成开发环境。</p></blockquote><p>我们今天要介绍的 VSCode 是一款轻量级的<strong>代码编辑器</strong>。如果没有各种扩展插件的支持的话，可能我们只能把它称作是大号的 Notepad++，而正是因为社区中各种各样的扩展，VSCode 才得以展现其强大。</p><p><img src="https://s2.loli.net/2022/02/09/psKk8yJ2CxMic1O.png" alt="image-20220209114623794"></p><p>本文我们介绍 VSCode 的基本配置，重点在于介绍一些未来可能会用到的扩展插件。按照本文的流程完成后，你应该等效地完成了足以应对《面向对象程序设计基础》课程中的代码的集成开发环境的配置。此外，我们还会介绍一些基本的调试方法，而这恰恰是 VSCode 比 Dev-C++ 在现阶段不知道高到哪里去的地方。</p><p>事实上，在未来，我们可以用 VSCode 配置 Python 开发环境，配置软件工程课程中所需要的框架的开发环境，而这些都是通过“扩展”（Extension）来实现的。</p><a id="more"></a><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><ul><li>了解一个 C++ 程序从源代码到可执行程序中发生了编译、链接这两步操作（《程序设计基础》大作业中会有此部分的讲解）</li><li>动手能力</li></ul><h2 id="下载与运行"><a href="#下载与运行" class="headerlink" title="下载与运行"></a>下载与运行</h2><ul><li>打开 VSCode 官网：<a href="https://code.visualstudio.com/">https://code.visualstudio.com/</a></li><li>点击大大的 Download 按钮（如果是 Windows 64 位用户可以点击下拉框选择 x64 安装包版本）</li><li>进行安装或解压缩（注意路径中不能存在任何中文字符，推荐仅用字母和数字）</li><li>到你安装 VSCode 的目录下，新建 <code>data</code> 文件夹</li></ul><blockquote><p>这里我们新建 <code>data</code> 文件夹后，之后 VSCode 运行时的扩展插件和用户数据便都会存放在 <code>data</code> 文件夹下，这样可以在一定程度上避免系统盘容量占用的问题。如果不新建 <code>data</code> 文件夹，那么 VSCode 会将上述插件和用户信息存放在系统盘的用户目录下。</p><p><img src="https://s2.loli.net/2022/02/09/IsPShQ2nLyqmwH8.png" alt="image-20220209213021194"></p></blockquote><h2 id="C-相关开发环境配置"><a href="#C-相关开发环境配置" class="headerlink" title="C++ 相关开发环境配置"></a>C++ 相关开发环境配置</h2><h3 id="环境变量与-Mingw64"><a href="#环境变量与-Mingw64" class="headerlink" title="环境变量与 Mingw64"></a>环境变量与 Mingw64</h3><p>我们可以先打开终端（Windows 用户请使用 Win+R，输入 <code>cmd</code>），尝试输入：</p><pre class="language-bash" data-language="bash"><code class="language-bash">g++ --version</code></pre><p>如果你的终端返回了 <code>g++</code> 的版本信息，恭喜，您 C++ 编译器的环境变量配置正确，可以跳过这一小节。当然，如果想更加详细地了解环境变量是什么，可以继续阅读这一小节。</p><p>而如果返回：</p><pre class="language-bash" data-language="bash"><code class="language-bash"><span class="token string">'g++'</span> 不是内部或外部命令，也不是可运行的程序或批处理文件。</code></pre><p>那么则说明你的终端不知道 <code>g++</code> 是什么命令。我们接下来将首先讲解环境变量是什么，然后再为大家讲述该怎么配置环境变量。</p><ul><li>什么是环境变量？</li></ul><p>当你的 Shell 在执行命令时，会尝试在<strong>一系列路径</strong>下搜索同名的可执行文件。这一系列路径我们就称作是环境变量。</p><p>Windows 用户可以在终端中输入 path 来查看当前环境变量（由于我进行过一系列配置，所以其输出结果可能与你的不同）：</p><pre class="language-bash" data-language="bash"><code class="language-bash">D:<span class="token punctuation">\</span>Coding<span class="token operator">></span>path<span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span>D:<span class="token punctuation">\</span>Anaconda<span class="token punctuation">;</span>D:<span class="token punctuation">\</span>Anaconda<span class="token punctuation">\</span>Library<span class="token punctuation">\</span>mingw-w64<span class="token punctuation">\</span>bin<span class="token punctuation">;</span>D:<span class="token punctuation">\</span>Anaconda<span class="token punctuation">\</span>Library<span class="token punctuation">\</span>usr<span class="token punctuation">\</span>bin<span class="token punctuation">;</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span></code></pre><p>Linux 用户可以通过使用 <code>echo $PATH</code> 来查看自己的环境变量：</p><pre class="language-bash" data-language="bash"><code class="language-bash">c7w@cc7w <span class="token operator">></span> /mnt/d/Coding <span class="token operator">></span> <span class="token builtin class-name">echo</span> <span class="token environment constant">$PATH</span>/home/c7w/.local/lib/python3.8/site-packages:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/mnt/d/Anaconda:/mnt/d/Anaconda/Library/mingw-w64/bin:/mnt/d/Anaconda/Library/usr/bin:/mnt/d/Anaconda/Library/bin:/mnt/d/Anaconda/Scripts:/mnt/f/VM/bin/:/mnt/c/Program Files <span class="token punctuation">(</span>x86<span class="token punctuation">)</span>/Common Files/Intel/Shared Libraries/redist/intel64/compiler:/mnt/c/Program Files/Common Files/Oracle/Java/javapath:<span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span></code></pre><p>没错，就是这一系列文件夹。回忆我们刚才执行 <code>g++ --version</code> 命令的时候，我们的终端会在这一系列文件夹下为我们寻找叫做 <code>g++</code> 的可执行文件。如果找到了名为 <code>g++</code> 的可执行文件，我们的终端就会将参数传入，将其执行；而如果我们的终端没有找到，那么就会向我们报告“未知命令”。</p><p>我们刚刚已经理解了“环境变量（Path）”的运行逻辑，接下来我们讲解如何进行环境变量的配置。`</p><p>对于 Windows 用户，请按下 Windows + S 打开搜索框，在其中输入 <code>path</code>，然后选择”编辑系统环境变量”，进而选择“环境变量”，然后选择“系统变量”中的 Path 字段，双击打开后即可配置。</p><p><img src="https://s2.loli.net/2022/02/09/L9DhPnOjNZ58gCV.png" alt="image-20220209214212982"></p><p>对于 Linux 用户，环境变量是绑定在你的 Shell 上的，不同的 Shell 有不同的配置方式。这里我们提供一个<a href="https://www.cnblogs.com/youyoui/p/10680329.html">链接</a>帮助您了解环境变量的相关配置。</p><ul><li>什么是 Mingw64？</li></ul><blockquote><p>MinGW 的全称是：Minimalist GNU on Windows。</p><p>它实际上是将经典的开源 C 语言编译器 GCC 移植到了 Windows 平台下，并且包含了 Win32API，因此可以将源代码编译为可在 Windows 中运行的可执行程序。而且还可以使用一些 Windows 不具备的，Linux平台下的开发工具。</p><p>一句话来概括：MinGW 就是 GCC 的 Windows 版本。这是将你写的 C/C++ 语言的源代码编译成汇编代码，进而链接成可执行文件的工具。之前我们的 Dev-C++ 事实上也集成了这个工具。</p></blockquote><p>我们下载官方的安装工具（<a href="https://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win32/Personal%20Builds/mingw-builds/installer/mingw-w64-install.exe">链接</a>），下载完成后右键以管理员身份运行，<code>Architecture</code> 中 <code>i686</code> 是针对于 32 位系统，<code>x86_64</code> 针对于 64 位系统，其他不用修改，进入下一步选择安装目录即可。然后即可等待安装程序下载并进行安装。</p><p>然后，我们需要进行环境变量配置。进入 <code>Mingw64 的安装路径/mingw64/bin/</code>，我们可以看到 <code>gcc</code>，<code>g++</code> 这些我们熟悉的可执行文件。<strong>然后我们需要做的就是将这个文件夹添加至环境变量中。</strong></p><p>然后我们就可以打开终端，输入 <code>g++</code> 验证环境变量是否配置成功。（请注意，在环境变量配置后需要重启终端才能生效）</p><h3 id="Make"><a href="#Make" class="headerlink" title="Make"></a>Make</h3><p>同时，针对于我们之后课上所需要用到的 <code>make</code> 命令，我们可以将同目录下的 <code>mingw32-make.exe</code> 复制一份，改名为 <code>make.exe</code>，这样我们也能正常使用 <code>make</code> 命令了。</p><p>由于 Linux 平台自带了 <code>gcc</code> 和 <code>make</code> 等等编译工具，所以这里不需要进行额外的配置。</p><h2 id="扩展插件的安装"><a href="#扩展插件的安装" class="headerlink" title="扩展插件的安装"></a>扩展插件的安装</h2><p>我们打开 VSCode，先简单介绍下界面及其功能：</p><p><img src="https://s2.loli.net/2022/02/09/pM6kzGH4xbIRW5K.png" alt="image-20220209220846472"></p><p>红色框是我们当前项目（即文件夹）下的所有文件清单，蓝色框是我们编写代码的地方，绿色框是我们的应用商店。</p><p>这里我们推荐几个扩展，在应用商店中搜索即可下载：</p><ul><li>Chinese (Simplified) Language Pack for Visual Studio Code：语言</li><li>Code Runner：调试用</li><li>C/C++：支持在 Code 中调试 C/C++ 程序</li><li>Remote - SSH：之后进行远程开发会用到，这里不多做介绍</li></ul><p>在安装了简体中文插件后，我们可以按 <code>Ctrl + Shift + P</code>，打开输入框，输入 <code>Configurate display language</code>，选择中文后重新启动即可。</p><h2 id="代码调试"><a href="#代码调试" class="headerlink" title="代码调试"></a>代码调试</h2><p>如何运行一段代码呢？很简单，我们只需要在<strong>对应的代码界面</strong>按下 <code>F5</code> 或是在菜单栏找到“运行 &gt; 启动调试”，便可以启动调试模式：</p><p><img src="https://s2.loli.net/2022/02/09/x6yBiPzfVAQsErZ.png" alt="image-20220209221547145"></p><p>在配置中选择 <code>C++ (GDB)</code>，进而选择 <code>g++.exe</code>。</p><p>然后我们会发现项目路径下生成了一个 <code>.vscode</code> 文件夹，内含 <code>tasks.json</code> 和 <code>launch.json</code>，这两个文件分别有什么作用我们即将就会进行介绍。</p><p><img src="https://s2.loli.net/2022/02/09/pwDenGirIJZdjsv.png" alt="image-20220209221657511"></p><p>（你的界面排版可能和我有所不同，不过主要功能是大同小异的，当你熟练运用了 Code 之后你可以自行将这几个框框拖来拖去摆到你觉得舒适的位置）</p><p>我们接下来将分单文件项目和多文件项目进行讨论，说明一些在 Code 中调试 C++ 代码的技巧。</p><h3 id="单文件项目"><a href="#单文件项目" class="headerlink" title="单文件项目"></a>单文件项目</h3><p>单文件项目指只有一个 cpp 文件的项目，<code>main()</code> 函数的定义就在其中，我们在《程序设计基础》课程的大部分平时作业都是这种项目。</p><p>这种项目我们直接按 <code>F5</code> 便可进行运行，其输出结果会在“终端”选项卡中出现。</p><p><img src="https://s2.loli.net/2022/02/09/UO5mv1K3VBcN2lL.png" alt="image-20220209222124275"></p><p>这是一段演示单向平方和双向平方探测在哈希表中可以占用的位置的示例程序，在这里仅做说明使用，大家不必理解其背后的原理。（事实上你给别人调代码的时候不都是这样嘛，对着看不懂的逻辑满脸黑线.jpeg）</p><p>想要在程序运行过程中设置断点，我们只需点击对应的行号：</p><p><img src="https://s2.loli.net/2022/02/09/ZVFLrcwSbaOdxTm.png" alt="image-20220209222401148"></p><p>在这里设置断点，程序将会在第 30 行执行完成，第 31 行将要执行的时候触发断点，让我们看一看：</p><p><img src="https://s2.loli.net/2022/02/09/5tHAOwQBdh1Sqcs.png" alt="image-20220209222500324"></p><p>红框，也就是“终端框中，我们的程序输出了前半段运行时产生的 <code>cout</code> 信息。接下来我们将说明该如何查看中间变量：</p><p><img src="https://s2.loli.net/2022/02/09/UEioypzr9fa57GK.png" alt="image-20220209222635735"></p><p>比如程序在命中这个断点时，我们有以下途径获取中间变量的值：</p><p>在黄色框“变量”中，我们可以看到程序自动追溯的局部变量和寄存器值。在蓝色框“监视”中，我们可以自行定义一些需要追溯的变量。在红色框中，我们可以直接输入变量名来查看其对应的值。</p><p><img src="https://s2.loli.net/2022/02/09/jAlCZgHIYphwoDv.png" alt="image-20220209222812673"></p><p>然后，我们来将目光放在上述这几个按钮身上。</p><ul><li>继续（F5）按钮将会使程序继续执行，直到命中下一个断点或是到程序结尾。</li><li>单步跳过（F10）按钮对于程序来说，如果将要执行的行调用了某些函数，那么将直接将本行执行完毕，进入下一行。</li><li>单步调试（F11）按钮对于程序来说，如果将要执行的行调用了某些函数，那么将进入将要执行的函数内部。</li><li>停止（Shift+F5）按钮终止当前调试工作。</li></ul><h3 id="多文件项目"><a href="#多文件项目" class="headerlink" title="多文件项目"></a>多文件项目</h3><p>对于多文件项目的调试来说，我们重点关注点在于 <code>.vscode</code> 下两个文件的配置。</p><p>首先我们将我们的示例程序修改为多文件项目：</p><p><img src="https://s2.loli.net/2022/02/09/IBLJmUG7NCy1ikv.png" alt="image-20220209223422595"></p><p>我们采用最简单的方式，将我们的单文件项目魔改成多文件。</p><p>我们回忆如果使用命令行，该如何将我们的程序编译：</p><pre class="language-bash'" data-language="bash'"><code class="language-bash'">g++ hash.cpp another.cpp -o main</code></pre><p>没错，我们现在配置 Code 使得其在“生成目标文件”任务中执行上述命令。</p><p><code>tasks.json</code> 负责可执行文件的生成，我们主要进行如下修改：</p><pre class="language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>    <span class="token property">"tasks"</span><span class="token operator">:</span> <span class="token punctuation">[</span>        <span class="token punctuation">&#123;</span>            <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"shell"</span><span class="token punctuation">,</span> <span class="token comment">// cppbuild -> shell</span>            <span class="token property">"label"</span><span class="token operator">:</span> <span class="token string">"C/C++: g++.exe 生成活动文件"</span><span class="token punctuation">,</span>            <span class="token property">"command"</span><span class="token operator">:</span> <span class="token string">"D:\\Mingw\\mingw64\\bin\\g++.exe"</span><span class="token punctuation">,</span>            <span class="token property">"args"</span><span class="token operator">:</span> <span class="token punctuation">[</span>                <span class="token string">"-g"</span><span class="token punctuation">,</span>                <span class="token string">"hash.cpp"</span><span class="token punctuation">,</span> <span class="token comment">// $&#123;file&#125; -> your source code list</span>                <span class="token string">"another.cpp"</span><span class="token punctuation">,</span>                <span class="token string">"-o"</span><span class="token punctuation">,</span>                <span class="token string">"$&#123;fileDirname&#125;\\main.exe"</span> <span class="token comment">// main.exe</span>            <span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token property">"options"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>                <span class="token property">"cwd"</span><span class="token operator">:</span> <span class="token string">"$&#123;fileDirname&#125;"</span>            <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>            <span class="token property">"problemMatcher"</span><span class="token operator">:</span> <span class="token punctuation">[</span>                <span class="token string">"$gcc"</span>            <span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token property">"group"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>                <span class="token property">"kind"</span><span class="token operator">:</span> <span class="token string">"build"</span><span class="token punctuation">,</span>                <span class="token property">"isDefault"</span><span class="token operator">:</span> <span class="token boolean">true</span>            <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>            <span class="token property">"detail"</span><span class="token operator">:</span> <span class="token string">"调试器生成的任务。"</span>        <span class="token punctuation">&#125;</span>    <span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token property">"version"</span><span class="token operator">:</span> <span class="token string">"2.0.0"</span><span class="token punctuation">&#125;</span></code></pre><p><code>launch.json</code> 主要负责调试目标程序，我们做以下修改：</p><pre class="language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>    <span class="token comment">// 使用 IntelliSense 了解相关属性。 </span>    <span class="token comment">// 悬停以查看现有属性的描述。</span>    <span class="token comment">// 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387</span>    <span class="token property">"version"</span><span class="token operator">:</span> <span class="token string">"0.2.0"</span><span class="token punctuation">,</span>    <span class="token property">"configurations"</span><span class="token operator">:</span> <span class="token punctuation">[</span>        <span class="token punctuation">&#123;</span>            <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"g++.exe - 生成和调试活动文件"</span><span class="token punctuation">,</span>            <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"cppdbg"</span><span class="token punctuation">,</span>            <span class="token property">"request"</span><span class="token operator">:</span> <span class="token string">"launch"</span><span class="token punctuation">,</span>            <span class="token property">"program"</span><span class="token operator">:</span> <span class="token string">"$&#123;fileDirname&#125;\\main.exe"</span><span class="token punctuation">,</span> <span class="token comment">// main.exe</span>            <span class="token property">"args"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token property">"stopAtEntry"</span><span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>            <span class="token property">"cwd"</span><span class="token operator">:</span> <span class="token string">"$&#123;fileDirname&#125;"</span><span class="token punctuation">,</span>            <span class="token property">"environment"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token property">"externalConsole"</span><span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>            <span class="token property">"MIMode"</span><span class="token operator">:</span> <span class="token string">"gdb"</span><span class="token punctuation">,</span>            <span class="token property">"miDebuggerPath"</span><span class="token operator">:</span> <span class="token string">"D:\\Mingw\\mingw64\\bin\\gdb.exe"</span><span class="token punctuation">,</span>            <span class="token property">"setupCommands"</span><span class="token operator">:</span> <span class="token punctuation">[</span>                <span class="token punctuation">&#123;</span>                    <span class="token property">"description"</span><span class="token operator">:</span> <span class="token string">"为 gdb 启用整齐打印"</span><span class="token punctuation">,</span>                    <span class="token property">"text"</span><span class="token operator">:</span> <span class="token string">"-enable-pretty-printing"</span><span class="token punctuation">,</span>                    <span class="token property">"ignoreFailures"</span><span class="token operator">:</span> <span class="token boolean">true</span>                <span class="token punctuation">&#125;</span>            <span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token property">"preLaunchTask"</span><span class="token operator">:</span> <span class="token string">"C/C++: g++.exe 生成活动文件"</span>        <span class="token punctuation">&#125;</span>    <span class="token punctuation">]</span><span class="token punctuation">&#125;</span></code></pre><p>然后我们就可以愉快地调试多文件项目了。</p><h2 id="后续学习"><a href="#后续学习" class="headerlink" title="后续学习"></a>后续学习</h2><ul><li>自行研究 Remote-SSH 的使用方法，如何连接到外部服务器进行开发</li><li>自行研究 Python 配置调试环境的方法</li><li>在《软件工程》课程中，使用 Code Prettier 插件 + ESLint 规范项目</li></ul><h2 id="资源链接"><a href="#资源链接" class="headerlink" title="资源链接"></a>资源链接</h2><ul><li><a href="https://code.visualstudio.com/">https://code.visualstudio.com/</a></li><li><a href="https://zhuanlan.zhihu.com/p/76613134">https://zhuanlan.zhihu.com/p/76613134</a></li><li><a href="https://blog.csdn.net/linjf520/article/details/108559210">https://blog.csdn.net/linjf520/article/details/108559210</a></li></ul><p>Tips: 配置开发环境往往是在学习的过程中最恼人的一件事，但是不用心急，常言道“良好的开端是成功的一半”。如果实在遇到配置问题，在进行搜索无法解决后，建议向同年级/学长/答疑坊进行求助。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;VSCode 是一款&lt;strong&gt;轻量级&lt;/strong&gt;的&lt;strong&gt;代码编辑器&lt;/strong&gt;，可以通过安装各种各样不同&lt;strong&gt;扩展&lt;/strong&gt;的方式来实现开发者所需要的功能。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;区分：代码编辑器（Editor）与集成开发环境（IDE, Integrated Development Environment）&lt;/p&gt;
&lt;p&gt;代码编辑器事实上我们可以看成是一个记事本（没错，如果是 Windows 用户，就是你按下 Win+R 输入 notepad 回车之后的那个记事本），其最基本的功能是文档编辑。不过之所以将其称为是&lt;strong&gt;代码编辑器&lt;/strong&gt;，是因为它虽然继承自一般的文档编辑器，又具备了一些一般的文档编辑器所不具备的功能。具体来说，例如自动语法高亮，自动补全，甚至是自动代码重构等等。&lt;/p&gt;
&lt;p&gt;集成开发环境（IDE）是一种用于构建应用程序的软件，&lt;strong&gt;可将常用的开发人员工具合并到单个图形用户界面&lt;/strong&gt;（GUI）中。具体来说，我们只需要简单的点击按钮，可能就可以完成程序的编译、链接、运行、调试等等工作。而这些工作在最初都是需要人手工在命令行中完成的。我们在《程序设计基础》课程中最初使用的 Dev-C++ 便是一个集成开发环境。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们今天要介绍的 VSCode 是一款轻量级的&lt;strong&gt;代码编辑器&lt;/strong&gt;。如果没有各种扩展插件的支持的话，可能我们只能把它称作是大号的 Notepad++，而正是因为社区中各种各样的扩展，VSCode 才得以展现其强大。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2022/02/09/psKk8yJ2CxMic1O.png&quot; alt=&quot;image-20220209114623794&quot;&gt;&lt;/p&gt;
&lt;p&gt;本文我们介绍 VSCode 的基本配置，重点在于介绍一些未来可能会用到的扩展插件。按照本文的流程完成后，你应该等效地完成了足以应对《面向对象程序设计基础》课程中的代码的集成开发环境的配置。此外，我们还会介绍一些基本的调试方法，而这恰恰是 VSCode 比 Dev-C++ 在现阶段不知道高到哪里去的地方。&lt;/p&gt;
&lt;p&gt;事实上，在未来，我们可以用 VSCode 配置 Python 开发环境，配置软件工程课程中所需要的框架的开发环境，而这些都是通过“扩展”（Extension）来实现的。&lt;/p&gt;</summary>
    
    
    
    <category term="技术" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="技术/综合" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF-%E7%BB%BC%E5%90%88/"/>
    
    
    <category term="VSCode" scheme="https://www.c7w.tech/tags/VSCode/"/>
    
  </entry>
  
  <entry>
    <title>ExpressJS 项目开发指北</title>
    <link href="https://www.c7w.tech/express-js/"/>
    <id>https://www.c7w.tech/express-js/</id>
    <published>2022-02-08T10:58:10.000Z</published>
    <updated>2022-02-08T16:14:35.861Z</updated>
    
    <content type="html"><![CDATA[<p>Express 是一个简洁而灵活的 Node.js Web 应用框架, 提供了一系列强大特性帮助你创建各种 Web 应用，和丰富的 HTTP 工具。</p><p>使用 Express 可以快速地搭建一个完整功能的网站，但是，我们一般更倾向于使用 Express 来快速搭建<strong>网站后端</strong>。</p><p>注意，这里我们将网站分为前端和后端，事实上与我们在《程序设计训练》课程中对于使用 Django 来搭建网站的方式不同。Django 的页面渲染是<strong>服务器端渲染</strong>（Server-side Rendering），也就是说，在收到用户发来的请求后，服务器端按照设计的逻辑读取相应的页面模板，在完成页面渲染（也就是在页面模板的对应处填充对应字段）后，将渲染后的 HTML 页面直接发给用户。</p><p>而这里我们将网站分为“前端”和“后端”，这种设计模式和上述服务器端渲染有本质的区别，我们一般称为<strong>客户端渲染</strong>（Client-side Rendering）。其运作模式是，网站提供服务器直接将未渲染的 HTML 模板（我们称为“前端代码”）发送给用户，而这模板中包含了类似于 <code>fetch</code> 的函数，可以在浏览器将其渲染时向我们的“后端”发送请求。“后端”在收到请求后，一般以 Json 格式返回所请求的数据，前端再通过 Javascript 脚本将收到的数据渲染在页面上。</p><p>在《软件工程》课程中我们推荐使用后者这种设计模式，即进行前后端分离。虽然我们也可以继续利用 Django 来作为后端，但是我们这里给大家提供一种业界也很常用的选项 —— Express。其优点在于，相比于 Django 而言，其编写起来更加方便，也更加快捷。<s>而且，后端更加靠近 <code>npm</code> 这个轮子工厂，对于我们进行大调库也更加的方便。当然，因为 Javascript 令人**的设计，也会收获更加酸爽的 Debug 体验。</s></p><p>本文我们侧重介绍如何配置一个 Express 项目，并完成一个最基本的与后端数据库通信的增删查改功能.</p><a id="more"></a><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><ul><li>JavaScript 语言</li><li>RESTful API 的有关知识（事实上后文也有介绍） <a href="https://www.runoob.com/nodejs/nodejs-restful-api.html">https://www.runoob.com/nodejs/nodejs-restful-api.html</a></li><li>（至少一种）数据库的使用操作<ul><li>可以是直接使用 SQL 语句操作</li><li>可以是使用 ORM 来操作</li></ul></li></ul><h2 id="初始化项目"><a href="#初始化项目" class="headerlink" title="初始化项目"></a>初始化项目</h2><p>搜索结果可以找到的大多数编写教程均是基于 <code>CommonJS</code> 规范（以 <code>require</code> 和 <code>define</code> 为特点），而 <code>Node.js</code> 则推出了基于语言层面支持的 <code>ES6 Module</code> 规范（以 <code>import</code> 和 <code>export</code> 为特点）。后者必将成为今后较为常用的编写规范。如果想了解更多关于 Javascript 模块化开发的有关知识，可以参考本文初稿作者的<a href="https://c7w.tech/javascript-module-dev/">这篇博客</a>。</p><p>同样，这里我们采用更为广泛使用的 <code>yarn</code> 来进行包管理。其安装在 Node.js 简介及 npm 的介绍中已给出，这里我们不再赘述。</p><p>首先我们先新建一个项目。（这里采用 Windows 的 CMD 进行操作，Linux 的操作类似，下同）</p><pre class="language-bash" data-language="bash"><code class="language-bash">D:<span class="token punctuation">\</span>Coding<span class="token operator">></span>cd D:<span class="token punctuation">\</span>Coding<span class="token punctuation">\</span>MyDashBoardBackendD:<span class="token punctuation">\</span>Coding<span class="token punctuation">\</span>MyDashBoardBackend<span class="token operator">></span>yarn init<span class="token function">yarn</span> init v1.22.17question name <span class="token punctuation">(</span>MyDashBoardBackend<span class="token punctuation">)</span>:question version <span class="token punctuation">(</span><span class="token number">1.0</span>.0<span class="token punctuation">)</span>:question description: A sample backend project.question entry point <span class="token punctuation">(</span>index.js<span class="token punctuation">)</span>:question repository url:question author:question license <span class="token punctuation">(</span>MIT<span class="token punctuation">)</span>:question private:success Saved package.jsonDone <span class="token keyword">in</span> <span class="token number">20</span>.93s.</code></pre><p>然后我们安装 express 模块：</p><pre class="language-bash" data-language="bash"><code class="language-bash"><span class="token function">yarn</span> <span class="token function">add</span> express</code></pre><p>为了使用 <code>ES6 Module</code> 规范，我们配置 <code>package.json</code>，在其中加入 <code>&quot;type&quot;: &quot;module&quot;</code> 字段：</p><pre class="language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>  <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"MyDashBoardBackend"</span><span class="token punctuation">,</span>  <span class="token property">"version"</span><span class="token operator">:</span> <span class="token string">"1.0.0"</span><span class="token punctuation">,</span>  <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"module"</span><span class="token punctuation">,</span>  <span class="token property">"description"</span><span class="token operator">:</span> <span class="token string">"A sample backend project."</span><span class="token punctuation">,</span>  <span class="token property">"main"</span><span class="token operator">:</span> <span class="token string">"index.js"</span><span class="token punctuation">,</span>  <span class="token property">"license"</span><span class="token operator">:</span> <span class="token string">"MIT"</span><span class="token punctuation">,</span>  <span class="token property">"dependencies"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>    <span class="token property">"express"</span><span class="token operator">:</span> <span class="token string">"^4.17.2"</span>  <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span></code></pre><p>然后，我们在根目录新建 <code>index.js</code>，写入如下内容：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token keyword">import</span> express <span class="token keyword">from</span> <span class="token string">"express"</span><span class="token punctuation">;</span><span class="token keyword">const</span> app <span class="token operator">=</span> <span class="token function">express</span><span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">'Hello, baka c7w!'</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span><span class="token function">listen</span><span class="token punctuation">(</span><span class="token number">3000</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>然后我们就可以运行 <code>node index.js</code>，然后前往浏览器访问 <code>http://localhost:3000/</code>，便可以看到我们输出的欢迎信息。</p><p>若是感觉如此逼格还不够高，不要紧，我们可以继续进行一些配置：</p><p>我们可以继续修改 <code>package.json</code>，向其中加入使用 <code>yarn start</code> 开启服务端的配置：</p><pre class="language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>  <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"MyDashBoardBackend"</span><span class="token punctuation">,</span>  <span class="token property">"version"</span><span class="token operator">:</span> <span class="token string">"1.0.0"</span><span class="token punctuation">,</span>  <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"module"</span><span class="token punctuation">,</span>  <span class="token property">"scripts"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>    <span class="token property">"start"</span><span class="token operator">:</span> <span class="token string">"node index.js"</span>  <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>  <span class="token property">"description"</span><span class="token operator">:</span> <span class="token string">"A sample backend project."</span><span class="token punctuation">,</span>  <span class="token property">"main"</span><span class="token operator">:</span> <span class="token string">"index.js"</span><span class="token punctuation">,</span>  <span class="token property">"license"</span><span class="token operator">:</span> <span class="token string">"MIT"</span><span class="token punctuation">,</span>  <span class="token property">"dependencies"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>    <span class="token property">"express"</span><span class="token operator">:</span> <span class="token string">"^4.17.2"</span>  <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span></code></pre><p>之后我们就可以使用 <code>yarn start</code> 来开启服务端了。</p><h2 id="路由-Routing"><a href="#路由-Routing" class="headerlink" title="路由 Routing"></a>路由 Routing</h2><p>没错，相信你已经猜到了，我们后端网站的路由便是主要通过 <code>app.get</code> 和 <code>app.post</code> 两个方法来定义。事实上，如果你对 HTTP 请求方法了解的更多些的话，我们可以使用以下方法：</p><ul><li><code>app.get()</code></li><li><code>app.post()</code></li><li><code>app.put()</code></li><li><code>app.delete()</code></li></ul><p>事实上还有更多，这里我们不再一一列出，如欲了解可以借助<a href="https://expressjs.com/en/4x/api.html#app.METHOD">官方的 Docs</a>。</p><p>我们这里给出一些示例写法：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token keyword">import</span> express <span class="token keyword">from</span> <span class="token string">"express"</span><span class="token punctuation">;</span><span class="token keyword">const</span> app <span class="token operator">=</span> <span class="token function">express</span><span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">'Hello, baka c7w!'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">'/item'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">'GET method to /item'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span><span class="token function">post</span><span class="token punctuation">(</span><span class="token string">'/item'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">'POST method to /item'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token comment">// Regular Expression!</span>app<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">'/item/*'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    console<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span>req<span class="token punctuation">.</span>path<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// `/item/1`</span>    console<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span>req<span class="token punctuation">.</span>params<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// undefined</span>    res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">"Item/*"</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token comment">// Variables!</span>app<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">'/item2/:item/'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    console<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span>req<span class="token punctuation">.</span>path<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// `/item2/1`</span>    console<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span>req<span class="token punctuation">.</span>params<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// &#123; item: '1' &#125;</span>    res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">"Item/*"</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token comment">// Even ReExp + Variables!</span>app<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"/item3/:item(\\d+)"</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    console<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span>req<span class="token punctuation">.</span>path<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// `/item3/1`</span>    console<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span>req<span class="token punctuation">.</span>params<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// &#123; item: '1' &#125;</span>    res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">"Item/*"</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span><span class="token function">listen</span><span class="token punctuation">(</span><span class="token number">3000</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h3 id="Route-Handler"><a href="#Route-Handler" class="headerlink" title="Route Handler"></a>Route Handler</h3><p>我们可以尝试考虑以下情景：我们要根据用户身份（这里做简要简化，假设用户身份通过 Routing 传入），分别展示不同的页面。事实上这种情景很常见，比如一个网站的管理员登入博客看到的应该是管理页面，而登录作者看到的应该是写作页面，普通用户看到的就是浏览页面。但是这些页面中又会有一些耦合的元素。于是，我们能不能采用 OOP 课程中策略模式的思想来解决这个问题呢？</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token keyword">const</span> <span class="token function-variable function">logger</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res<span class="token punctuation">,</span> next</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span> <span class="token comment">// Logger 部件，记录用</span>    console<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span>req<span class="token punctuation">.</span>params<span class="token punctuation">.</span>user <span class="token operator">+</span> <span class="token string">' tried to visit...'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token keyword">const</span> <span class="token function-variable function">main</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res<span class="token punctuation">,</span> next</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>req<span class="token punctuation">.</span>params<span class="token punctuation">.</span>user <span class="token operator">==</span> <span class="token string">"c7w"</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        res<span class="token punctuation">.</span>result <span class="token operator">=</span> <span class="token string">"Welcome!&lt;br />"</span><span class="token punctuation">;</span>        <span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>        res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">"Permission Denied"</span><span class="token punctuation">)</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token keyword">const</span> <span class="token function-variable function">footer</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    res<span class="token punctuation">.</span>result <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token string">'&lt;br />&lt;br />'</span> <span class="token operator">+</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>res<span class="token punctuation">.</span>result<span class="token punctuation">)</span><span class="token punctuation">&#125;</span>app<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"/user/:user"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>logger<span class="token punctuation">,</span> main<span class="token punctuation">,</span> footer<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p>事实上我们可以利用这种 Handler “数组”来定义处理一个请求的先后顺序。如果在前面的某个 Handler 调用了 <code>next()</code>，那么便会执行下一个 <code>Handler</code>。</p><h2 id="req-与-res"><a href="#req-与-res" class="headerlink" title="req 与 res"></a>req 与 res</h2><p>这里我们介绍下 <code>req</code> 和 <code>res</code> 两个参数的主要属性和方法。</p><h3 id="req"><a href="#req" class="headerlink" title="req"></a><code>req</code></h3><div class="table-container"><table><thead><tr><th>Property</th><th>Description</th></tr></thead><tbody><tr><td>req.query</td><td>在请求后以 <code>?</code> 和 <code>&amp;</code> 连接的键值对</td></tr><tr><td>req.body</td><td>请求体的内容</td></tr><tr><td>req.cookies</td><td>Cookies 中的内容</td></tr></tbody></table></div><p>更多详见：<a href="https://expressjs.com/en/4x/api.html#req">https://expressjs.com/en/4x/api.html#req</a></p><h3 id="res"><a href="#res" class="headerlink" title="res"></a><code>res</code></h3><div class="table-container"><table><thead><tr><th>Method</th><th>Description</th></tr></thead><tbody><tr><td><a href="https://expressjs.com/en/4x/api.html#res.download">res.download()</a></td><td>Prompt a file to be downloaded.</td></tr><tr><td><a href="https://expressjs.com/en/4x/api.html#res.end">res.end()</a></td><td>End the response process.</td></tr><tr><td><a href="https://expressjs.com/en/4x/api.html#res.json">res.json()</a></td><td>Send a JSON response.</td></tr><tr><td><a href="https://expressjs.com/en/4x/api.html#res.redirect">res.redirect()</a></td><td>Redirect a request.</td></tr><tr><td><a href="https://expressjs.com/en/4x/api.html#res.render">res.render()</a></td><td>Render a view template.</td></tr><tr><td><a href="https://expressjs.com/en/4x/api.html#res.send">res.send()</a></td><td>Send a response of various types.</td></tr><tr><td><a href="https://expressjs.com/en/4x/api.html#res.sendFile">res.sendFile()</a></td><td>Send a file as an octet stream.</td></tr><tr><td><a href="https://expressjs.com/en/4x/api.html#res.sendStatus">res.sendStatus()</a></td><td>Set the response status code and send its string representation as the response body.</td></tr></tbody></table></div><p>更多详见：<a href="https://expressjs.com/en/4x/api.html#res">https://expressjs.com/en/4x/api.html#res</a></p><h2 id="Middleware"><a href="#Middleware" class="headerlink" title="Middleware"></a>Middleware</h2><p>Middleware（中间件函数）的概念其实很好理解。就像是我们上面举的那个例子，<code>logger</code> 和 <code>main</code> 就可以理解成是 Middleware functions。中间件函数是带有了 <code>req, res, next</code> 为签名的函数，在 Express 处理请求的时候，事实上会将某个地址对应的路由的所有中间件组织成一个类似链表的结构，随着 <code>next()</code> 的调用在中间件间顺序执行。而且，中间件都是有修改 <code>req</code> 和 <code>res</code> 的所有属性的能力的。</p><p>一个需要注意的点是，如果中间件函数没有使用类似于 <code>res.send()</code> 的方法将一个请求返回的话，必须要调用 <code>next()</code> 函数，不然即使这个中间件函数执行到末尾，也不会自动跳转。这就会导致请求“假死”的现象。</p><h3 id="全局-Middleware"><a href="#全局-Middleware" class="headerlink" title="全局 Middleware"></a>全局 Middleware</h3><p>使用 <code>app.use([path], &lt;middleware function&gt;)</code> 我们可以添加供全局使用的 Middleware 函数（Application-level middleware），示例如下：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token keyword">import</span> express <span class="token keyword">from</span> <span class="token string">"express"</span><span class="token punctuation">;</span><span class="token keyword">const</span> app <span class="token operator">=</span> <span class="token function">express</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">const</span> <span class="token function-variable function">logger</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res<span class="token punctuation">,</span> next</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span> <span class="token comment">// Logger 部件，记录用</span>    console<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span><span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">[</span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">$&#123;</span><span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token interpolation-punctuation punctuation">&#125;</span></span><span class="token string">] </span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">$&#123;</span>req<span class="token punctuation">.</span>method<span class="token interpolation-punctuation punctuation">&#125;</span></span><span class="token string"> </span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">$&#123;</span>req<span class="token punctuation">.</span>originalUrl<span class="token interpolation-punctuation punctuation">&#125;</span></span><span class="token template-punctuation string">`</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span>app<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">'Hello, baka c7w!'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">'/item'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">'GET method to /item'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span><span class="token function">post</span><span class="token punctuation">(</span><span class="token string">'/item'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">'POST method to /item'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">'/item/*'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    console<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span>req<span class="token punctuation">.</span>path<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// `/item/1`</span>    console<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span>req<span class="token punctuation">.</span>params<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// undefined</span>    res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">"Item/*"</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">'/item2/:item/'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    console<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span>req<span class="token punctuation">.</span>path<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// `/item2/1`</span>    console<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span>req<span class="token punctuation">.</span>params<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// &#123; item: '1' &#125;</span>    res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">"Item/*"</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"/item3/:item(\\d+)"</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token parameter">req<span class="token punctuation">,</span> res</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    console<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span>req<span class="token punctuation">.</span>path<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// `/item3/1`</span>    console<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span>req<span class="token punctuation">.</span>params<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// &#123; item: '1' &#125;</span>    res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">"Item/*"</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span><span class="token function">use</span><span class="token punctuation">(</span>logger<span class="token punctuation">)</span>app<span class="token punctuation">.</span><span class="token function">listen</span><span class="token punctuation">(</span><span class="token number">3000</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><pre class="language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>Tue Feb 08 <span class="token number">2022</span> <span class="token number">22</span>:16:18 GMT+0800 <span class="token punctuation">(</span>China Standard Time<span class="token punctuation">)</span><span class="token punctuation">]</span> GET /user/123<span class="token punctuation">[</span>Tue Feb 08 <span class="token number">2022</span> <span class="token number">22</span>:16:20 GMT+0800 <span class="token punctuation">(</span>China Standard Time<span class="token punctuation">)</span><span class="token punctuation">]</span> GET /user/123<span class="token punctuation">[</span>Tue Feb 08 <span class="token number">2022</span> <span class="token number">22</span>:16:22 GMT+0800 <span class="token punctuation">(</span>China Standard Time<span class="token punctuation">)</span><span class="token punctuation">]</span> GET /user/123/123</code></pre><h3 id="异常处理-Middleware"><a href="#异常处理-Middleware" class="headerlink" title="异常处理 Middleware"></a>异常处理 Middleware</h3><p>我们可以定义处理异常的中间件函数，方法如下：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript">app<span class="token punctuation">.</span><span class="token function">use</span><span class="token punctuation">(</span><span class="token keyword">function</span> <span class="token punctuation">(</span><span class="token parameter">err<span class="token punctuation">,</span> req<span class="token punctuation">,</span> res<span class="token punctuation">,</span> next</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  console<span class="token punctuation">.</span><span class="token function">error</span><span class="token punctuation">(</span>err<span class="token punctuation">.</span>stack<span class="token punctuation">)</span>  res<span class="token punctuation">.</span><span class="token function">status</span><span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token string">'Sorry, but fatal error occurred meanwhile.'</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span></code></pre><h3 id="内置-Middleware"><a href="#内置-Middleware" class="headerlink" title="内置 Middleware"></a>内置 Middleware</h3><p>Express 内置了以下中间件：</p><ul><li><a href="https://expressjs.com/en/4x/api.html#express.static">express.static</a> 用于提供静态文件，比如图片，文件等等</li><li><a href="https://expressjs.com/en/4x/api.html#express.json">express.json</a> 将 req.body 处理为 json (Available with Express 4.16.0+)</li><li><a href="https://expressjs.com/en/4x/api.html#express.urlencoded">express.urlencoded</a></li></ul><p>对于 POST 请求，我们推荐使用后两个中间件。</p><h2 id="CRUD-的实现"><a href="#CRUD-的实现" class="headerlink" title="CRUD 的实现"></a>CRUD 的实现</h2><p>首先我们先简单地介绍一下 RESTful API 是什么。</p><p>RESTful API 是目前比较成熟的一套互联网应用程序的 API 设计理论。可以参考 <a href="https://www.ruanyifeng.com/blog/2014/05/restful_api.html。">https://www.ruanyifeng.com/blog/2014/05/restful_api.html。</a></p><p>TL; DR: 按照一定约定俗成的设计，对于我们所关心的涉及的资源，进行增删查改的操作。RESTful API 更多的是关注在“设计”这一层面。</p><p>作为今天的教程，我们只要理解，我们设计出一个后端，能让它和我们的数据库连接，完成增删查改（Create, Read, Update, Delete）就可以了。</p><p>作为轮子工厂，我们经过简单的搜索就能找到 JavaScript 与 mysql 连接的工具，其使用教程可以<a href="https://www.runoob.com/nodejs/nodejs-mysql.html">见此</a>。</p><p>直接撰写 SQL 语句固然在应用上是高效的，但是切换编程语言或者找一些自动生成 SQL 查询语句的工具也会降低我们的编程效率。在我们<strong>并不是很在意查询效率的前提下</strong>，我们不禁回忆起 Django 中用类撰写 Model 的模式，当时可是十分节省我们的力气。</p><p>事实上，这也是一种十分常见的设计模式，叫做 ORM（Object–relational mapping）。之前我们可以将关系型数据库中的一个表看做是一张 Excel 表，而表头规定了这个表的每行记录所应该有的属性。而如果我们把这张表中的表头，视为是一个类在规定它应该具有的属性的话，那么这张表的每行记录，事实上就是这个类所实例化出来的对象。这正是 Django 的 db.models 所采用的设计模式。</p><p>再一次，作为轮子工厂，只需要简单的搜索，我们便能找到实现与数据库之间 ORM 设计的库，这里我们以 <a href="https://sequelize.org/v7/">Sequelize</a> 为例。这里我们采用便携的 <code>sqlite3</code> 作为我们的数据库。</p><p>实现后的简单项目归档于：<a href="https://github.com/c7w/MyDashboardBackend">https://github.com/c7w/MyDashboardBackend</a></p><h2 id="后续拓展"><a href="#后续拓展" class="headerlink" title="后续拓展"></a>后续拓展</h2><ul><li>了解更多 ExpressJS 的中间件</li><li>了解 ExpressJS 的模板渲染机制</li><li>换用其他数据库尝试，包括 fs（本地存储），MySQL，以及非关系型数据库 PostgreSQL</li></ul><p>可以应用 ExpressJS 的课程：</p><ul><li>《软件工程》</li></ul><h2 id="资源链接"><a href="#资源链接" class="headerlink" title="资源链接"></a>资源链接</h2><ul><li>ExpressJS 官网 <a href="https://expressjs.com/">https://expressjs.com/</a></li><li>ExpressJS 中文网 <a href="https://expressjs.com/zh-cn/">https://expressjs.com/zh-cn/</a></li><li>菜鸟教程 <a href="https://www.runoob.com/nodejs/nodejs-express-framework.html">https://www.runoob.com/nodejs/nodejs-express-framework.html</a></li><li>MDN 教程 <a href="https://developer.mozilla.org/zh-CN/docs/Learn/Server-side/Express_Nodejs/skeleton_website">https://developer.mozilla.org/zh-CN/docs/Learn/Server-side/Express_Nodejs/skeleton_website</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;Express 是一个简洁而灵活的 Node.js Web 应用框架, 提供了一系列强大特性帮助你创建各种 Web 应用，和丰富的 HTTP 工具。&lt;/p&gt;
&lt;p&gt;使用 Express 可以快速地搭建一个完整功能的网站，但是，我们一般更倾向于使用 Express 来快速搭建&lt;strong&gt;网站后端&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;注意，这里我们将网站分为前端和后端，事实上与我们在《程序设计训练》课程中对于使用 Django 来搭建网站的方式不同。Django 的页面渲染是&lt;strong&gt;服务器端渲染&lt;/strong&gt;（Server-side Rendering），也就是说，在收到用户发来的请求后，服务器端按照设计的逻辑读取相应的页面模板，在完成页面渲染（也就是在页面模板的对应处填充对应字段）后，将渲染后的 HTML 页面直接发给用户。&lt;/p&gt;
&lt;p&gt;而这里我们将网站分为“前端”和“后端”，这种设计模式和上述服务器端渲染有本质的区别，我们一般称为&lt;strong&gt;客户端渲染&lt;/strong&gt;（Client-side Rendering）。其运作模式是，网站提供服务器直接将未渲染的 HTML 模板（我们称为“前端代码”）发送给用户，而这模板中包含了类似于 &lt;code&gt;fetch&lt;/code&gt; 的函数，可以在浏览器将其渲染时向我们的“后端”发送请求。“后端”在收到请求后，一般以 Json 格式返回所请求的数据，前端再通过 Javascript 脚本将收到的数据渲染在页面上。&lt;/p&gt;
&lt;p&gt;在《软件工程》课程中我们推荐使用后者这种设计模式，即进行前后端分离。虽然我们也可以继续利用 Django 来作为后端，但是我们这里给大家提供一种业界也很常用的选项 —— Express。其优点在于，相比于 Django 而言，其编写起来更加方便，也更加快捷。&lt;s&gt;而且，后端更加靠近 &lt;code&gt;npm&lt;/code&gt; 这个轮子工厂，对于我们进行大调库也更加的方便。当然，因为 Javascript 令人**的设计，也会收获更加酸爽的 Debug 体验。&lt;/s&gt;&lt;/p&gt;
&lt;p&gt;本文我们侧重介绍如何配置一个 Express 项目，并完成一个最基本的与后端数据库通信的增删查改功能.&lt;/p&gt;</summary>
    
    
    
    <category term="技术" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="技术/后端" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF-%E5%90%8E%E7%AB%AF/"/>
    
    
    <category term="ExpressJS" scheme="https://www.c7w.tech/tags/ExpressJS/"/>
    
  </entry>
  
  <entry>
    <title>JavaScript 模块化进化论</title>
    <link href="https://www.c7w.tech/javascript-module-dev/"/>
    <id>https://www.c7w.tech/javascript-module-dev/</id>
    <published>2022-02-06T15:48:48.000Z</published>
    <updated>2022-02-07T13:48:41.795Z</updated>
    
    <content type="html"><![CDATA[<p>什么是模块化开发？我们可以类比 C++ 中的面向对象和 Java 中的类，我们的做法是，为了避免因为项目过大而导致变量名发生冲突，同时为了便于解耦合的实现，我们将具有某个特定功能的一些属性和方法组织为一个类，单独放在一个文件之中。</p><p>事实上，在前端开发中，我们的习惯是，要么将用到的模块全部打包，要么通过 CDN 引入。前者通过 Node.js 实现，而后者则直接将导出的模块挂在在 <code>window</code> 下，也即成为全局变量，这也就是早期 JavaScript 的问题，通过全局变量解决一切问题。</p><p>本文我们梳理 JavaScript 对于项目模块化的范式的历史发展进程，以此我们在今后编写项目时提出以下建议：使用最新的 <code>ES6</code> 标准，使用 <code>Babel</code> 向前兼容。</p><a id="more"></a><h2 id="全局变量"><a href="#全局变量" class="headerlink" title="全局变量"></a>全局变量</h2><h3 id="window-对象"><a href="#window-对象" class="headerlink" title="window 对象"></a><code>window</code> 对象</h3><p>最初的时候，JavaScript 脚本之间的通信完全依靠 <code>window</code> 对象：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token comment">// config.js</span><span class="token keyword">var</span> api <span class="token operator">=</span> <span class="token string">'https://github.com/ronffy'</span><span class="token punctuation">;</span><span class="token keyword">var</span> config <span class="token operator">=</span> <span class="token punctuation">&#123;</span>  api<span class="token operator">:</span> api<span class="token punctuation">,</span><span class="token punctuation">&#125;</span></code></pre><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token comment">// utils.js</span><span class="token keyword">var</span> utils <span class="token operator">=</span> <span class="token punctuation">&#123;</span>  <span class="token function">request</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span>window<span class="token punctuation">.</span>config<span class="token punctuation">.</span>api<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span></code></pre><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token comment">// main.js</span>window<span class="token punctuation">.</span>utils<span class="token punctuation">.</span><span class="token function">request</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><pre class="language-html" data-language="html"><code class="language-html"><span class="token comment">&lt;!-- 所有 script 标签必须保证顺序正确，否则会依赖报错 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>./js/config.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>./js/utils.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>./js/main.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span></code></pre><h3 id="IIFE"><a href="#IIFE" class="headerlink" title="IIFE"></a>IIFE</h3><p><strong>IIFE</strong>（立即调用函数表达式）是一个在定义时就会立即执行的 JavaScript 函数。</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token punctuation">(</span><span class="token keyword">function</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    statements<span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token punctuation">(</span><span class="token keyword">function</span> <span class="token punctuation">(</span><span class="token parameter">root</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  <span class="token keyword">var</span> api <span class="token operator">=</span> <span class="token string">'https://github.com/ronffy'</span><span class="token punctuation">;</span>  <span class="token keyword">var</span> config <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    api<span class="token operator">:</span> api<span class="token punctuation">,</span>  <span class="token punctuation">&#125;</span><span class="token punctuation">;</span>  root<span class="token punctuation">.</span>config <span class="token operator">=</span> config<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">(</span>window<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>IIFE 的出现，使全局变量的声明数量得到了有效的控制。</p><h2 id="AMD-CMD"><a href="#AMD-CMD" class="headerlink" title="AMD / CMD"></a>AMD / CMD</h2><p>随着前端业务增重，代码越来越复杂，靠全局变量通信的方式开始捉襟见肘，前端急需一种更清晰、更简单的处理代码依赖的方式，将 JS 模块化的实现及规范陆续出现，其中被应用较广的模块规范有 AMD 和 CMD。</p><p>面对一种模块化方案，我们首先要了解的是：1. 如何导出接口；2. 如何导入接口。</p><h3 id="AMD-RequireJS"><a href="#AMD-RequireJS" class="headerlink" title="AMD + RequireJS"></a>AMD + RequireJS</h3><p><code>AMD</code>(<code>Asynchronous Module Definition</code>，异步加载模块定义)规范，一个单独的文件就是一个模块。它采用异步方式加载模块，模块的加载不影响它后面语句的运行。</p><p>这里异步指的是不堵塞浏览器其他任务（<code>dom</code> 构建，<code>css</code> 渲染等），而加载内部是同步的（加载完模块后立即执行回调）。</p><p>AMD 是一种异步模块规范，<code>RequireJS</code> 是 AMD 规范的实现。官网介绍 <code>RequireJS</code>是一个 <code>js</code> 文件和模块的加载器，提供了加载和定义模块的 <code>api</code>，当在页面中引入了 <code>RequireJS</code> 之后，我们便能够在全局调用 <strong><code>define</code> 和 <code>require</code></strong>。</p><h4 id="require"><a href="#require" class="headerlink" title="require"></a><code>require</code></h4><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token function">require</span><span class="token punctuation">(</span><span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>第一个参数 [module]，是一个数组，里面的成员是要加载的模块，<code>callback</code>是加载完成后的回调函数，回调函数中参数对应数组中的成员（模块）。</p><p><code>AMD</code> 的标准中，引入模块需要用到方法 <code>require</code>，由于 <code>window</code> 对象上没定义 <code>require</code> 方法，RequireJS 这个库将其具体实现。</p><h4 id="define"><a href="#define" class="headerlink" title="define"></a><code>define</code></h4><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token function">define</span><span class="token punctuation">(</span>id<span class="token operator">?</span><span class="token punctuation">,</span> dependencies<span class="token operator">?</span><span class="token punctuation">,</span> factory<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><ul><li>id：模块的名字，如果没有提供该参数，模块的名字应该默认为模块加载器请求的指定脚本的名字</li><li>dependencies：模块的依赖，已被模块定义的模块标识的数组字面量。依赖参数是可选的，如果忽略此参数，它应该默认为 <code>[&quot;require&quot;, &quot;exports&quot;, &quot;module&quot;]</code>。然而，如果工厂方法的长度属性小于 3，加载器会选择以函数的长度属性指定的参数个数调用工厂方法。</li><li>factory：模块的工厂函数，模块初始化要执行的函数或对象。<strong>如果为函数，它应该只被执行一次。如果是对象，此对象应该为模块的输出值。</strong></li></ul><p>接下来，我们用 <code>RequireJS</code> 重构上面的项目。</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token comment">// config.js</span><span class="token function">define</span><span class="token punctuation">(</span><span class="token keyword">function</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  <span class="token keyword">var</span> api <span class="token operator">=</span> <span class="token string">'https://github.com/ronffy'</span><span class="token punctuation">;</span>  <span class="token keyword">var</span> config <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    api<span class="token operator">:</span> api<span class="token punctuation">,</span>  <span class="token punctuation">&#125;</span><span class="token punctuation">;</span>  <span class="token keyword">return</span> config<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// utils.js</span><span class="token function">define</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'./config'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">function</span><span class="token punctuation">(</span><span class="token parameter">config</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  <span class="token keyword">var</span> utils <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token function">request</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>      console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>api<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>  <span class="token punctuation">&#125;</span><span class="token punctuation">;</span>  <span class="token keyword">return</span> utils<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// main.js</span><span class="token function">require</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'./utils'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">function</span><span class="token punctuation">(</span><span class="token parameter">utils</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  utils<span class="token punctuation">.</span><span class="token function">request</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><pre class="language-html" data-language="html"><code class="language-html"><span class="token comment">&lt;!-- index.html  --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">data-main</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>./js/main<span class="token punctuation">"</span></span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>./js/require.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span></code></pre><h3 id="CMD"><a href="#CMD" class="headerlink" title="CMD"></a>CMD</h3><p>CMD 和 AMD 一样，都是 JS 的模块化规范，也主要应用于浏览器端。</p><p>AMD 是 RequireJS 在的推广和普及过程中被创造出来。</p><p>CMD 是 SeaJS 在的推广和普及过程中被创造出来。</p><p>二者的的主要区别是 CMD 推崇依赖就近，AMD 推崇依赖前置：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token comment">// AMD</span><span class="token comment">// 依赖必须一开始就写好</span><span class="token function">define</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'./utils'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">function</span><span class="token punctuation">(</span><span class="token parameter">utils</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  utils<span class="token punctuation">.</span><span class="token function">request</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// CMD</span><span class="token function">define</span><span class="token punctuation">(</span><span class="token keyword">function</span><span class="token punctuation">(</span><span class="token parameter">require</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  <span class="token comment">// 依赖可以就近书写</span>  <span class="token keyword">var</span> utils <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'./utils'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  utils<span class="token punctuation">.</span><span class="token function">request</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>AMD 也支持依赖就近，但 RequireJS 作者和官方文档都是优先推荐依赖前置写法。</p><p><strong>考虑到目前主流项目中对 AMD 和 CMD 的使用越来越少，大家对 AMD 和 CMD 有大致的认识就好，此处不再过多赘述。</strong></p><h2 id="CommonJS"><a href="#CommonJS" class="headerlink" title="CommonJS"></a>CommonJS</h2><p><code>CommonJS</code> 是一个更<strong>偏向于服务器端</strong>的规范。<code>NodeJS</code> 采用了这个规范。<code>CommonJS</code> 的一个模块就是一个脚本文件。</p><h3 id="exports-与-module-exports"><a href="#exports-与-module-exports" class="headerlink" title="exports 与 module.exports"></a><code>exports</code> 与 <code>module.exports</code></h3><p>定义一个模块导出通过 <code>exports</code> 或者 <code>module.exports</code> 挂载即可。</p><h3 id="require-1"><a href="#require-1" class="headerlink" title="require"></a><code>require</code></h3><p><code>require</code> 命令<strong>第一次加载该脚本时就会执行整个脚本，然后在内存中生成一个对象</strong>：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token punctuation">&#123;</span>  id<span class="token operator">:</span> <span class="token string">'...'</span><span class="token punctuation">,</span>  exports<span class="token operator">:</span> <span class="token punctuation">&#123;</span> <span class="token operator">...</span> <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>  loaded<span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>  <span class="token operator">...</span><span class="token punctuation">&#125;</span></code></pre><p><code>id</code> 是模块名，<code>exports</code>是该模块导出的接口，<code>loaded</code> 表示模块是否加载完毕。</p><p>以后需要用到这个模块时，就会到 <code>exports</code> 属性上取值。<strong>即使再次执行 <code>require</code> 命令，也不会再次执行该模块，而是到缓存中取值</strong>。</p><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token comment">// config.js</span><span class="token keyword">var</span> api <span class="token operator">=</span> <span class="token string">'https://github.com/ronffy'</span><span class="token punctuation">;</span><span class="token keyword">var</span> config <span class="token operator">=</span> <span class="token punctuation">&#123;</span>  api<span class="token operator">:</span> api<span class="token punctuation">,</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span>module<span class="token punctuation">.</span>exports <span class="token operator">=</span> config<span class="token punctuation">;</span><span class="token comment">// utils.js</span><span class="token keyword">var</span> config <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'./config'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">var</span> utils <span class="token operator">=</span> <span class="token punctuation">&#123;</span>  <span class="token function">request</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>api<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span>module<span class="token punctuation">.</span>exports <span class="token operator">=</span> utils<span class="token punctuation">;</span><span class="token comment">// main.js</span><span class="token keyword">var</span> utils <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'./utils'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>utils<span class="token punctuation">.</span><span class="token function">request</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span>global<span class="token punctuation">.</span>api<span class="token punctuation">)</span></code></pre><p>执行<code>node main.js</code>，<code>https://github.com/ronffy</code> 被打印了出来。</p><p>在 main.js 中打印 <code>global.api</code>，打印结果是 <code>undefined</code>。</p><p>node 用 <code>global</code> 管理全局变量，与浏览器的 <code>window</code> 类似。与浏览器不同的是，浏览器中顶层作用域是全局作用域，在顶层作用域中声明的变量都是全局变量，而 node 中顶层作用域不是全局作用域，所以在顶层作用域中声明的变量非全局变量。</p><p>注意：</p><ul><li><code>CommonJS</code> 是同步导入模块</li><li><code>CommonJS</code> 导入时，它会给你一个导入对象的副本</li><li><code>CommonJS</code> 模块不能直接在浏览器中运行，需要进行转换、打包</li></ul><p>由于 <code>CommonJS</code> 是同步加载模块，这对于服务器端不是一个问题，因为所有的模块都放在本地硬盘。等待模块时间就是硬盘读取文件时间，很小。但是，对于浏览器而言，它需要从服务器加载模块，涉及到网速，代理等原因，一旦等待时间过长，浏览器处于”假死”状态。所以在浏览器端，不适合于 <code>CommonJS</code> 规范。</p><h3 id="CommonJS-与-AMD-的对比"><a href="#CommonJS-与-AMD-的对比" class="headerlink" title="CommonJS 与 AMD 的对比"></a>CommonJS 与 AMD 的对比</h3><ol><li>CommonJS 是服务器端模块规范，AMD 是浏览器端模块规范。</li><li>CommonJS 加载模块是同步的，即执行<code>var a = require(&#39;./a.js&#39;);</code> 时，在 a.js 文件加载完成后，才执行后面的代码。AMD 加载模块是异步的，所有依赖加载完成后以回调函数的形式执行代码。</li><li>如下代码中，<code>fs</code> 和 <code>chalk</code> 都是模块，不同的是，<code>fs</code> 是 node 内置模块，<code>chalk</code> 是一个 npm 包。这两种情况在 CommonJS 中才有，AMD 不支持。</li></ol><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token keyword">var</span> fs <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'fs'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">var</span> chalk <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'chalk'</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h2 id="UMD"><a href="#UMD" class="headerlink" title="UMD"></a>UMD</h2><p><code>UMD</code> 代表通用模块定义（<code>Universal Module Definition</code>）。所谓的通用，就是兼容了 <code>CommonJS</code> 和 <code>AMD</code> 规范，这意味着无论是在 <code>CommonJS</code> 规范的项目中，还是 <code>AMD</code> 规范的项目中，都可以直接引用 <code>UMD</code> 规范的模块使用。</p><p>原理其实就是在模块中去判断全局是否存在 <code>exports</code> 和 <code>define</code>，如果存在 <code>exports</code>，那么以 <code>CommonJS</code> 的方式暴露模块，如果存在 <code>define</code> 那么以 <code>AMD</code> 的方式暴露模块:</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token punctuation">(</span><span class="token keyword">function</span> <span class="token punctuation">(</span><span class="token parameter">root<span class="token punctuation">,</span> factory</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token keyword">typeof</span> define <span class="token operator">===</span> <span class="token string">"function"</span> <span class="token operator">&amp;&amp;</span> define<span class="token punctuation">.</span>amd<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    <span class="token function">define</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"jquery"</span><span class="token punctuation">,</span> <span class="token string">"underscore"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> factory<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token keyword">typeof</span> exports <span class="token operator">===</span> <span class="token string">"object"</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    module<span class="token punctuation">.</span>exports <span class="token operator">=</span> <span class="token function">factory</span><span class="token punctuation">(</span><span class="token function">require</span><span class="token punctuation">(</span><span class="token string">"jquery"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">"underscore"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>    root<span class="token punctuation">.</span>Requester <span class="token operator">=</span> <span class="token function">factory</span><span class="token punctuation">(</span>root<span class="token punctuation">.</span>$<span class="token punctuation">,</span> root<span class="token punctuation">.</span>_<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token keyword">function</span> <span class="token punctuation">(</span><span class="token parameter">$<span class="token punctuation">,</span> _</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  <span class="token comment">// this is where I defined my module implementation</span>  <span class="token keyword">const</span> Requester <span class="token operator">=</span> <span class="token punctuation">&#123;</span> <span class="token comment">// ... &#125;;</span>  <span class="token keyword">return</span> Requester<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h2 id="ES6-Module"><a href="#ES6-Module" class="headerlink" title="ES6 Module"></a>ES6 Module</h2><p>AMD、CMD 等都是在原有 JS 语法的基础上<strong>二次封装</strong>的一些方法来解决模块化的方案，<strong>ES6 module</strong>（在很多地方被简写为 ESM）是<strong>语言层面的规范</strong>，ES6 module 旨在<strong>为浏览器和服务器提供通用的模块解决方案</strong>。</p><p><strong>长远来看，未来无论是基于 JS 的 Web 端，还是基于 node 的服务器端或桌面应用，模块规范都会统一使用 ES6 module。因此，使用 ES6 Module 规范是我们今后的开发首选。</strong></p><p><code>ES6</code> 模块是前端开发同学更为熟悉的方式，使用 <code>import</code>, <code>export</code> 关键字来进行模块输入输出。<code>ES6</code> 不再是使用闭包和函数封装的方式进行模块化，而是从语法层面提供了模块化的功能。</p><p>使用 <code>Node</code> 原生 <code>ES6</code> 模块需要将 <code>js</code> 文件后缀改成 <code>mjs</code>，或者 <code>package.json</code> “type” 字段改为 “module”，通过这种形式告知 <code>Node</code> 使用 <code>ES Module</code> 的形式加载模块。（这里我们推荐使用后者）</p><h3 id="export"><a href="#export" class="headerlink" title="export"></a><code>export</code></h3><p>方式 1：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token keyword">export</span> <span class="token keyword">const</span> prefix <span class="token operator">=</span> <span class="token string">'https://github.com'</span><span class="token punctuation">;</span><span class="token keyword">export</span> <span class="token keyword">const</span> api <span class="token operator">=</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">$&#123;</span>prefix<span class="token interpolation-punctuation punctuation">&#125;</span></span><span class="token string">/ronffy</span><span class="token template-punctuation string">`</span></span><span class="token punctuation">;</span></code></pre><p>方式 2：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token keyword">const</span> prefix <span class="token operator">=</span> <span class="token string">'https://github.com'</span><span class="token punctuation">;</span><span class="token keyword">const</span> api <span class="token operator">=</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">$&#123;</span>prefix<span class="token interpolation-punctuation punctuation">&#125;</span></span><span class="token string">/ronffy</span><span class="token template-punctuation string">`</span></span><span class="token punctuation">;</span><span class="token keyword">export</span> <span class="token punctuation">&#123;</span>  prefix<span class="token punctuation">,</span>  api<span class="token punctuation">,</span><span class="token punctuation">&#125;</span></code></pre><p>方式 1 和方式 2 只是写法不同，结果是一样的，都是把 prefix 和 api 分别导出。</p><p>方式 3（默认导出）：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token comment">// foo.js</span><span class="token keyword">export</span> <span class="token keyword">default</span> <span class="token keyword">function</span> <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token comment">// 等同于：</span><span class="token keyword">function</span> <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token keyword">export</span> <span class="token punctuation">&#123;</span>  foo <span class="token keyword">as</span> <span class="token keyword">default</span><span class="token punctuation">&#125;</span></code></pre><p>方式 4（先导入再导出）：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token keyword">export</span> <span class="token punctuation">&#123;</span> api <span class="token punctuation">&#125;</span> <span class="token keyword">from</span> <span class="token string">'./config.js'</span><span class="token punctuation">;</span><span class="token comment">// 等同于：</span><span class="token keyword">import</span> <span class="token punctuation">&#123;</span> api <span class="token punctuation">&#125;</span> <span class="token keyword">from</span> <span class="token string">'./config.js'</span><span class="token punctuation">;</span><span class="token keyword">export</span> <span class="token punctuation">&#123;</span>  api<span class="token punctuation">&#125;</span></code></pre><h3 id="import"><a href="#import" class="headerlink" title="import"></a><code>import</code></h3><p>假设我们以方式 1 和方式 2 导出了 <code>&#123;prefix: prefix, api: api&#125;</code>，那么我们可以以如下方式导入：</p><p>方式 1：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token keyword">import</span> <span class="token punctuation">&#123;</span> api <span class="token punctuation">&#125;</span> <span class="token keyword">from</span> <span class="token string">'./config.js'</span><span class="token punctuation">;</span><span class="token comment">// or</span><span class="token comment">// 配合 import 使用的 as 关键字用来为导入的接口重命名。</span><span class="token keyword">import</span> <span class="token punctuation">&#123;</span> api <span class="token keyword">as</span> myApi <span class="token punctuation">&#125;</span> <span class="token keyword">from</span> <span class="token string">'./config.js'</span><span class="token punctuation">;</span></code></pre><p>方式 2（整体导入）：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token keyword">import</span> <span class="token operator">*</span> <span class="token keyword">as</span> config <span class="token keyword">from</span> <span class="token string">'./config.js'</span><span class="token punctuation">;</span><span class="token keyword">const</span> api <span class="token operator">=</span> config<span class="token punctuation">.</span>api<span class="token punctuation">;</span></code></pre><p>方式 3（默认导出的导入）：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token comment">// foo.js</span><span class="token keyword">export</span> <span class="token keyword">const</span> conut <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">export</span> <span class="token keyword">default</span> <span class="token keyword">function</span> <span class="token function">myFoo</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token comment">// index.js</span><span class="token comment">// 默认导入的接口此处刻意命名为 cusFoo，旨在说明该命名可完全自定义。</span><span class="token keyword">import</span> cusFoo<span class="token punctuation">,</span> <span class="token punctuation">&#123;</span> count <span class="token punctuation">&#125;</span> <span class="token keyword">from</span> <span class="token string">'./foo.js'</span><span class="token punctuation">;</span><span class="token comment">// 等同于：</span><span class="token keyword">import</span> <span class="token punctuation">&#123;</span> <span class="token keyword">default</span> <span class="token keyword">as</span> cusFoo<span class="token punctuation">,</span> count <span class="token punctuation">&#125;</span> <span class="token keyword">from</span> <span class="token string">'./foo.js'</span><span class="token punctuation">;</span></code></pre><p><code>export default</code> 导出的接口，可以使用 <code>import name from &#39;module&#39;</code> 导入。这种方式，使导入默认接口很便捷。</p><p>方式 4（整体加载）：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token keyword">import</span> <span class="token string">'./config.js'</span><span class="token punctuation">;</span></code></pre><p>这样会加载整个 config.js 模块，但未导入该模块的任何接口。</p><p>方式 5（动态加载模块）：</p><p>上面介绍了 ES6 module 各种导入接口的方式，但有一种场景未被涵盖：动态加载模块。比如用户点击某个按钮后才弹出弹窗，弹窗里功能涉及的模块的代码量比较重，所以这些相关模块如果在页面初始化时就加载，实在浪费资源，<code>import()</code> 可以解决这个问题，从语言层面实现模块代码的按需加载。</p><p>ES6 module 在处理以上几种导入模块接口的方式时都是编译时处理，所以 <code>import</code> 和 <code>export</code> 命令只能用在模块的顶层，以下方式都会报错：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token comment">// 报错</span><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token comment">/* ... */</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  <span class="token keyword">import</span> <span class="token punctuation">&#123;</span> api <span class="token punctuation">&#125;</span> <span class="token keyword">from</span> <span class="token string">'./config.js'</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span><span class="token comment">// 报错</span><span class="token keyword">function</span> <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  <span class="token keyword">import</span> <span class="token punctuation">&#123;</span> api <span class="token punctuation">&#125;</span> <span class="token keyword">from</span> <span class="token string">'./config.js'</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span><span class="token comment">// 报错</span><span class="token keyword">const</span> modulePath <span class="token operator">=</span> <span class="token string">'./utils'</span> <span class="token operator">+</span> <span class="token string">'/api.js'</span><span class="token punctuation">;</span><span class="token keyword">import</span> modulePath<span class="token punctuation">;</span></code></pre><p>使用 <code>import()</code> 实现按需加载：</p><pre class="language-javascript" data-language="javascript"><code class="language-javascript"><span class="token keyword">function</span> <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  <span class="token keyword">import</span><span class="token punctuation">(</span><span class="token string">'./config.js'</span><span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token function">then</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token parameter"><span class="token punctuation">&#123;</span> api <span class="token punctuation">&#125;</span></span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">&#123;</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token keyword">const</span> modulePath <span class="token operator">=</span> <span class="token string">'./utils'</span> <span class="token operator">+</span> <span class="token string">'/api.js'</span><span class="token punctuation">;</span><span class="token keyword">import</span><span class="token punctuation">(</span>modulePath<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>注意，在浏览器中加载 ES6 模块的时候，我们需要使用：</p><pre class="language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>module<span class="token punctuation">"</span></span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>index.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span></code></pre><p>但是，对于加载外部模块，需要注意：</p><ul><li>代码是在模块作用域之中运行，而不是在全局作用域运行。<strong>模块内部的顶层变量，外部不可见</strong></li><li>模块脚本自动采用严格模式，不管有没有声明 <code>use strict</code></li><li>模块之中，可以使用 <code>import</code> 命令加载其他模块（.js 后缀不可省略，需要提供绝对 URL 或相对 URL），也可以使用 <code>export</code> 命令输出对外接口</li><li><strong>模块之中，顶层的 <code>this</code> 关键字返回 <code>undefined</code>，而不是指向 <code>window</code></strong>。也就是说，在模块顶层使用 <code>this</code> 关键字，是无意义的</li><li><strong>同一个模块如果加载多次，将只执行一次</strong></li></ul><h3 id="ES6-Module-与-CommonJS-的区别"><a href="#ES6-Module-与-CommonJS-的区别" class="headerlink" title="ES6 Module 与 CommonJS 的区别"></a>ES6 Module 与 CommonJS 的区别</h3><ul><li><code>CommonJS</code> 输出的是一个<strong>值的拷贝</strong>，ES6 模块输出的是<strong>值的引用</strong>,加载的时候会做静态优化</li><li><code>CommonJS</code> 模块是<strong>运行时加载</strong>确定输出接口，ES6 模块是<strong>编译时</strong>确定输出接口</li></ul><h2 id="Babel"><a href="#Babel" class="headerlink" title="Babel"></a>Babel</h2><p>目前，无论是浏览器端还是 node，<strong>都没有完全原生支持 ES6 module</strong>，如果想使用 ES6 module ，可借助 <a href="https://link.segmentfault.com/?enc=NPnBue71LLC14ip6TZXbng%3D%3D.bbpSMgal9YqIDxlkVk1c1BQhJYiGJYf2ZYbUth7aOkE%3D">babel</a> 等编译器。</p><blockquote><p> Babel 是一个 JavaScript 编译器。</p><p>今天就开始使用下一代的 JavaScript 语法编程吧！</p><p><img src="https://s2.loli.net/2022/02/07/lm5dWXcRirIC8JH.png" alt="image-20220207214422726"></p><p><img src="https://s2.loli.net/2022/02/07/uSzJEKP8rBGV24T.png" alt="image-20220207214437008"></p><p>简单来说，可以理解成是编译时替换的一种 polyfill.</p></blockquote><p>Babel is a toolchain that is mainly used to convert ECMAScript 2015+ code into a backwards compatible version of JavaScript in current and older browsers or environments. </p><p>Here are the main things Babel can do for you:</p><ul><li>Transform syntax</li><li>Polyfill features that are missing in your target environment (through a third-party polyfill such as core-js)</li><li>Source code transformations (codemods)</li><li>And more! (check out these videos for inspiration)</li></ul><p>配置方法：<a href="https://babeljs.io/setup#installation">https://babeljs.io/setup#installation</a></p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://segmentfault.com/a/1190000023711059">https://segmentfault.com/a/1190000023711059</a></li><li><a href="https://segmentfault.com/a/1190000039375332">https://segmentfault.com/a/1190000039375332</a></li><li><a href="https://juejin.cn/post/6844904080955932680">https://juejin.cn/post/6844904080955932680</a></li><li><a href="http://nodejs.cn/api/modules.html">http://nodejs.cn/api/modules.html</a></li><li><a href="http://nodejs.cn/api/esm.html">http://nodejs.cn/api/esm.html</a></li><li><a href="https://docs.net9.org/languages/node.js/">https://docs.net9.org/languages/node.js/</a></li><li><a href="https://babeljs.io/docs/en/index.html">https://babeljs.io/docs/en/index.html</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;什么是模块化开发？我们可以类比 C++ 中的面向对象和 Java 中的类，我们的做法是，为了避免因为项目过大而导致变量名发生冲突，同时为了便于解耦合的实现，我们将具有某个特定功能的一些属性和方法组织为一个类，单独放在一个文件之中。&lt;/p&gt;
&lt;p&gt;事实上，在前端开发中，我们的习惯是，要么将用到的模块全部打包，要么通过 CDN 引入。前者通过 Node.js 实现，而后者则直接将导出的模块挂在在 &lt;code&gt;window&lt;/code&gt; 下，也即成为全局变量，这也就是早期 JavaScript 的问题，通过全局变量解决一切问题。&lt;/p&gt;
&lt;p&gt;本文我们梳理 JavaScript 对于项目模块化的范式的历史发展进程，以此我们在今后编写项目时提出以下建议：使用最新的 &lt;code&gt;ES6&lt;/code&gt; 标准，使用 &lt;code&gt;Babel&lt;/code&gt; 向前兼容。&lt;/p&gt;</summary>
    
    
    
    <category term="技术" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="技术/JavaScript" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF-JavaScript/"/>
    
    
    <category term="JavaScript" scheme="https://www.c7w.tech/tags/JavaScript/"/>
    
  </entry>
  
  <entry>
    <title>爬取《雨课堂》慕课字幕 Tsinghua MOOC Caption Crawler</title>
    <link href="https://www.c7w.tech/yuketang-caption-crawler/"/>
    <id>https://www.c7w.tech/yuketang-caption-crawler/</id>
    <published>2022-01-29T16:03:46.000Z</published>
    <updated>2022-01-29T16:04:25.324Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2022/01/30/nkI5B9DcPQzX3Us.png" alt="image-20220130000139599"></p><p>GitHub Repo: <a href="https://github.com/c7w/TsinghuaMoocCaptionCrawler">https://github.com/c7w/TsinghuaMoocCaptionCrawler</a></p><p>Blog: <a href="https://c7w.tech/yuketang-caption-crawler/">https://c7w.tech/yuketang-caption-crawler/</a></p><a id="more"></a><h2 id="爬取过程"><a href="#爬取过程" class="headerlink" title="爬取过程"></a>爬取过程</h2><h3 id="乱抓"><a href="#乱抓" class="headerlink" title="乱抓"></a>乱抓</h3><ul><li><strong>利用 Break on change 查看脚本运行状况</strong></li></ul><p>首先自然是取字幕所在的那个 xt-caption 元素，然后打上 Break on change.</p><blockquote><p>在 Javascript 调试中，我们经常会使用到断点调试。</p><p>其实，在 DOM 结构的调试中，我们也可以使用断点方法，这就是 DOM Breakpoint（DOM 断点）。</p><p>具体的使用方法：</p><p>在 Chrome 浏览器中，打开开发者工具，先选中一个页面元素，然后点击鼠标右键，依次点击菜单中的 “Break on …” —— 勾选 “Attributes modifications”。</p><p>刷新页面，当该元素的属性发生变化时，就会暂停脚本的执行，并且定位到改变发生的地方。</p><p>除了可以监视 DOM 元素本身的属性变化，Chrome 还可以监视其子元素的变化，以及何时元素被删除。</p></blockquote><p><img src="https://s2.loli.net/2022/01/29/xYiujWzwTfM7mIv.png" alt="image-20220129222222643"></p><ul><li><strong>查看调用栈</strong></li></ul><p>然后是当 Trigger 了字幕更改 Event 之后，逐个检查这里的调用栈。</p><p><img src="https://s2.loli.net/2022/01/27/e9qdIOvc2butLP3.png" alt="image-20220127155350265"></p><p>逐级查看后，这里（页面加载 caption 属性的时候）看起来像是在发可疑的请求，然后找到了一个地址：</p><p><img src="https://s2.loli.net/2022/01/27/NoOutDYEpwHPzy3.png" alt="image-20220127155631381"></p><p>然后在 HTML 里面全文检索竟然找到了一样的地址。于是我们就得到了我们的第一个关键词 <code>subtitle_parse</code>。</p><p><img src="https://s2.loli.net/2022/01/27/HdU58pV4NkJyASC.png" alt="image-20220127155810865"></p><ul><li><strong>查看字幕源数据</strong></li></ul><p>打开这个网页，发现里面就是纯字母数据。</p><p><img src="https://s2.loli.net/2022/01/27/uGwhPFHA176dXKy.png" alt="image-20220127160055541"></p><p>即使是开无痕浏览也可以打开，说明不记录 Cookies。</p><p><img src="https://s2.loli.net/2022/01/29/dJBibYkN9enuEtx.png" alt="image-20220129222439327"></p><p>然后本来想直接用 Python 写批量抓取脚本，结果写了一段发现这个字幕元素竟然也是晚加载：</p><ul><li><code>Crawler.py</code></li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup<span class="token keyword">def</span> <span class="token function">getCookies</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>    f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span>    f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>    f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>    f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>    f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>    data <span class="token operator">=</span> f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\""</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">";"</span><span class="token punctuation">)</span>    result <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token keyword">for</span> entry <span class="token keyword">in</span> data<span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token string">'='</span> <span class="token keyword">in</span> entry<span class="token punctuation">:</span>            entryGroup <span class="token operator">=</span> entry<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"="</span><span class="token punctuation">)</span>            result<span class="token punctuation">[</span>entryGroup<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> entryGroup<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> result<span class="token keyword">def</span> <span class="token function">trim</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token builtin">str</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span>\              <span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">fetch_single_video</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>    url <span class="token operator">=</span> <span class="token string">'https://tsinghua.yuketang.cn/pro/lms/8NpUsbr6GZH/3029907/video/2224317'</span>    cookies <span class="token operator">=</span> getCookies<span class="token punctuation">(</span><span class="token string">'./cookies'</span><span class="token punctuation">)</span>        response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers<span class="token operator">=</span><span class="token punctuation">&#123;</span>                            <span class="token string">'User-Agent'</span><span class="token punctuation">:</span> <span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                            cookies<span class="token operator">=</span>getCookies<span class="token punctuation">(</span><span class="token string">"./cookies"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        response<span class="token punctuation">.</span>encoding <span class="token operator">=</span> <span class="token string">'utf-8'</span>    html <span class="token operator">=</span> response<span class="token punctuation">.</span>text<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>    soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>html<span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span>    f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./a.txt'</span><span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>soup<span class="token punctuation">.</span>prettify<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    fetch_single_video<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span></code></pre><p>其中 <code>./cookies</code> 里面放的是使用 <code>EditThisCookie</code> extension 导出的 txt 格式的 Cookies.</p><p><img src="https://s2.loli.net/2022/01/29/8CIt4g7kFJLoxXp.png" alt="image-20220129222822889"></p><p>发现这就是个 Vue 搭的前端网站，而且是晚加载的模式：</p><pre class="language-html" data-language="html"><code class="language-html"><span class="token doctype"><span class="token punctuation">&lt;!</span><span class="token doctype-tag">DOCTYPE</span> <span class="token name">html</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>html</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>head</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">charset</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>utf-8<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>text/html; charset=utf-8<span class="token punctuation">"</span></span> <span class="token attr-name">http-equiv</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>content-type<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>width=device-width,initial-scale=1,user-scalable=no<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>viewport<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>no-cache<span class="token punctuation">"</span></span> <span class="token attr-name">http-equiv</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>Pragma<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>no-transform <span class="token punctuation">"</span></span> <span class="token attr-name">http-equiv</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>Cache-Control<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>no-siteapp<span class="token punctuation">"</span></span> <span class="token attr-name">http-equiv</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>Cache-Control<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>no-cache<span class="token punctuation">"</span></span> <span class="token attr-name">http-equiv</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>Cache-Control<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0<span class="token punctuation">"</span></span> <span class="token attr-name">http-equiv</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>Expires<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>雨课堂, 清华大学, 智慧教学, 翻转课堂, 混合式教学, 教学工具, 教学软件<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>keywords<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>雨课堂是清华大学和学堂在线共同推出的新型智慧教学解决方案，是教育部在线教育研究中心的最新研究成果，致力于快捷免费的为所有教学过程提供数据化、智能化的信息支持。<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>Description<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>//proxt-cdn.xuetangx.com<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>dns-prefetch<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>//static-cdn.xuetangx.com<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>dns-prefetch<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>//qn-next.xuetangx.com<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>dns-prefetch<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>//s.xuetangx.com<span class="token punctuation">"</span></span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>dns-prefetch<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>//storagecdn.xuetangx.com<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>dns-prefetch<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/static/images/favicon.ico<span class="token punctuation">"</span></span> <span class="token attr-name">id</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>J_logo_ico<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>shortcut icon<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>image/x-icon<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>//at.alicdn.com/t/font_2914297_aiu6672k7jm.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>//at.alicdn.com/t/font_2914297_aiu6672k7jm.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>//at.alicdn.com/t/font_956123_fw8xrxx7a4u.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>//at.alicdn.com/t/font_956123_fw8xrxx7a4u.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">defer</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>defer<span class="token punctuation">"</span></span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://code.bdstatic.com/npm/@baiducloud/sdk@1.0.0-rc.19/dist/baidubce-sdk.bundle.min.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://storagecdn.xuetangx.com/public_assets/xuetangx/aliyun-upload-sdk/lib/aliyun-oss-sdk-5.3.1.min.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://storagecdn.xuetangx.com/public_assets/xuetangx/aliyun-upload-sdk/aliyun-upload-sdk-1.5.0.min.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://ssl.captcha.qq.com/TCaptcha.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://web-stat.jiguang.cn/web-janalytics/scripts/janalytics-web.min.js<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>text/javascript<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>title</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>title</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style"><span class="token language-css">   <span class="token selector">.ie-hint</span><span class="token punctuation">&#123;</span><span class="token property">display</span><span class="token punctuation">:</span>none<span class="token punctuation">;</span><span class="token property">position</span><span class="token punctuation">:</span>relative<span class="token punctuation">;</span><span class="token property">left</span><span class="token punctuation">:</span>0<span class="token punctuation">;</span><span class="token property">top</span><span class="token punctuation">:</span>0<span class="token punctuation">;</span><span class="token property">z-index</span><span class="token punctuation">:</span>100000<span class="token punctuation">;</span><span class="token property">width</span><span class="token punctuation">:</span>100%<span class="token punctuation">;</span><span class="token property">height</span><span class="token punctuation">:</span>40px<span class="token punctuation">;</span><span class="token property">line-height</span><span class="token punctuation">:</span>40px<span class="token punctuation">;</span><span class="token property">font-size</span><span class="token punctuation">:</span>16px<span class="token punctuation">;</span><span class="token property">text-align</span><span class="token punctuation">:</span>center<span class="token punctuation">;</span><span class="token property">background</span><span class="token punctuation">:</span>#fff8bf<span class="token punctuation">;</span><span class="token property">color</span><span class="token punctuation">:</span>#4a4a4a<span class="token punctuation">&#125;</span><span class="token selector">.ie-hint img</span><span class="token punctuation">&#123;</span><span class="token property">vertical-align</span><span class="token punctuation">:</span>middle<span class="token punctuation">&#125;</span><span class="token selector">.ie-hint a</span><span class="token punctuation">&#123;</span><span class="token property">color</span><span class="token punctuation">:</span>#639ef4<span class="token punctuation">&#125;</span><span class="token selector">.ie-hint .icon</span><span class="token punctuation">&#123;</span><span class="token property">font-size</span><span class="token punctuation">:</span>19px<span class="token punctuation">;</span><span class="token property">vertical-align</span><span class="token punctuation">:</span>middle<span class="token punctuation">&#125;</span><span class="token selector">#close-ie-hint</span><span class="token punctuation">&#123;</span><span class="token property">position</span><span class="token punctuation">:</span>absolute<span class="token punctuation">;</span><span class="token property">right</span><span class="token punctuation">:</span>10px<span class="token punctuation">;</span><span class="token property">top</span><span class="token punctuation">:</span>10px<span class="token punctuation">;</span><span class="token property">width</span><span class="token punctuation">:</span>20px<span class="token punctuation">&#125;</span><span class="token atrule"><span class="token rule">@media</span> print</span><span class="token punctuation">&#123;</span><span class="token selector">.no-print</span><span class="token punctuation">&#123;</span><span class="token property">visibility</span><span class="token punctuation">:</span>hidden<span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span>  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/styles.929a58a998b9713fd859.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/142.c165ba72220097b7a058.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/572.05955aff5704fb65b9f1.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1281.eb0a92d7006955f1e691.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1269.ecf512d0ea931c4302bf.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1255.a02392a53202a02f00cd.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1300.4c085e415259addde382.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1291.3fe43df5becd9c98e83b.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1301.d0128c8af9fd07b09a38.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1302.d0128c8af9fd07b09a38.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>head</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>body</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>ie-hint<span class="token punctuation">"</span></span> <span class="token attr-name">id</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>ie-hint<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">alt</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span><span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>icon<span class="token punctuation">"</span></span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://qn-sfe.yuketang.cn/o_1ecmgnntbah3150231eevqmpja.png<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>   当前浏览器可能无法正常使用   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>span</span> <span class="token attr-name">id</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>school-name<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>span</span><span class="token punctuation">></span></span>   ， 推荐使用   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://xiazai.sogou.com/detail/34/8/6262355089742005676.html<span class="token punctuation">"</span></span> <span class="token attr-name">target</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>_blank<span class="token punctuation">"</span></span> <span class="token attr-name">title</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>chrome<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    chrome浏览器、   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://www.firefox.com.cn/download/<span class="token punctuation">"</span></span> <span class="token attr-name">target</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>_blank<span class="token punctuation">"</span></span> <span class="token attr-name">title</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>火狐<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    火狐浏览器   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>   或   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://browser.qq.com/?adtag=SEM1<span class="token punctuation">"</span></span> <span class="token attr-name">target</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>_blank<span class="token punctuation">"</span></span> <span class="token attr-name">title</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>QQ浏览器<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    QQ浏览器   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>   。   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">alt</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span><span class="token punctuation">"</span></span> <span class="token attr-name">id</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>close-ie-hint<span class="token punctuation">"</span></span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://qn-sfe.yuketang.cn/o_1ecmgnntcn761v2p1vcn1i851jqcb.png<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">id</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>app<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>text/x-mathjax-config<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">   window<span class="token punctuation">.</span>MathJax<span class="token punctuation">.</span>Hub<span class="token punctuation">.</span><span class="token function">Config</span><span class="token punctuation">(</span><span class="token punctuation">&#123;</span>showProcessingMessages<span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token comment">//关闭js加载过程信息</span>messageStyle<span class="token operator">:</span> <span class="token string">"none"</span><span class="token punctuation">,</span> <span class="token comment">//不显示信息</span>jax<span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"input/TeX"</span><span class="token punctuation">,</span> <span class="token string">"output/HTML-CSS"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>showMathMenu<span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token comment">//关闭右击菜单显示</span>tex2jax<span class="token operator">:</span> <span class="token punctuation">&#123;</span>inlineMath<span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'$'</span><span class="token punctuation">,</span><span class="token string">'$'</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">"\\("</span><span class="token punctuation">,</span><span class="token string">"\\)"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'[mathjaxinline]'</span><span class="token punctuation">,</span><span class="token string">'[/mathjaxinline]'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>displayMath<span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'$$'</span><span class="token punctuation">,</span><span class="token string">'$$'</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">"\\["</span><span class="token punctuation">,</span><span class="token string">"\\]"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'[mathjax]'</span><span class="token punctuation">,</span><span class="token string">'[/mathjax]'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>processEscapes<span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span><span class="token string">"HTML-CSS"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span> availableFonts<span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"TeX"</span><span class="token punctuation">]</span> <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">defer</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://s.xuetangx.com/resource/mathjax/MathJax.js?config=TeX-MML-AM_HTMLorMML-full<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>text/javascript<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">   <span class="token keyword">var</span> _mtac<span class="token operator">=</span><span class="token punctuation">&#123;</span>performanceMonitor<span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">,</span>senseQuery<span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span class="token operator">!</span><span class="token keyword">function</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token keyword">var</span> t<span class="token operator">=</span>document<span class="token punctuation">.</span><span class="token function">createElement</span><span class="token punctuation">(</span><span class="token string">"script"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>t<span class="token punctuation">.</span>src<span class="token operator">=</span><span class="token string">"https://pingjs.qq.com/h5/stats.js?v2.0.4"</span><span class="token punctuation">,</span>t<span class="token punctuation">.</span><span class="token function">setAttribute</span><span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">,</span><span class="token string">"MTAH5"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>t<span class="token punctuation">.</span><span class="token function">setAttribute</span><span class="token punctuation">(</span><span class="token string">"sid"</span><span class="token punctuation">,</span><span class="token string">"500535776"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>t<span class="token punctuation">.</span><span class="token function">setAttribute</span><span class="token punctuation">(</span><span class="token string">"cid"</span><span class="token punctuation">,</span><span class="token string">"500613279"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">var</span> e<span class="token operator">=</span>document<span class="token punctuation">.</span><span class="token function">getElementsByTagName</span><span class="token punctuation">(</span><span class="token string">"script"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>e<span class="token punctuation">.</span>parentNode<span class="token punctuation">.</span><span class="token function">insertBefore</span><span class="token punctuation">(</span>t<span class="token punctuation">,</span>e<span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">   window<span class="token punctuation">.</span><span class="token constant">UEDITOR_HOME_URL</span><span class="token operator">=</span><span class="token string">"/vue_images/js/ueditor/"</span>  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">   <span class="token keyword">var</span> ieHint<span class="token operator">=</span>document<span class="token punctuation">.</span><span class="token function">getElementById</span><span class="token punctuation">(</span><span class="token string">"ie-hint"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>closeIeHintBtn<span class="token operator">=</span>document<span class="token punctuation">.</span><span class="token function">getElementById</span><span class="token punctuation">(</span><span class="token string">"close-ie-hint"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>closeIeHintBtn<span class="token punctuation">.</span><span class="token function-variable function">onclick</span><span class="token operator">=</span><span class="token keyword">function</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>ieHint<span class="token punctuation">.</span>style<span class="token punctuation">.</span>display<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span class="token keyword">var</span> ua<span class="token operator">=</span>navigator<span class="token punctuation">.</span>userAgent<span class="token punctuation">.</span><span class="token function">toLocaleLowerCase</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">null</span><span class="token operator">==</span>ua<span class="token punctuation">.</span><span class="token function">match</span><span class="token punctuation">(</span><span class="token regex"><span class="token regex-delimiter">/</span><span class="token regex-source language-regex">msie</span><span class="token regex-delimiter">/</span></span><span class="token punctuation">)</span><span class="token operator">&amp;&amp;</span><span class="token keyword">null</span><span class="token operator">==</span>ua<span class="token punctuation">.</span><span class="token function">match</span><span class="token punctuation">(</span><span class="token regex"><span class="token regex-delimiter">/</span><span class="token regex-source language-regex">trident</span><span class="token regex-delimiter">/</span></span><span class="token punctuation">)</span><span class="token operator">||</span><span class="token punctuation">(</span>ieHint<span class="token punctuation">.</span>style<span class="token punctuation">.</span>display<span class="token operator">=</span><span class="token string">"block"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">var</span> el<span class="token operator">=</span>document<span class="token punctuation">.</span><span class="token function">getElementById</span><span class="token punctuation">(</span><span class="token string">"school-name"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>el<span class="token punctuation">.</span>innerText<span class="token operator">=</span><span class="token regex"><span class="token regex-delimiter">/</span><span class="token regex-source language-regex">gdufemooc\.cn|gc\.xuetangonline\.com</span><span class="token regex-delimiter">/</span><span class="token regex-flags">g</span></span><span class="token punctuation">.</span><span class="token function">test</span><span class="token punctuation">(</span>window<span class="token punctuation">.</span>location<span class="token punctuation">.</span>host<span class="token punctuation">)</span><span class="token operator">?</span><span class="token string">"广财慕课"</span><span class="token operator">:</span><span class="token string">"雨课堂"</span>  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">   window<span class="token punctuation">.</span>JAnalyticsInterface<span class="token operator">&amp;&amp;</span>window<span class="token punctuation">.</span>JAnalyticsInterface<span class="token punctuation">.</span><span class="token function">init</span><span class="token punctuation">(</span><span class="token punctuation">&#123;</span>appkey<span class="token operator">:</span><span class="token string">"d651262356d93f6497b466bc"</span><span class="token punctuation">,</span>debugMode<span class="token operator">:</span><span class="token operator">!</span><span class="token number">1</span><span class="token punctuation">,</span>channel<span class="token operator">:</span><span class="token string">"web"</span><span class="token punctuation">,</span>loc<span class="token operator">:</span><span class="token operator">!</span><span class="token number">1</span><span class="token punctuation">,</span>singlePage<span class="token operator">:</span><span class="token operator">!</span><span class="token number">0</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/manifest_c74775d18d54217265e2.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/231_38a88de77e34999627ab.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/569_bc3c767e5675a607dbbd.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1282_f9bb16a2941af9a9732e.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/133_78b4a2f4ec1e774e0cd7.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1236_3946732fbcdc70b913ab.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/99_a1791a23a69e2309f9f1.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/46_492686a3fb63a70f8537.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/55_29d1ee187d2ac1bf8576.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/63_7e9066f450ffae3dbf1f.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1256_7a55b42b33475074b3d3.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/119_75b24be79cbc0f38e9b5.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/117_59618d0ce41a577cd0a2.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/232_5b17f99d4219ca1a5b59.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/339_18c69c22659d338f44af.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/100_29dabc580c2213c93d8c.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/56_ca3e56863eb65145d5ef.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/47_1a6f41d3f0d03e528606.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1264_4f1e99a3b8cdc6a85310.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/336_48448e96f180a901248e.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/101_317e4792ce1ff0603658.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/60_1f97ad5d40dccb242d3c.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/59_0b81e0afe51de42239f4.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/48_f696c92ebfa6dbe3a1ac.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/50_9da5f4380a1dd62a4349.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/70_c7d3361bfc7496f5d803.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1265_046603f30d395e0e1099.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/230_43fd774de4f928a81aa1.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1283_cdf10be9a5df97cb7d46.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/338_f4f2d394eb1bd2e4a76e.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/116_b722a9793903aa54c4a3.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1266_b1f6eab4866937cd2334.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/335_2f5c77a15099004dd76d.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/132_67afce490fea2dc1441a.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1274_53106a71aa695ff1e11d.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/337_5f023640d90421312cf8.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1258_0513b6935105b9242092.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/187_1d921a816015be88fc98.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/140_1429b54afac3f6055d28.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/189_312d72f77e83bd9f27d2.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/236_dd7f542d4cd9f02617d4.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1220_07a737b91c2b22ee2d3f.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/137_274aba69f9f08e27032a.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/118_03f55e7d8630c32b7003.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/139_32cd669c513bcc12f0d8.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1239_00c23825dfd87a3592d2.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/135_f61430536202b9abeb3f.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/138_e9b0ca84dbbf77e36067.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/141_b23872740ac87e16f8a0.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/188_f2c1d703e3c638123d7c.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/136_62c77544e64cd5ab11f5.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1296_9a4770963b01517ef057.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/121_8311183faa6fc009705d.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/134_592e67bb4735225d8109.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/styles_58dd88566a7c28f3ead9.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1235_8188f874883aec589e8d.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1288_777c8223f036e812be31.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/571_10162dcb435848dccc4a.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/234_46302fa6da910e733695.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1289_24f0da49aa9672e5f66b.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/235_9c17d4274dbb108f05a0.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/142_5298840037f69140cb58.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1290_37149584899447655329.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/574_83911d6a3fc0bac17622.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/120_4d32aa2ec1486063ffd5.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1237_e7ef338fbf8b5abae028.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1254_e17ce52fb300bba23ecb.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/572_6009ef3a4252cf76550d.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1281_ac1f61a1ceac82ef5c3a.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1269_1f2a8d4c2f0d32f8015c.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1255_64cf7487e3b6ed9cf088.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1300_7963eccd7914586cfe07.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1291_0619decfb4f04b856012.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1301_d74f386080e2a40bf9ed.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1302_a6924788437f7f6a7f03.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://proxt-cdn.xuetangx.com/fe-proxtassets/1287_07a707cc838c899e0e6a.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script"><span class="token language-javascript">  </span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>body</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>html</span><span class="token punctuation">></span></span></code></pre><h3 id="模拟"><a href="#模拟" class="headerlink" title="模拟"></a>模拟</h3><p>于是…想法就是模拟 JS 页面的加载…</p><p>仍然心存侥幸，想着不用油猴去写页面加载后运行的抓取脚本，或是不用 <code>PhantomJS</code> 写 JS 模拟（这两者都不够优雅），于是打开 DevTools 的 Network 页面模拟整个页面的加载过程：</p><p><img src="https://s2.loli.net/2022/01/29/4OnxEIr7pWPLtUV.png" alt="image-20220129225952673"></p><p>我们想要搜索的信息是这个视频的字幕 ID，也就是 <code>https://tsinghua.yuketang.cn/mooc-api/v1/lms/service/subtitle_parse/?c_d=07AA3C78762F81A09C33DC5901307461&amp;lg=0</code> 中的 <code>07AA3C78762F81A09C33DC5901307461</code>。对所有请求全文检索：</p><p><img src="https://s2.loli.net/2022/01/29/c8YTzbfE2x9RjNr.png" alt="image-20220129230159693"></p><p>首先，因为我们最初并不知道这个 ID 是多少，所以以这个 ID 为目标 URL 的直接略去，因为这个 ID 肯定是以某种方式传到前端的。所以目光就放在了第三个和第四个两个请求上面，其中第三个请求的 URL 似乎很合适：</p><p><code>[GET] https://tsinghua.yuketang.cn/mooc-api/v1/lms/learn/leaf_info/3029907/2224317/?sign=8NpUsbr6GZH&amp;term=latest&amp;uv_id=2598</code></p><p>对照一下：</p><ul><li>3029907 是课程 ID</li><li>2224317 是这个视频的 ID</li><li>8NpUsbr6GZH 似乎是我这个学生的 ID（因为别的课程界面里面也带有这个 ID）</li><li>2598 应该是 univ_ID，学校 ID</li></ul><p>而且是 GET 请求，除了 Cookies 之外不需要别的 POST 参数。</p><p>尝试访问：</p><p><img src="https://s2.loli.net/2022/01/29/qrRzEHdeusWP72N.png" alt="image-20220129230600173"></p><p><code>XTBZ</code> 是个啥？难道 GET 请求还需要验证？回到发请求那里认真看了下 headers：</p><p><img src="https://s2.loli.net/2022/01/29/2Ux9jtNVL13raCT.png" alt="image-20220129230701817"></p><p>好吧，确实有个 <code>xtbz</code> 字段，于是照着填上去…</p><pre class="language-python" data-language="python"><code class="language-python">response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"https://tsinghua.yuketang.cn/mooc-api/v1/lms/learn/leaf_info/3029907/2224317/?sign=8NpUsbr6GZH&amp;term=latest&amp;uv_id=2598"</span><span class="token punctuation">,</span> headers<span class="token operator">=</span><span class="token punctuation">&#123;</span>\                            <span class="token string">'User-Agent'</span><span class="token punctuation">:</span> <span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'</span><span class="token punctuation">,</span>                            <span class="token string">'xtbz'</span><span class="token punctuation">:</span> <span class="token string">'cloud'</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                            cookies <span class="token operator">=</span> getCookies<span class="token punctuation">(</span><span class="token string">"./cookies"</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>结果：</p><pre class="language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>'msg'<span class="token operator">:</span> ''<span class="token punctuation">,</span> 'data'<span class="token operator">:</span> <span class="token punctuation">&#123;</span>'sku_id'<span class="token operator">:</span> <span class="token number">813523</span><span class="token punctuation">,</span> 'is_assessed'<span class="token operator">:</span> False<span class="token punctuation">,</span> 'locked_reason'<span class="token operator">:</span> None<span class="token punctuation">,</span> 'course_id'<span class="token operator">:</span> <span class="token number">1360275</span><span class="token punctuation">,</span> 'classroom_short_name'<span class="token operator">:</span> None<span class="token punctuation">,</span> 'university_id'<span class="token operator">:</span> '<span class="token number">2598</span>'<span class="token punctuation">,</span> 'score_deadline'<span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span> 'current_price'<span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span> 'id'<span class="token operator">:</span> <span class="token number">2224317</span><span class="token punctuation">,</span> 'user_id'<span class="token operator">:</span> <span class="token number">20970575</span><span class="token punctuation">,</span> 'content_info'<span class="token operator">:</span> <span class="token punctuation">&#123;</span>'status'<span class="token operator">:</span> 'post'<span class="token punctuation">,</span> 'video_user_play'<span class="token operator">:</span> None<span class="token punctuation">,</span> 'expand_discuss'<span class="token operator">:</span> False<span class="token punctuation">,</span> 'score_evaluation'<span class="token operator">:</span> <span class="token punctuation">&#123;</span>'score_proportion'<span class="token operator">:</span> <span class="token punctuation">&#123;</span>'proportion'<span class="token operator">:</span> <span class="token number">0.0</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> 'score'<span class="token operator">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span> 'id'<span class="token operator">:</span> <span class="token number">6</span><span class="token punctuation">,</span> 'name'<span class="token operator">:</span> '视 频单元考核'<span class="token punctuation">&#125;</span><span class="token punctuation">,</span> 'download'<span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 'is_score'<span class="token operator">:</span> True<span class="token punctuation">,</span> 'is_discuss'<span class="token operator">:</span> True<span class="token punctuation">,</span> 'remark'<span class="token operator">:</span> <span class="token punctuation">&#123;</span>'remark'<span class="token operator">:</span> ''<span class="token punctuation">&#125;</span><span class="token punctuation">,</span> 'cover_desc'<span class="token operator">:</span> ''<span class="token punctuation">,</span> 'cover_thumbnail'<span class="token operator">:</span> 'https<span class="token operator">:</span><span class="token comment">//qn-next.xuetangx.com/15659303522988.jpg?imageView2/0/h/500', 'media': </span><span class="token punctuation">&#123;</span>'lecturer'<span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span> 'ccid'<span class="token operator">:</span> '07AA3C78762F81A09C33DC5901307461'<span class="token punctuation">,</span> 'start_time'<span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span> 'cover'<span class="token operator">:</span> 'https<span class="token operator">:</span><span class="token comment">//qn-next.xuetangx.com/15659303522988.jpg', 'ccurl': '07AA3C78762F81A09C33DC5901307461', 'duration': 550, 'end_time': 0, 'live_palyback_url': '', 'live_url': '', 'type': 'video', 'teacher': []&#125;, 'cover': 'https://qn-next.xuetangx.com/15659303522988.jpg', 'leaf_type_id': None, 'context': '&lt;!DOCTYPE html>&lt;html>&lt;head>&lt;/head>&lt;body>\n&lt;/body>&lt;/html>'&#125;, 'classroom_id': '3029907', 'leaf_type': 0, 'has_classend': True, 'upgrade_sku_status': None, 'price': 0, 'user_role': </span><span class="token number">3</span><span class="token punctuation">,</span> 'class_start_time'<span class="token operator">:</span> <span class="token number">1613959200000</span><span class="token punctuation">,</span> 'upgrade_sku_id'<span class="token operator">:</span> None<span class="token punctuation">,</span> 'be_in_force'<span class="token operator">:</span> False<span class="token punctuation">,</span> 'teacher'<span class="token operator">:</span> <span class="token punctuation">&#123;</span>'org_name'<span class="token operator">:</span> '清华大学'<span class="token punctuation">,</span> 'picture'<span class="token operator">:</span> 'https<span class="token operator">:</span><span class="token comment">//qn-next.xuetangx.com/15659303632348.jpg', 'name': '【教师名字】', 'department_name': '【教师院系】', 'intro': '【教师介绍】', 'job_title': '副教授'&#125;, 'is_score': True, 'is_deleted': False, 'name': '开篇的话', 'is_locked': False, 'class_end_time': 1623596400000&#125;, 'success': True&#125;</span></code></pre><p>好吧，看到 ccid 我们终于是拿到想要的东西了。这个 Response 里面打码了一些跟课程有关的内容（虽然已经泄露的差不多了吧x）</p><p>好的，现在来整理一下思路，截至目前我们已经获得了从一个视频在网页上外显的 ID 转换成其 CCID 的方法，也就是 <code>[GET] https://tsinghua.yuketang.cn/mooc-api/v1/lms/learn/leaf_info/[课程号]/[视频外显ID]/?sign=[学生ID]&amp;term=latest&amp;uv_id=2598</code>，然后<code>CCID = response.json()[&#39;data&#39;][&#39;content_info&#39;][&#39;media&#39;][&#39;ccid&#39;]</code>，接着我们就能通过 <code>[GET] https://tsinghua.yuketang.cn/mooc-api/v1/lms/service/subtitle_parse/?c_d=[CCID]&amp;lg=0</code> 来获取对应视频字幕。</p><p>下面我们还想优化，就是怎么把一个课程所有的 <code>[视频外显ID]</code> 全部拿出来，事实上这也是可以做到的，因为我们再仔细检查一下发送的这一堆请求，找到了：</p><p><code>[GET] https://tsinghua.yuketang.cn/mooc-api/v1/lms/learn/course/chapter?cid=3029907&amp;sign=8NpUsbr6GZH&amp;term=latest&amp;uv_id=2598</code>，请求了整个课程的信息，我们对其返回的 JSON 解码得到：</p><p><img src="https://s2.loli.net/2022/01/29/KftCcXuOY73v5NR.png" alt="image-20220129232309709"></p><p>从这个 Response 里面我们能拿到所有视频的外显 ID。</p><h3 id="调-API"><a href="#调-API" class="headerlink" title="调 API"></a>调 API</h3><ul><li><code>[GET] https://tsinghua.yuketang.cn/mooc-api/v1/lms/learn/course/chapter?cid=[课程ID]&amp;sign=[学生ID]&amp;term=latest&amp;uv_id=2598</code> -&gt; 视频外显 ID 的列表</li><li><code>[GET] https://tsinghua.yuketang.cn/mooc-api/v1/lms/learn/leaf_info/[课程ID]/[视频外显ID]/?sign=[学生ID]&amp;term=latest&amp;uv_id=2598</code> -&gt; 视频 CCID</li><li><code>[GET] https://tsinghua.yuketang.cn/mooc-api/v1/lms/service/subtitle_parse/?c_d=[CCID]&amp;lg=0</code> -&gt; 视频字幕</li></ul><p>整理成代码如下：</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_course_info</span><span class="token punctuation">(</span>cid<span class="token punctuation">,</span> sid<span class="token punctuation">)</span><span class="token punctuation">:</span>        video_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        url <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'''https://tsinghua.yuketang.cn/mooc-api/v1/lms/learn/course/chapter?cid=</span><span class="token interpolation"><span class="token punctuation">&#123;</span>cid<span class="token punctuation">&#125;</span></span><span class="token string">&amp;sign=</span><span class="token interpolation"><span class="token punctuation">&#123;</span>sid<span class="token punctuation">&#125;</span></span><span class="token string">&amp;term=latest&amp;uv_id=2598'''</span></span>    cookies <span class="token operator">=</span> getCookies<span class="token punctuation">(</span><span class="token string">'./cookies'</span><span class="token punctuation">)</span>    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers<span class="token operator">=</span><span class="token punctuation">&#123;</span>\                            <span class="token string">'User-Agent'</span><span class="token punctuation">:</span> <span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'</span><span class="token punctuation">,</span>                            <span class="token string">'xtbz'</span><span class="token punctuation">:</span> <span class="token string">'cloud'</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                            cookies <span class="token operator">=</span> getCookies<span class="token punctuation">(</span><span class="token string">"./cookies"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        data <span class="token operator">=</span> response<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>    chapter_list <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'course_chapter'</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> chapter <span class="token keyword">in</span> chapter_list<span class="token punctuation">:</span>        leaves <span class="token operator">=</span> chapter<span class="token punctuation">[</span><span class="token string">'section_leaf_list'</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> leaf <span class="token keyword">in</span> leaves<span class="token punctuation">:</span>            <span class="token keyword">try</span><span class="token punctuation">:</span>                video_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>leaf<span class="token punctuation">[</span><span class="token string">'leaf_list'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token keyword">except</span><span class="token punctuation">:</span>                <span class="token keyword">pass</span>        <span class="token keyword">return</span> video_list<span class="token keyword">def</span> <span class="token function">get_caption</span><span class="token punctuation">(</span>cid<span class="token punctuation">,</span> sid<span class="token punctuation">,</span> vid<span class="token punctuation">)</span><span class="token punctuation">:</span>    url <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'''https://tsinghua.yuketang.cn/mooc-api/v1/lms/learn/leaf_info/</span><span class="token interpolation"><span class="token punctuation">&#123;</span>cid<span class="token punctuation">&#125;</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">&#123;</span>vid<span class="token punctuation">&#125;</span></span><span class="token string">/?sign=</span><span class="token interpolation"><span class="token punctuation">&#123;</span>sid<span class="token punctuation">&#125;</span></span><span class="token string">&amp;term=latest&amp;uv_id=2598'''</span></span>    cookies <span class="token operator">=</span> getCookies<span class="token punctuation">(</span><span class="token string">'./cookies'</span><span class="token punctuation">)</span>    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers<span class="token operator">=</span><span class="token punctuation">&#123;</span>\                            <span class="token string">'User-Agent'</span><span class="token punctuation">:</span> <span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'</span><span class="token punctuation">,</span>                            <span class="token string">'xtbz'</span><span class="token punctuation">:</span> <span class="token string">'cloud'</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                            cookies <span class="token operator">=</span> getCookies<span class="token punctuation">(</span><span class="token string">"./cookies"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        data <span class="token operator">=</span> response<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>    video_name <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>        ccid <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'content_info'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'media'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'ccid'</span><span class="token punctuation">]</span>        <span class="token keyword">if</span> <span class="token keyword">not</span> ccid<span class="token punctuation">:</span> <span class="token keyword">raise</span> BaseException<span class="token punctuation">(</span><span class="token string">"HTML Introduction. No video."</span><span class="token punctuation">)</span>                url <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'''https://tsinghua.yuketang.cn/mooc-api/v1/lms/service/subtitle_parse/?c_d=</span><span class="token interpolation"><span class="token punctuation">&#123;</span>ccid<span class="token punctuation">&#125;</span></span><span class="token string">&amp;lg=0'''</span></span>        cookies <span class="token operator">=</span> getCookies<span class="token punctuation">(</span><span class="token string">'./cookies'</span><span class="token punctuation">)</span>        response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers<span class="token operator">=</span><span class="token punctuation">&#123;</span>\                                <span class="token string">'User-Agent'</span><span class="token punctuation">:</span> <span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'</span><span class="token punctuation">,</span>                                <span class="token string">'xtbz'</span><span class="token punctuation">:</span> <span class="token string">'cloud'</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                                cookies <span class="token operator">=</span> getCookies<span class="token punctuation">(</span><span class="token string">"./cookies"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                data <span class="token operator">=</span> response<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>        data<span class="token punctuation">[</span><span class="token string">'start'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token keyword">for</span> s <span class="token keyword">in</span> data<span class="token punctuation">[</span><span class="token string">'start'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>        caption_list <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'start'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token string">'text'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"./output/[</span><span class="token interpolation"><span class="token punctuation">&#123;</span>vid<span class="token punctuation">&#125;</span></span><span class="token string">] </span><span class="token interpolation"><span class="token punctuation">&#123;</span>video_name<span class="token punctuation">&#125;</span></span><span class="token string">.txt"</span></span><span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>                <span class="token keyword">for</span> caption <span class="token keyword">in</span> caption_list<span class="token punctuation">:</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"%-10d  %s\n"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>caption<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> caption<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">except</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span></code></pre><p>效果如下：</p><p><img src="https://s2.loli.net/2022/01/29/klDeE37nTJ6QPgb.png" alt="image-20220129235837541"></p><h2 id="碎碎念"><a href="#碎碎念" class="headerlink" title="碎碎念"></a>碎碎念</h2><p>清华雨课堂用来放 MOOC 的这个平台和学堂在线那个平台前端是一样的。</p><p>这简直就和 net9.org 和 stu.cs.tsinghua.edu.cn 的后台一样，写一份账户管理工具，一份自己用，另一份拿出去用。</p><p>这篇博文仅供练习使用，不保证能复现，更不会提供爬取后的慕课字幕数据。以上。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2022/01/30/nkI5B9DcPQzX3Us.png&quot; alt=&quot;image-20220130000139599&quot;&gt;&lt;/p&gt;
&lt;p&gt;GitHub Repo: &lt;a href=&quot;https://github.com/c7w/TsinghuaMoocCaptionCrawler&quot;&gt;https://github.com/c7w/TsinghuaMoocCaptionCrawler&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Blog: &lt;a href=&quot;https://c7w.tech/yuketang-caption-crawler/&quot;&gt;https://c7w.tech/yuketang-caption-crawler/&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="技术" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="技术/Python应用" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF-Python%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="爬虫" scheme="https://www.c7w.tech/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>《动手学深度学习》 Pytorch ver. 阅读摘录 Part C</title>
    <link href="https://www.c7w.tech/dive-into-dl-pytorch-C/"/>
    <id>https://www.c7w.tech/dive-into-dl-pytorch-C/</id>
    <published>2022-01-27T07:00:32.000Z</published>
    <updated>2022-01-28T08:16:40.949Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/cover.png" alt=""></p><ul><li>《动手学深度学习》原书地址：<a href="https://github.com/d2l-ai/d2l-zh">https://github.com/d2l-ai/d2l-zh</a></li><li>《动手学深度学习》(Pytorch ver.)：<a href="https://tangshusen.me/Dive-into-DL-PyTorch/#/">https://tangshusen.me/Dive-into-DL-PyTorch/#/</a></li></ul><p>知识架构：</p><p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/book-org.svg" alt="封面"></p><p>本文的主要作用是在阅读过程中做一些摘录。对于「机器学习」领域， c7w 虽然曾尝试从各个领域入门，也尝试训过一些模型，但是还是缺少系统性、结构性的学习。希望阅读本书能带来更多的收获吧。</p><p>与前面的一些笔记相比，本文更加侧重于「实践」。也就是说切实地提升自己的代码能力。</p><p>Part C 包含：</p><ul><li>§ 7 优化算法<ul><li>优化与深度学习，优化存在的挑战</li><li>梯度下降（略）</li><li>Momentum, Adagrad</li><li>RMSProp, AdaDelta</li><li>Adam</li></ul></li><li>§ 8 计算性能<ul><li>多 GPU 计算</li><li>多 GPU 计算时模型的保存与加载</li></ul></li><li>§ 10 NLP<ul><li>Word2Vec, fastText, GloVe</li><li>Encoder-Decoder, Beam Search</li><li>Attention</li></ul></li></ul><a id="more"></a><h2 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h2><h3 id="优化与深度学习"><a href="#优化与深度学习" class="headerlink" title="优化与深度学习"></a>优化与深度学习</h3><p>本节将讨论优化与深度学习的关系，以及优化在深度学习中的挑战。</p><p>在一个深度学习问题中，我们通常会预先定义一个损失函数。有了损失函数以后，我们就可以使用优化算法试图将其最小化。在优化中，这样的损失函数通常被称作优化问题的<strong>目标函数</strong>。依据惯例，优化算法通常只考虑最小化目标函数。其实，任何最大化问题都可以很容易地转化为最小化问题，只需令目标函数的相反数为新的目标函数即可。</p><p>优化的挑战：</p><ul><li>局部最小值</li><li>Saddle Point</li></ul><h3 id="Gradient-Descent-与-SGD"><a href="#Gradient-Descent-与-SGD" class="headerlink" title="Gradient Descent 与 SGD"></a>Gradient Descent 与 SGD</h3><p>（之前的笔记中记录已十分详细，此处略去）</p><h3 id="动量法"><a href="#动量法" class="headerlink" title="动量法"></a>动量法</h3><blockquote><p>　指数移动加权平均法，是指<strong>各数值的加权系数随时间呈指数式递减，越靠近当前时刻的数值加权系数就越大</strong>。</p><p>　指数移动加权平均较传统的平均法来说，一是不需要保存过去所有的数值；二是计算量显著减小。</p></blockquote><p>目标函数有关自变量的梯度代表了目标函数在自变量当前位置下降最快的方向。因此，梯度下降也叫作最陡下降。在每次迭代中，梯度下降根据自变量当前位置，沿着当前位置的梯度更新自变量。</p><p>然而，如果自变量的迭代方向仅仅取决于自变量当前位置，这可能会带来一些问题。</p><p>让我们考虑一个输入和输出分别为二维向量 $\boldsymbol{x} = [x_1, x_2]^\top$​ 和标量的目标函数 $f(\boldsymbol{x})=0.1x_1^2+2x_2^2$​。</p><p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter07/7.4_output1.png" alt="img"></p><p>可以看到，同一位置上，目标函数在竖直方向（$x_2$ 轴方向）比在水平方向（$x_1$ 轴方向）的斜率的绝对值更大。因此，给定学习率，梯度下降迭代自变量时会使自变量在竖直方向比在水平方向移动幅度更大。那么，我们需要一个较小的学习率从而避免自变量在竖直方向上越过目标函数最优解。然而，这会造成自变量在水平方向上朝最优解移动变慢。</p><p>但如果我们试着将学习率调得稍大一点，此时自变量在竖直方向不断越过最优解并逐渐发散。</p><p>动量法的提出是为了解决梯度下降的上述问题。设时间步 $t$​ 的自变量为 $\boldsymbol{x}_t$​，学习率为 $\eta_t$​，对应梯度为 $\boldsymbol  g_t$​。<br>在时间步 $0$​，动量法创建速度变量 $\boldsymbol{v}_0$​，并将其元素初始化成 0。在时间步 $t&gt;0$​，动量法对每次迭代的步骤做如下修改：</p><script type="math/tex; mode=display">\begin{aligned}\boldsymbol{v}_t &\leftarrow \gamma \boldsymbol{v}_{t-1} + \eta_t \boldsymbol{g}_t, \\\boldsymbol{x}_t &\leftarrow \boldsymbol{x}_{t-1} - \boldsymbol{v}_t,\end{aligned}</script><p>其中，动量超参数$\gamma$满足$0 \leq \gamma &lt; 1$。当$\gamma=0$时，动量法等价于小批量随机梯度下降。</p><p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter07/7.4_output3.png" alt="img"></p><p>在动量法中，自变量在各个方向上的移动幅度不仅取决当前梯度，还取决于过去的各个梯度在各个方向上是否一致。</p><p>实现的话也是大调库：</p><pre class="language-python" data-language="python"><code class="language-python">d2l<span class="token punctuation">.</span>train_pytorch_ch7<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.004</span><span class="token punctuation">,</span> <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0.9</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                    features<span class="token punctuation">,</span> labels<span class="token punctuation">)</span></code></pre><h3 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h3><p>AdaGrad 算法根据自变量在每个维度的梯度值的大小来调整各个维度上的学习率，从而避免统一的学习率难以适应所有维度的问题。</p><p>AdaGrad 算法会使用一个小批量随机梯度 $\boldsymbol{g}_t$​​ 按元素平方的累加变量 $\boldsymbol{s}_t$​​。在时间步 0，AdaGrad 将 $\boldsymbol{s}_0$​​ 中每个元素初始化为 0。在时间步 $t$​​，首先将小批量随机梯度 $\boldsymbol{g}_t$​​ 按元素平方后累加到变量 $\boldsymbol{s}_t$​​：</p><script type="math/tex; mode=display">\boldsymbol{s}_t \leftarrow \boldsymbol{s}_{t-1} + \boldsymbol{g}_t \odot \boldsymbol{g}_t</script><p>接着，我们将目标函数自变量中每个元素的学习率通过按元素运算重新调整一下：</p><script type="math/tex; mode=display">\boldsymbol{x}_t \leftarrow \boldsymbol{x}_{t-1} - \frac{\eta}{\sqrt{\boldsymbol{s}_t + \epsilon}} \odot \boldsymbol{g}_t</script><p>其中 $\eta$​ 是学习率，$\epsilon$​ 是为了维持数值稳定性而添加的常数，如 $10^{-6}$​​​。这里开方、除法和乘法的运算都是按元素运算的。这些按元素运算使得目标函数自变量中每个元素都分别拥有自己的学习率。</p><p>由于 $\boldsymbol{s}_t$ 一直在累加按元素平方的梯度，自变量中每个元素的学习率在迭代过程中一直在降低（或不变）。所以，当学习率在迭代早期降得较快且当前解依然不佳时，AdaGrad算法在迭代后期由于学习率过小，可能较难找到一个有用的解。</p><p>通过名称为 <code>Adagrad</code> 的优化器方法，我们便可使用 PyTorch 提供的 AdaGrad 算法来训练模型。</p><pre class="language-python" data-language="python"><code class="language-python">d2l<span class="token punctuation">.</span>train_pytorch_ch7<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adagrad<span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> features<span class="token punctuation">,</span> labels<span class="token punctuation">)</span></code></pre><h3 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h3><p>针对最后我们提出的 Adagrad 算法存在的迭代后期 learning_rate 过小问题，RMSProp 算法被提出。</p><p>不同于 AdaGrad 算法里状态变量 $\boldsymbol{s}_t$ 是截至时间步 $t$ 所有小批量随机梯度 $\boldsymbol{g}_t$ 按元素平方和，RMSProp 算法将这些梯度按元素平方做指数加权移动平均。具体来说，给定超参数 $0 \leq \gamma &lt; 1$，RMSProp 算法在时间步 $t&gt;0$ 计算 $\boldsymbol{s}_t \leftarrow \gamma \boldsymbol{s}_{t-1} + (1 - \gamma) \boldsymbol{g}_t \odot \boldsymbol{g}_t$​.</p><p>和 AdaGrad 算法一样，RMSProp 算法将目标函数自变量中每个元素的学习率通过按元素运算重新调整，然后更新自变量 $\boldsymbol{x}_t \leftarrow \boldsymbol{x}_{t-1} - \frac{\eta}{\sqrt{\boldsymbol{s}_t + \epsilon}} \odot \boldsymbol{g}_t $.</p><p>因为 RMSProp 算法的状态变量 $\boldsymbol{s}_t$ 是对平方项 $\boldsymbol{g}_t \odot \boldsymbol{g}_t$ 的指数加权移动平均，所以可以看作是最近 $ \dfrac 1 {1-\gamma}$ 个时间步的小批量随机梯度平方项的加权平均。如此一来，自变量每个元素的学习率在迭代过程中就不再一直降低（或不变）。</p><pre class="language-python" data-language="python"><code class="language-python">d2l<span class="token punctuation">.</span>train_pytorch_ch7<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>RMSprop<span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token string">'alpha'</span><span class="token punctuation">:</span> <span class="token number">0.9</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                    features<span class="token punctuation">,</span> labels<span class="token punctuation">)</span></code></pre><h3 id="AdaDelta"><a href="#AdaDelta" class="headerlink" title="AdaDelta"></a>AdaDelta</h3><p>除了 RMSProp 算法以外，另一个常用优化算法 AdaDelta 算法也针对 AdaGrad 算法在迭代后期可能较难找到有用解的问题做了改进。有意思的是，<strong>AdaDelta 算法没有学习率这一超参数</strong>。</p><p>AdaDelta 算法也像 RMSProp 算法一样，使用了小批量随机梯度 $\boldsymbol{g}_t$ 按元素平方的指数加权移动平均变量 $\boldsymbol{s}_t$。在时间步 0，它的所有元素被初始化为 0。给定超参数 $0 \leq \rho &lt; 1$（对应RMSProp算法中的 $\gamma$），在时间步 $t&gt;0$，同RMSProp算法一样计算 $ \boldsymbol{s}_t \leftarrow \rho \boldsymbol{s}_{t-1} + (1 - \rho) \boldsymbol{g}_t \odot \boldsymbol{g}_t $。​</p><p>与 RMSProp 算法不同的是，AdaDelta 算法还维护一个额外的状态变量 $\Delta\boldsymbol{x}_t$，其元素同样在时间步 0 时被初始化为 0。我们使用 $\Delta\boldsymbol{x}_{t-1}$ 来计算自变量的变化量：$ \boldsymbol{g}_t’ \leftarrow \sqrt{\frac{\Delta\boldsymbol{x}_{t-1} + \epsilon}{\boldsymbol{s}_t + \epsilon}}   \odot \boldsymbol{g}_t $​，其中 $\epsilon$ 是为了维持数值稳定性而添加的常数，如$10^{-5}$。</p><p>接着更新自变量：$ \boldsymbol{x}_t \leftarrow \boldsymbol{x}_{t-1} - \boldsymbol{g}’_t $​。</p><p>最后，我们使用 $\Delta\boldsymbol{x}_t$ 来记录自变量变化量 $\boldsymbol{g}’_t$ 按元素平方的指数加权移动平均：$\Delta\boldsymbol{x}_t \leftarrow \rho \Delta\boldsymbol{x}_{t-1} + (1 - \rho) \boldsymbol{g}’_t \odot \boldsymbol{g}’_t$。</p><p>可以看到，如不考虑 $\epsilon$​ 的影响，<strong>AdaDelta 算法跟 RMSProp 算法的不同之处在于使用 $\sqrt{\Delta\boldsymbol{x}_{t-1}}$​ 来替代学习率 $\eta$​</strong>。</p><pre class="language-python" data-language="python"><code class="language-python">d2l<span class="token punctuation">.</span>train_pytorch_ch7<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adadelta<span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">'rho'</span><span class="token punctuation">:</span> <span class="token number">0.9</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> features<span class="token punctuation">,</span> labels<span class="token punctuation">)</span></code></pre><h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p>Adam 算法在 RMSProp 算法基础上对小批量随机梯度也做了指数加权移动平均，所以 Adam 算法可以看做是 RMSProp 算法与动量法的结合。</p><p>Adam 算法使用了动量变量 $\boldsymbol{v}_t$ 和 RMSProp 算法中小批量随机梯度按元素平方的指数加权移动平均变量 $\boldsymbol{s}_t$，并在时间步 0 将它们中每个元素初始化为 0。</p><p>给定超参数 $0 \leq \beta_1 &lt; 1$（算法作者建议设为 0.9），时间步 $t$ 的动量变量 $\boldsymbol{v}_t$ 即小批量随机梯度 $\boldsymbol{g}_t$ 的指数加权移动平均：$\boldsymbol{v}_t \leftarrow \beta_1 \boldsymbol{v}_{t-1} + (1 - \beta_1) \boldsymbol{g}_t $。​</p><p>和 RMSProp 算法中一样，给定超参数 $0 \leq \beta_2 &lt; 1$（算法作者建议设为0.999），<br>将小批量随机梯度按元素平方后的项 $\boldsymbol{g}_t \odot \boldsymbol{g}_t$ 做指数加权移动平均得到 $\boldsymbol{s}_t$：$\boldsymbol{s}_t \leftarrow \beta_2 \boldsymbol{s}_{t-1} + (1 - \beta_2) \boldsymbol{g}_t \odot \boldsymbol{g}_t$</p><ul><li>偏差修正</li></ul><p>由于我们将 $\boldsymbol{v}_0$ 和 $\boldsymbol{s}_0$ 中的元素都初始化为 0，在时间步 $t$ 我们得到 $\boldsymbol{v}_t =  (1-\beta_1) \sum_{i=1}^t \beta_1^{t-i} \boldsymbol{g}_i$。</p><p>将过去各时间步小批量随机梯度的权值相加，得到 $(1-\beta_1) \sum_{i=1}^t \beta_1^{t-i} = 1 - \beta_1^t$。</p><p>需要注意的是，当 $t$ 较小时，过去各时间步小批量随机梯度权值之和会较小。例如，当 $\beta_1 = 0.9$ 时，$\boldsymbol{v}_1 = 0.1\boldsymbol{g}_1$。</p><p>为了消除这样的影响，对于任意时间步 $t$，我们可以将 $\boldsymbol{v}_t$ 再除以 $1 - \beta_1^t$​，从而使过去各时间步小批量随机梯度权值之和为 1。这也叫作偏差修正。</p><p>在 Adam 算法中，我们对变量 $\boldsymbol{v}_t$ 和 $\boldsymbol{s}_t$ 均作偏差修正：</p><script type="math/tex; mode=display">\hat{\boldsymbol{v}}_t \leftarrow \frac{\boldsymbol{v}_t}{1 - \beta_1^t}, \\ \hat{\boldsymbol{s}}_t \leftarrow \frac{\boldsymbol{s}_t}{1 - \beta_2^t}.</script><p>接下来，Adam 算法使用以上偏差修正后的变量 $\hat{\boldsymbol{v}}_t$ 和 $\hat{\boldsymbol{s}}_t$，将模型参数中每个元素的学习率通过按元素运算重新调整：$\boldsymbol{g}_t’ \leftarrow \frac{\eta \hat{\boldsymbol{v}}_t}{\sqrt{\hat{\boldsymbol{s}}_t} + \epsilon}$。​​其中 $\eta$ ​是学习率，$\epsilon$ ​是为了维持数值稳定性而添加的常数，如 $10^{-8}$​。</p><p>和 AdaGrad 算法、RMSProp 算法以及 AdaDelta 算法一样，目标函数自变量中每个元素都分别拥有自己的学习率。最后，使用 $\boldsymbol{g}_t’$ ​迭代自变量：$\boldsymbol{x}_t \leftarrow \boldsymbol{x}_{t-1} - \boldsymbol{g}_t’$。</p><pre class="language-python" data-language="python"><code class="language-python">d2l<span class="token punctuation">.</span>train_pytorch_ch7<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.01</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> features<span class="token punctuation">,</span> labels<span class="token punctuation">)</span></code></pre><h2 id="计算性能：多-GPU-计算"><a href="#计算性能：多-GPU-计算" class="headerlink" title="计算性能：多 GPU 计算"></a>计算性能：多 GPU 计算</h2><ul><li>多 GPU 计算</li></ul><p>先定义一个模型：</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchnet <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span> <span class="token comment"># Linear(in_features=10, out_features=1, bias=True)</span></code></pre><p>要想使用 PyTorch 进行多 GPU 计算，最简单的方法是直接用 <code>torch.nn.DataParallel</code> 将模型wrap一下即可：<br><pre class="language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>DataParallel<span class="token punctuation">(</span>net<span class="token punctuation">)</span>net</code></pre><br>输出：<br><pre class="language-none"><code class="language-none">DataParallel(  (module): Linear(in_features&#x3D;10, out_features&#x3D;1, bias&#x3D;True))</code></pre><br>这时，默认所有存在的 GPU 都会被使用。</p><p>如果我们机子中有很多 GPU (例如上面显示我们有 4 张显卡，但是只有第 0、3 块还剩下一点点显存)，但我们只想使用 0、3 号显卡，那么我们可以用参数 <code>device_ids</code> 指定即可：<code>torch.nn.DataParallel(net, device_ids=[0, 3])</code>。</p><ul><li>多 GPU 模型的保存与加载</li></ul><p>按之前的方法，被 <code>DataParallel</code> 包围的模型保存时正常，但加载时会出问题。</p><p>正确的方法是保存的时候只保存 <code>net.module</code>:</p><pre class="language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>module<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"./8.4_model.pt"</span><span class="token punctuation">)</span>new_net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"./8.4_model.pt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 加载成功</span></code></pre><p>或者先将 <code>new_net</code> 用 <code>DataParallel</code> 包括以下再用上面报错的方法进行模型加载:<br><pre class="language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"./8.4_model.pt"</span><span class="token punctuation">)</span>new_net <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>new_net <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>DataParallel<span class="token punctuation">(</span>new_net<span class="token punctuation">)</span>new_net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"./8.4_model.pt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 加载成功</span></code></pre></p><h2 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h2><h3 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h3><p>Word2vec 是 Google 于 2013 年推出的开源的获取词向量 word2vec 的工具包。它包括了一组用于 word embedding 的模型，这些模型通常都是用浅层（两层）神经网络训练词向量。</p><p>Word2vec 的模型以大规模语料库作为输入，然后生成一个向量空间（通常为几百维）。词典中的每个词都对应了向量空间中的一个独一的向量，而且<strong>语料库中拥有共同上下文的词映射到向量空间中的距离会更近</strong>。</p><p>本节参考 <a href="https://www.zybuluo.com/Dounm/note/591752，梳理其发展历程及原理。">https://www.zybuluo.com/Dounm/note/591752，梳理其发展历程及原理。</a></p><ul><li><strong>神经概率语言模型</strong></li></ul><p><img src="https://raw.githubusercontent.com/Dounm/TheFarmOfDounm/master/resources/images/word2vec/1.png" alt="1"></p><ul><li>训练样本为 <code>(Context(w), w)</code>，其中 $w \in Corpus$, $Context(w)$ 为其前面的 $n-1$ 个词</li><li>$X_w$ 为直接将 $Context(w)$​ 收尾顺次相接得到的 $(n-1) \cdot m$ 长度的向量，其中 $m$ 为词向量长度</li><li>$Z_w = \tanh (WX_w + p), \, y_w = Uz_w + q$.</li></ul><p>于是在对 $y_w$ Softmax 归一化之后，$y_w$ 在对应维度的分量就是对应词的预测概率。</p><p>这个模型存在的问题：计算量太大。假设 $n \sim  5, m \sim 10^2, |Z_w| \sim 10^2, |y_w| = | \Sigma| \sim 10^5$，那么<strong>隐层和输出层之间的矩阵运算</strong>，以及<strong>输出层的 Softmax 运算</strong>会大大增加模型的计算量。</p><ul><li><strong>Word2vec 对网格结构的优化</strong></li></ul><p><img src="https://raw.githubusercontent.com/Dounm/TheFarmOfDounm/master/resources/images/word2vec/2.png" alt="7"></p><p>网格结构删除了隐藏层，而且 Projection Layer 也由“拼接”变成了“求和”，因此 Projection Layer 的结点数为词向量对应维数；输出层规模仍然是词典中词的个数。</p><p>但是，对于神经网络而言，我们的输入层的参数是中各个词的词向量，那么这个词向量是怎么来的呢？</p><p>事实上，我们在给定 $x$ 计算 $y_i$ 的时候，采用的方法是 $Y = Wx$，即 $y_i = w_i^Tx$，即矩阵 $W$ 第 $i$ 行与投影层做点积。于是这个词向量就可以直接用输出层和映射层之间的参数 $W$ 的第 $i$ 行 $w_i$ 来表示。</p><p>这样一来的话，我们训练神经网络的参数，就相当于训练了每个词的词向量，也就得到了词典中每个词的词向量。</p><ul><li><strong>对 Softmax 归一化的优化</strong></li></ul><p>但是这样我们还是没有绕开 Softmax 对计算量的消耗。</p><script type="math/tex; mode=display">\begin {align}p(y_i | Context(w)) &= \dfrac {e^{y_i}}{\sum_{k=1}^{|C|} e^{y_k} } \\ &=\dfrac {e^{w_i^Tx}} { \sum_{k=1}^{|C|} e^{w_k^T x}}\end {align}</script><p>上述式子的计算瓶颈在于分母。分母需要枚举一遍词典中所有的词，而词典中的词的数目在 $10^5$ 的量级。同时，我们需要对语料库中的每个词进行训练并按照这个公式计算所有 $y_i$ 的归一化概率，而语料库中的词的数量级通常在 million 甚至 billion 量级，这样一来的话，训练复杂度就无法接受。</p><p>因此，Word2vec 提出了两种优化 Softmax 计算过程的方法，同样也对应着 Word2vec 的两种框架，即： Hieraichical Softmax 和 Negative Sampling。</p><ul><li><strong>Hierarchical Softmax</strong></li></ul><p>本框架之所以叫 Hierarchical Softmax，是因为它利用了树实现了分层的 Softmax，即用树形结构替代了输出层的结构。</p><p>其具体作用原理我们会在后续介绍 CBOW 模型时介绍。</p><ul><li><strong>Negative Sampling</strong></li></ul><p>除了使用上述 Hierarchical Softmax 方法之外，也可以使用 Noise Contrastive Estimation 来优化。</p><blockquote><p>NCE posits that a good model should <strong>be able to differentiate data from noise</strong> by means of <strong>logistic regression</strong>.</p></blockquote><p>Word2vec 采用的 Negative Sampling 是 NCE 的一种简化版本，目的是为了提高训练速度以及改善所得词的质量。相比于 Hierarchical Softmax，Negative Sampling 不再采用 Huffman 树，而是采用<strong>随机负采样</strong>。</p><p>考虑：</p><script type="math/tex; mode=display">\begin {align}p(y_i | Context(w)) &= \dfrac {e^{y_i}}{\sum_{k=1}^{|C|} e^{y_k} } \\ &=\dfrac {e^{w_i^Tx}} { \sum_{k=1}^{|C|} e^{w_k^T x}}\end {align}</script><p>我们要让这个值最大化，也就是说要最大化 $w_i$ 和 $x$ 的余弦相似度，最小化非 $w_i$ 与 $x$ 的余弦相似度。</p><p>我们可以将分子的 $(Context(w), w_i)$​​ 看做一个正样本，将分母的 $(Context(w), w_k)$​​ 看做负样本，这里 $k \ne i$。</p><p>问题在于，上面公式将词典里的几乎所有词都看做了负样本，因此计算分母太耗时间。所以，我们使用 Negative Sampling 的思路，每次只从词典里随机选一些词作为当前词 $w$​ 的负样本（称为 $NCE(w)$​​），而不是以所有的字典里的其他词作为负样本。</p><p>Word2vec 的作者们测试发现，<strong>最佳的分布是 $\frac 3 4$ 次幂的 Unigram Distribution</strong>，也就是说，选中语料库中词 $w$ 的概率为 $\dfrac {count(w)^{3/4}} {\sum_{u \in D}count(u)^{3/4}}$. </p><p>其实在做出随机选取负样本的动作之后，我们就已经抛弃了 Softmax 这个函数所代表的归一化的意思了。也就代表了我们已经不再关注求解<strong>语言模型</strong>的问题，而只关注求解<strong>词向量</strong>的问题。</p><ul><li><strong>Continous Bag-of-words</strong></li></ul><p>这里我们以 CBOW（Continous Bag-of-words）模型来说明 Hierarchical Softmax 的作用方法。</p><p><img src="https://raw.githubusercontent.com/Dounm/TheFarmOfDounm/master/resources/images/word2vec/3.png" alt="2"></p><p>这里首先对上图进行一定的解释：</p><ul><li>$Context(w)$: 由 $w$ 前后各 $c$ 个词构成</li><li>输入层：包含 $2c$ 个词的词向量</li><li>投影层：将 $2c$ 个词向量累加求和得到的 $X_w$</li><li>输出层：输出层对应的是一棵 Huffman 树。该 Huffman 树以语料中出现的词为叶子节点，以各词在语料中<strong>出现的次数当做权值</strong>构造出来的。该树中，叶子节点总共有 $N$ 个（$N = |D| := |Corpus|$）。</li></ul><p>首先定义以下符号：</p><ul><li>$p^w$：从根节点到 $w$ 对应的那个叶子结点在树中的路径</li><li>$l^w$：路径 $p^w$ 上包含的结点数目</li><li>$p^w_1, p^w_2, \cdots, p^w_{l^w}$：路径 $p^w$ 上对应的结点</li><li>$d^w_2, d^w_3, \cdots, d^w_{l^w}$：路径 $p^w$ 上的结点对应的 Huffman 编码</li><li>$\theta^w_1, \theta^w_2, \cdots, \theta^w_{l^w}$：路径 $p^w$ 上非叶子结点对应的词向量</li></ul><p>从根节点出发到某个叶子节点的路径上，每次分支都可视为进行了一次<strong>二分类</strong>。以下的推导过程中，我们默认左边（编码为0）是负类，右边（编码为1）是正类。于是有：</p><ul><li>分为正类的概率：$\sigma(X_w^T\theta) = \dfrac 1 {1 + e^{-X_w^T\theta}}$</li><li>分为负类的概率：$1-\sigma(X_w^T\theta)$</li></ul><p>其中 $\theta$ 即为当前非叶子结点的对应词向量。</p><p>所以 Hierarchical Softmax 的思想就是：<strong>对于词典 $D$ 中的任意词 $w$，Huffman 树中必存在一条从根节点到词对应叶子节点 $w$ 的路径 $p^w$。这条路径 $p^w$ 上存在 $l^w-1$ 个分支，将每个分支看做一次二分类，每次分类就产生一个概率，将这些概率连乘，即得到我们所需近似的 $p(w | Context(w))$</strong>。</p><p>然后我们就可以使用极大似然法，只需将这个近似的条件概率最大化，就可以达到我们想要的训练效果。这里我们略去对其求梯度的推导过程。</p><ul><li><strong>Skip-gram</strong></li></ul><p>Skip-gram 模型是已知当前词 $w$，对其上下文中的词 $Context(w)$ 进行预测。</p><p>举个例子，假设文本序列是 “the”“man”“loves”“his”“son”。以 “loves” 作为中心词，设背景窗口大小为 2。Skip-gram 模型所关心的是，给定中心词 “loves”，生成与它距离不超过 2 个词的背景词 “the”“man”“his”“son” 的条件概率，即</p><script type="math/tex; mode=display">P(the, man, his, son | loves) \\= P(the |loves) P(man | loves) P(his | loves) P(son | loves)</script><p>我们要做的就是使用极大似然法最大化这个条件概率。</p><h3 id="fastText"><a href="#fastText" class="headerlink" title="fastText"></a>fastText</h3><p>在 Word2Vec 中，我们并没有直接利用构词学中的信息。无论是在跳字模型还是连续词袋模型中，我们都将形态不同的单词用不同的向量来表示。例如，“dog” 和 “dogs” 分别用两个不同的向量表示，而模型中并未直接表达这两个向量之间的关系。鉴于此，fastText 提出了子词嵌入的方法，从而试图将构词信息引入 Word2Vec 中的跳字模型。</p><p>在 fastText 中，每个中心词被表示成子词的集合。下面我们用单词 “where” 作为例子来了解子词是如何产生的。首先，我们在单词的首尾分别添加特殊字符 “&lt;” 和 “&gt;” 以区分作为前后缀的子词。然后，将单词当成一个由字符构成的序列来提取 $n$​ 元语法。例如，当 $n=3$​ 时，我们得到所有长度为3的子词：<code>“&lt;wh&gt;”“whe”“her”“ere”“&lt;re&gt;”</code> 以及特殊子词 <code>“&lt;where&gt;”</code>。</p><p>在 fastText 中，对于一个词 $w$​​，我们将它所有长度在 $3 \sim 6$​ ​的子词和特殊子词的并集记为 $\mathcal{G}_w$​​。那么词典则是所有词的子词集合的并集。假设词典中子词 $g$​​ 的向量为 $\boldsymbol{z}_g$​​，那么跳字模型中词 $w$​​ 的作为中心词的向量 $\boldsymbol{v}_w$ ​​​则表示成</p><script type="math/tex; mode=display">\boldsymbol{v}_w = \sum_{g\in\mathcal{G}_w} \boldsymbol{z}_g.</script><h3 id="GloVe"><a href="#GloVe" class="headerlink" title="GloVe"></a>GloVe</h3><ul><li>在有些情况下，交叉熵损失函数有劣势。GloVe 模型采用了平方损失，并通过词向量拟合预先基于整个数据集计算得到的全局统计信息。</li><li>任意词的中心词向量和背景词向量在 GloVe 模型中是等价的。</li></ul><h3 id="Encoder-Decoder"><a href="#Encoder-Decoder" class="headerlink" title="Encoder-Decoder"></a>Encoder-Decoder</h3><ul><li>总览</li></ul><p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter10/10.9_seq2seq.svg" alt="img"></p><p>图中描述了使用编码器—解码器将上述英语句子翻译成法语句子的一种方法。</p><p>在训练数据集中，我们可以在每个句子后附上特殊符号“&lt;eos&gt;”（end of sequence）以表示序列的终止。</p><p>编码器每个时间步的输入依次为英语句子中的单词、标点和特殊符号“&lt;eos&gt;”。图中使用了编码器在最终时间步的隐藏状态作为输入句子的表征或编码信息。</p><p>解码器在各个时间步中使用输入句子的编码信息和上个时间步的输出以及隐藏状态作为输入。我们希望解码器在各个时间步能正确依次输出翻译后的法语单词、标点和特殊符号”&lt;eos&gt;”。</p><p>需要注意的是，解码器在最初时间步的输入用到了一个表示序列开始的特殊符号”&lt;bos&gt;”（beginning of sequence）。</p><ul><li>Encoder (Usually RNN)</li></ul><p>编码器的作用是把一个不定长的输入序列变换成一个定长的背景变量 $\boldsymbol{c}$，并在该背景变量中编码输入序列信息。常用的编码器是循环神经网络。</p><p>让我们考虑批量大小为 1 的时序数据样本。假设输入序列是 $x_1,\ldots,x_T$，$x_i$ 是输入句子中的第 $i$ 个词。在时间步 $t$，循环神经网络将输入 $x_t$ 的特征向量 $\boldsymbol{x}_t$ 和上个时间步的隐藏状态 $\boldsymbol{h}_{t-1}$ 变换为当前时间步的隐藏状态 $\boldsymbol{h}_t$。我们可以用函数 $f$ 表达循环神经网络隐藏层的变换：</p><script type="math/tex; mode=display">\boldsymbol{h}_t = f(\boldsymbol{x}_t, \boldsymbol{h}_{t-1})</script><p>接下来，编码器通过自定义函数 $q$ 将各个时间步的隐藏状态变换为背景变量</p><script type="math/tex; mode=display">\boldsymbol{c} =  q(\boldsymbol{h}_1, \ldots, \boldsymbol{h}_T)</script><p>例如，当选择 $q(\boldsymbol{h}_1, \ldots, \boldsymbol{h}_T) = \boldsymbol{h}_T$ 时，背景变量是输入序列最终时间步的隐藏状态 $\boldsymbol{h}_T$。</p><p>以上描述的编码器是一个单向的循环神经网络，每个时间步的隐藏状态只取决于该时间步及之前的输入子序列。我们也可以使用双向循环神经网络构造编码器。在这种情况下，编码器每个时间步的隐藏状态同时取决于该时间步之前和之后的子序列（包括当前时间步的输入），并编码了整个序列的信息。</p><ul><li>Decoder</li></ul><p>刚刚已经介绍，编码器输出的背景变量 $\boldsymbol{c}$ 编码了整个输入序列 $x_1, \ldots, x_T$ 的信息。给定训练样本中的输出序列 $y_1, y_2, \ldots, y_{T’}$，对每个时间步 $t’$（符号与输入序列或编码器的时间步 $t$ 有区别），解码器输出 $y_{t’}$ 的条件概率将基于之前的输出序列 $y_1,\ldots,y_{t’-1}$ 和背景变量 $\boldsymbol{c}$，即$P(y_{t’} \mid y_1, \ldots, y_{t’-1}, \boldsymbol{c})$。</p><p>为此，我们可以使用另一个循环神经网络作为解码器。在输出序列的时间步 $t^\prime$，解码器将上一时间步的输出 $y_{t^\prime-1}$ 以及背景变量 $\boldsymbol{c}$ 作为输入，并将它们与上一时间步的隐藏状态 $\boldsymbol{s}_{t^\prime-1}$ 变换为当前时间步的隐藏状态 $\boldsymbol{s}_{t^\prime}$。因此，我们可以用函数 $g$ 表达解码器隐藏层的变换：</p><script type="math/tex; mode=display">\boldsymbol{s}_{t^\prime} = g(y_{t^\prime-1}, \boldsymbol{c}, \boldsymbol{s}_{t^\prime-1})</script><p>有了解码器的隐藏状态后，我们可以使用自定义的输出层和 softmax 运算来计算 $P(y_{t^\prime} \mid y_1, \ldots, y_{t^\prime-1}, \boldsymbol{c})$，例如，基于当前时间步的解码器隐藏状态 $\boldsymbol{s}_{t^\prime}$、上一时间步的输出 $y_{t^\prime-1}$ 以及背景变量 $\boldsymbol{c}$ 来计算当前时间步输出$y_{t^\prime}$的概率分布。</p><h4 id="Beam-Search"><a href="#Beam-Search" class="headerlink" title="Beam Search"></a>Beam Search</h4><ul><li>输出层的贪婪搜索不一定能得到最优输出序列</li></ul><p>上一节里已经提到，在准备训练数据集时，我们通常会在样本的输入序列和输出序列后面分别附上一个特殊符号 “&lt;eos&gt;” 表示序列的终止。我们在接下来的讨论中也将沿用上一节的全部数学符号。为了便于讨论，假设解码器的输出是一段文本序列。设输出文本词典 $\mathcal{Y}$（包含特殊符号 “&lt;eos&gt;” ）的大小为 $\left|\mathcal{Y}\right|$，输出序列的最大长度为 $T’$。所有可能的输出序列一共有 $\mathcal{O}(\left|\mathcal{Y}\right|^{T’})$ 种。这些输出序列中所有特殊符号 “&lt;eos&gt;” 后面的子序列将被舍弃。</p><p>让我们先来看一个简单的解决方案：贪婪搜索（greedy search）。对于输出序列任一时间步 $t’$​​，我们从 $|\mathcal{Y}|$​​ 个词中搜索出条件概率最大的词</p><script type="math/tex; mode=display">y _ { t ^ { \prime } } = \underset { y \in \mathcal { Y } } { \operatorname { argmax } } P \left( y | y _ { 1 } , \ldots , y _ { t ^ { \prime } - 1 } , c \right)</script><p>作为输出。一旦搜索出 “&lt;eos&gt;” 符号，或者输出序列长度已经达到了最大长度 $T’$​，便完成输出。</p><p>这样做的问题是，这样“逐层贪心”的策略不一定能够得到最优输出序列。</p><ul><li>穷举搜索的开销过于庞大</li><li>Beam Search!</li></ul><p>束搜索（beam search）是对贪婪搜索的一个改进算法。</p><p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter10/10.10_beam_search.svg" alt="img"></p><p>它有一个束宽（beam size）超参数。我们将它设为 $k$​​。在时间步1时，选取当前时间步条件概率最大的 $k$​​ 个词，分别组成 $k$​​ 个候选输出序列的首词。在之后的每个时间步，基于上个时间步的 $k$ ​​个候选输出序列，从 $k\left|\mathcal{Y}\right|$​​ 个可能的输出序列中选取条件概率最大的 $k$​ ​​个，作为该时间步的候选输出序列。最终，我们从各个时间步的候选输出序列中筛选出包含特殊符号 “&lt;eos&amp; gt;”的序列，并将它们中所有特殊符号 “&lt;eos&gt;” 后面的子序列舍弃，得到最终候选输出序列的集合。</p><p>在最终候选输出序列的集合中，我们取以下分数最高的序列作为输出序列：</p><script type="math/tex; mode=display">\frac{1}{L^\alpha} \log P(y_1, \ldots, y_{L}) = \frac{1}{L^\alpha} \sum_{t'=1}^L \log P(y_{t'} \mid y_1, \ldots, y_{t'-1}, \boldsymbol{c})</script><p>其中 $L$​​ 为最终候选序列长度，$\alpha$​​ 一般可选为0.75。分母上的 $L^\alpha$ ​​是为了惩罚较长序列在以上分数中较多的对数相加项。分析可知，束搜索的计算开销为 $\mathcal{O}(k\left|\mathcal{Y}\right|T’)$​​。这介于贪婪搜索和穷举搜索的计算开销之间。此外，贪婪搜索可看作是束宽为 1 的束搜索。束搜索通过灵活的束宽 $k$ ​​来权衡计算开销和搜索质量。</p><h3 id="Attention-Mechanism"><a href="#Attention-Mechanism" class="headerlink" title="Attention Mechanism"></a>Attention Mechanism</h3><p>现在，让我们再次思考上一节提到的翻译例子：输入为英语序列 “They”“are”“watching”“.”，输出为法语序列 “Ils”“regardent”“.”。</p><p>不难想到，解码器在生成输出序列中的每一个词时可能只需利用输入序列某一部分的信息。例如，在输出序列的时间步 1，解码器可以主要依赖 “They”“are” 的信息来生成 “Ils”，在时间步 2 则主要使用来自 “watching” 的编码信息生成 “regardent”，最后在时间步3则直接映射句号 “.”。这看上去就像是在解码器的每一时间步对输入序列中不同时间步的表征或编码信息分配不同的注意力一样。这也是注意力机制的由来。</p><p>仍然以循环神经网络为例，注意力机制通过对编码器所有时间步的隐藏状态做加权平均来得到背景变量。解码器在每一时间步调整这些权重，即注意力权重，从而能够在不同时间步分别关注输入序列中的不同部分并编码进相应时间步的背景变量。本节我们将讨论注意力机制是怎么工作的。</p><p>在上一节里我们区分了输入序列或编码器的索引 $t$ ​与输出序列或解码器的索引 $t’$​。该节中，解码器在时间步 $t’$ ​的隐藏状态 $\boldsymbol{s}_{t’} = g(\boldsymbol{y}_{t’-1}, \boldsymbol{c}, \boldsymbol{s}_{t’-1})$，其中 $\boldsymbol{y}_{t’-1}$​ 是上一时间步 $t’-1$​ 的输出 $y_{t’-1}$ ​的表征，且任一时间步 $t’$ ​使用相同的背景变量 $\boldsymbol{c}$​。</p><p>但在注意力机制中，解码器的每一时间步将使用可变的背景变量。记 $\boldsymbol{c}_{t’}$ ​是解码器在时间步 $t’$ ​的背景变量，那么解码器在该时间步的隐藏状态可以改写为：$\boldsymbol{s}_{t’} = g(\boldsymbol{y}_{t’-1}, \boldsymbol{c}_{t’}, \boldsymbol{s}_{t’-1})$。</p><p>这里的关键是如何计算背景变量 $\boldsymbol{c}_{t’}$ ​和如何利用它来更新隐藏状态 $\boldsymbol{s}_{t’}$​。下面将分别描述这两个关键点。</p><ul><li><strong>计算背景变量</strong></li></ul><p>我们先描述第一个关键点，即计算背景变量。</p><p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter10/10.11_attention.svg" alt="img"></p><p>图中描绘了注意力机制如何为解码器在时间步 2 计算背景变量。</p><p>首先，函数 $a$​​​ 根据解码器在时间步 1 的隐藏状态和编码器在各个时间步的隐藏状态计算 softmax 运算的输入。softmax 运算输出概率分布并对编码器各个时间步的隐藏状态做加权平均，从而得到背景变量。</p><p>具体来说，令编码器在时间步 $t$ 的隐藏状态为 $\boldsymbol{h}_t$，且总时间步数为 $T$。那么解码器在时间步 $t’$ ​的背景变量为所有编码器隐藏状态的加权平均：</p><script type="math/tex; mode=display">\boldsymbol{c}_{t'} = \sum_{t=1}^T \alpha_{t' t} \boldsymbol{h}_t,</script><p>其中给定 $t’$​ 时，权重 $\alpha_{t’ t}$ ​在 $t=1,\ldots,T$ ​的值是一个概率分布。为了得到概率分布，我们可以使用 softmax 运算:</p><script type="math/tex; mode=display">\alpha_{t' t} = \frac{\exp(e_{t' t})}{ \sum_{k=1}^T \exp(e_{t' k}) },\quad t=1,\ldots,T.</script><p>现在，我们需要定义如何计算上式中 softmax 运算的输入 $e_{t’ t}$​​。由于 $e_{t’ t} $ ​​同时取决于解码器的时间步 $t’$​​ 和编码器的时间步 $t$​​，我们不妨以解码器在时间步 $t’-1$ ​​的隐藏状态 $\boldsymbol{s}_{t’ - 1}$ ​​与编码器在时间步 $t$​​ 的隐藏状态 $\boldsymbol{h}_t$​​ 为输入，并通过函数 $a$ ​​计算$e_{t’ t}$​​：</p><script type="math/tex; mode=display">e_{t' t} = a(\boldsymbol{s}_{t' - 1}, \boldsymbol{h}_t).</script><p>这里函数 $a$ ​有多种选择，如果两个输入向量长度相同，一个简单的选择是计算它们的内积 $a(\boldsymbol{s}, \boldsymbol{h})=\boldsymbol{s}^\top \boldsymbol{h}$​。而最早提出注意力机制的论文则将输入连结后通过含单隐藏层的多层感知机变换：</p><script type="math/tex; mode=display">a(\boldsymbol{s}, \boldsymbol{h}) = \boldsymbol{v}^\top \tanh(\boldsymbol{W}_s \boldsymbol{s} + \boldsymbol{W}_h \boldsymbol{h}),</script><p>其中$\boldsymbol{v}$​、$\boldsymbol{W}_s$​、$\boldsymbol{W}_h$​都是可以学习的模型参数。</p><ul><li><strong>矢量化计算</strong> (Query, Key &amp; Value)</li></ul><p>广义上，注意力机制的输入包括 query 以及对应的 key 和 value，其中 value 是需要加权平均的一组项。在加权平均中，value 的权重来自 $a(query, key)$。</p><p>在上面的例子中，查询项为解码器的隐藏状态 $s_{t’-1}$，Key 和 Value 均为编码器的隐藏状态 $h_t$。</p><p>让我们考虑一个常见的简单情形，即编码器和解码器的隐藏单元个数均为 $h$，且函数$a(\boldsymbol{s}, \boldsymbol{h})=\boldsymbol{s}^\top \boldsymbol{h}$。</p><p>假设我们希望根据解码器单个隐藏状态 $\boldsymbol{s}_{t’ - 1} \in \mathbb{R}^{h}$ 和编码器所有隐藏状态 $\boldsymbol{h}_t \in \mathbb{R}^{h}, t = 1,\ldots,T$ 来计算背景向量$\boldsymbol{c}_{t’}\in \mathbb{R}^{h}$。</p><p>我们可以将查询项矩阵 $\boldsymbol{Q} \in \mathbb{R}^{1 \times h}$ 设为 $\boldsymbol{s}_{t’ - 1}^\top$，并令键项矩阵 $\boldsymbol{K} \in \mathbb{R}^{T \times h}$ 和值项矩阵 $\boldsymbol{V} \in \mathbb{R}^{T \times h}$ 相同且第 $t$ 行均为 $\boldsymbol{h}_t^\top$​。</p><p>此时，我们只需要通过矢量化计算 $\text{softmax}(\boldsymbol{Q}\boldsymbol{K}^\top)\boldsymbol{V}$​​ 即可算出转置后的背景向量 $\boldsymbol{c}_{t’}^\top$。</p><p>当查询项矩阵 $\boldsymbol{Q}$ 的行数为 $n$ 时，上式将得到 $n$ 行的输出矩阵。输出矩阵与查询项矩阵在相同行上一一对应。</p><ul><li><strong>更新隐藏状态</strong> (GRU)</li></ul><p>以门控循环单元为例，在解码器中我们可以对 GRU 中门控循环单元的设计稍作修改，从而变换上一时间步 $t’-1$ 的输出 $\boldsymbol{y}_{t’-1}$、隐藏状态 $\boldsymbol{s}_{t’ - 1}$ 和当前时间步 $t’$ 的含注意力机制的背景变量 $\boldsymbol{c}_{t’}$。</p><p>解码器在时间步 $t’$ 的隐藏状态为：$\boldsymbol{s}_{t’} = \boldsymbol{z}_{t’} \odot \boldsymbol{s}_{t’-1}  + (1 - \boldsymbol{z}_{t’}) \odot \tilde{\boldsymbol{s}}_{t’}$.​</p><p>其中的重置门、更新门和候选隐藏状态分别为</p><script type="math/tex; mode=display">\begin{aligned}\boldsymbol{r}_{t'} &= \sigma(\boldsymbol{W}_{yr} \boldsymbol{y}_{t'-1} + \boldsymbol{W}_{sr} \boldsymbol{s}_{t' - 1} + \boldsymbol{W}_{cr} \boldsymbol{c}_{t'} + \boldsymbol{b}_r),\\\boldsymbol{z}_{t'} &= \sigma(\boldsymbol{W}_{yz} \boldsymbol{y}_{t'-1} + \boldsymbol{W}_{sz} \boldsymbol{s}_{t' - 1} + \boldsymbol{W}_{cz} \boldsymbol{c}_{t'} + \boldsymbol{b}_z),\\\tilde{\boldsymbol{s}}_{t'} &= \text{tanh}(\boldsymbol{W}_{ys} \boldsymbol{y}_{t'-1} + \boldsymbol{W}_{ss} (\boldsymbol{s}_{t' - 1} \odot \boldsymbol{r}_{t'}) + \boldsymbol{W}_{cs} \boldsymbol{c}_{t'} + \boldsymbol{b}_s),\end{aligned}</script><p>其中含下标的 $\boldsymbol{W}$ ​和 $\boldsymbol{b}$ ​分别为门控循环单元的权重参数和偏差参数。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://tangshusen.me/Dive-into-DL-PyTorch/img/cover.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;《动手学深度学习》原书地址：&lt;a href=&quot;https://github.com/d2l-ai/d2l-zh&quot;&gt;https://github.com/d2l-ai/d2l-zh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;《动手学深度学习》(Pytorch ver.)：&lt;a href=&quot;https://tangshusen.me/Dive-into-DL-PyTorch/#/&quot;&gt;https://tangshusen.me/Dive-into-DL-PyTorch/#/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;知识架构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tangshusen.me/Dive-into-DL-PyTorch/img/book-org.svg&quot; alt=&quot;封面&quot;&gt;&lt;/p&gt;
&lt;p&gt;本文的主要作用是在阅读过程中做一些摘录。对于「机器学习」领域， c7w 虽然曾尝试从各个领域入门，也尝试训过一些模型，但是还是缺少系统性、结构性的学习。希望阅读本书能带来更多的收获吧。&lt;/p&gt;
&lt;p&gt;与前面的一些笔记相比，本文更加侧重于「实践」。也就是说切实地提升自己的代码能力。&lt;/p&gt;
&lt;p&gt;Part C 包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;§ 7 优化算法&lt;ul&gt;
&lt;li&gt;优化与深度学习，优化存在的挑战&lt;/li&gt;
&lt;li&gt;梯度下降（略）&lt;/li&gt;
&lt;li&gt;Momentum, Adagrad&lt;/li&gt;
&lt;li&gt;RMSProp, AdaDelta&lt;/li&gt;
&lt;li&gt;Adam&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;§ 8 计算性能&lt;ul&gt;
&lt;li&gt;多 GPU 计算&lt;/li&gt;
&lt;li&gt;多 GPU 计算时模型的保存与加载&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;§ 10 NLP&lt;ul&gt;
&lt;li&gt;Word2Vec, fastText, GloVe&lt;/li&gt;
&lt;li&gt;Encoder-Decoder, Beam Search&lt;/li&gt;
&lt;li&gt;Attention&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="理论" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/"/>
    
    <category term="理论/机器学习" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/%E7%90%86%E8%AE%BA-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://www.c7w.tech/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>《动手学深度学习》 Pytorch ver. 阅读后练习</title>
    <link href="https://www.c7w.tech/dive-into-dl-pytorch-practice/"/>
    <id>https://www.c7w.tech/dive-into-dl-pytorch-practice/</id>
    <published>2022-01-26T13:44:56.000Z</published>
    <updated>2022-01-28T08:20:45.206Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/cover.png" alt=""></p><ul><li>《动手学深度学习》原书地址：<a href="https://github.com/d2l-ai/d2l-zh">https://github.com/d2l-ai/d2l-zh</a></li><li>《动手学深度学习》(Pytorch ver.)：<a href="https://tangshusen.me/Dive-into-DL-PyTorch/#/">https://tangshusen.me/Dive-into-DL-PyTorch/#/</a></li></ul><p>知识架构：</p><p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/book-org.svg" alt="封面"></p><p>本文的主要作用是在阅读过程中做一些摘录。对于「机器学习」领域，c7w 虽然曾尝试从各个领域入门，也尝试训过一些模型，但是还是缺少系统性、结构性的学习。希望阅读本书能带来更多的收获吧。</p><p>与前面的一些笔记相比，本文更加侧重于「实践」。也就是说切实地提升自己的代码能力。</p><p>本部分包含：</p><ol><li>{Finished} [5-5] 实现一个可以实现表情识别的类 CNN 网络并训练，重点在于造出一个机器学习的框架，然后评估其准确率。</li><li>{Finished} [5-11, 5-12] 实现 ResNet 和 DenseNet，注意体会怎样才能使得运算维度匹配。</li></ol><a id="more"></a><h2 id="5-5-CNN"><a href="#5-5-CNN" class="headerlink" title="[5-5] CNN"></a>[5-5] CNN</h2><p>主要是把训练模型的轮子连抄带造写了一遍。</p><ul><li><code>train.py</code></li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> toolkit<span class="token punctuation">.</span>dataset <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">import</span> torch<span class="token keyword">from</span> toolkit<span class="token punctuation">.</span>utils <span class="token keyword">import</span> get_device<span class="token keyword">from</span> toolkit<span class="token punctuation">.</span>net <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> toolkit<span class="token punctuation">.</span>procedure <span class="token keyword">import</span> <span class="token operator">*</span><span class="token comment"># By c7w, created on 2022/1/27.</span><span class="token triple-quoted-string string">'''Usage:+ Define your model in toolkit/net.py+ Define your dataset in toolkit/dataset.py+ Define configuration in main.py'''</span>device <span class="token operator">=</span> get_device<span class="token punctuation">(</span><span class="token punctuation">)</span>device <span class="token operator">=</span> <span class="token string">'cpu'</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Now on </span><span class="token interpolation"><span class="token punctuation">&#123;</span>device<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token comment"># Configuration Here</span>config <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">'epochs'</span><span class="token punctuation">:</span> <span class="token number">10000</span><span class="token punctuation">,</span>    <span class="token string">'batch_size'</span><span class="token punctuation">:</span> <span class="token number">16</span><span class="token punctuation">,</span>    <span class="token comment"># 'optimizer': in training stage</span>    <span class="token string">'early_stop'</span><span class="token punctuation">:</span> <span class="token number">20</span><span class="token punctuation">,</span>    <span class="token string">'save_path'</span><span class="token punctuation">:</span> <span class="token string">'save/model2-rms.pth'</span><span class="token punctuation">&#125;</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment"># Data Preparation Stage</span>    tr_data <span class="token operator">=</span> Data<span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">)</span>    vd_data <span class="token operator">=</span> Data<span class="token punctuation">(</span><span class="token string">'valid'</span><span class="token punctuation">)</span>    tt_data <span class="token operator">=</span> Data<span class="token punctuation">(</span><span class="token string">'test'</span><span class="token punctuation">)</span>    tr_set <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>tr_data<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    vd_set <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>vd_data<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    tt_set <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>tt_data<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        <span class="token comment"># Training Stage</span>    model <span class="token operator">=</span> LeNet<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    <span class="token comment"># config['optimizer'] = torch.optim.Adam(model.parameters())</span>    config<span class="token punctuation">[</span><span class="token string">'optimizer'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model_loss<span class="token punctuation">,</span> model_loss_record <span class="token operator">=</span> train<span class="token punctuation">(</span>tr_set<span class="token punctuation">,</span> vd_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> config<span class="token punctuation">,</span> device<span class="token punctuation">)</span>    <span class="token comment"># Test Stage</span>    <span class="token keyword">del</span> model    model <span class="token operator">=</span> LeNet<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    acc <span class="token operator">=</span> test<span class="token punctuation">(</span>tt_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>acc<span class="token punctuation">)</span></code></pre><ul><li><code>toolkit/dataset.py</code></li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> random<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token keyword">from</span> icecream <span class="token keyword">import</span> ic<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">class</span> <span class="token class-name">Data</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mode<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>mode <span class="token operator">=</span> mode        data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"./project/data.csv"</span><span class="token punctuation">)</span>                usage <span class="token operator">=</span> <span class="token string">"Test"</span> <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">"test"</span> <span class="token keyword">else</span> <span class="token string">"Training"</span>        data <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>data<span class="token punctuation">.</span>Usage <span class="token operator">==</span> usage<span class="token punctuation">]</span>                features <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                <span class="token keyword">for</span> r<span class="token punctuation">,</span> row <span class="token keyword">in</span> data<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>  <span class="token builtin">int</span><span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token string">'emotion'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">)</span>            feature <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>number<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span> <span class="token keyword">for</span> number <span class="token keyword">in</span> row<span class="token punctuation">[</span><span class="token string">'pixels'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            features<span class="token punctuation">.</span>append<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>feature<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>data <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">)</span>        random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>                <span class="token comment"># im = Image.fromarray((self.data[0][0].view(48, 48) * 255).numpy())</span>        <span class="token comment"># im = im.convert('L')</span>        <span class="token comment"># ic(self.data[0][0], self.data[0][1])</span>        <span class="token comment"># im.show()</span>                l <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">10</span>        <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'valid'</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>data <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token operator">-</span>l <span class="token punctuation">:</span> <span class="token punctuation">]</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>data <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span> <span class="token punctuation">:</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span> <span class="token operator">-</span> l<span class="token punctuation">]</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Reading </span><span class="token interpolation"><span class="token punctuation">&#123;</span>mode<span class="token punctuation">&#125;</span></span><span class="token string"> set finished with </span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string"> samples in total."</span></span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Example:"</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>            <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span></code></pre><ul><li><code>toolkit/net.py</code></li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">class</span> <span class="token class-name">LeNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>LeNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            <span class="token comment"># Conv Layer</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        <span class="token comment"># FC Layer</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token operator">*</span><span class="token number">6</span><span class="token operator">*</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>                self<span class="token punctuation">.</span>Loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>Loss<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><ul><li><code>toolkit/procedure.py</code></li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>tr_set<span class="token punctuation">,</span> vd_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> config<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    max_epoch_count <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'epochs'</span><span class="token punctuation">]</span>    optimizer <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'optimizer'</span><span class="token punctuation">]</span>    loss_record <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'train'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'valid'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span>    curr_min_loss <span class="token operator">=</span> <span class="token number">1145141919810.0</span>    early_stop_cnt <span class="token operator">=</span> <span class="token number">0</span>    epoch <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">while</span> epoch <span class="token operator">&lt;</span> max_epoch_count<span class="token punctuation">:</span>        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> tr_set<span class="token punctuation">:</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                        l <span class="token operator">=</span> model<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>            l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                        loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>l<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        valid_mse <span class="token operator">=</span> validate<span class="token punctuation">(</span>vd_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch &#123;:4d&#125; completed, tr_loss = &#123;:.4f&#125;'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> valid_mse<span class="token punctuation">)</span><span class="token punctuation">)</span>                        <span class="token keyword">if</span> valid_mse <span class="token operator">&lt;</span> curr_min_loss<span class="token punctuation">:</span>            <span class="token comment"># Save model if model improved</span>            curr_min_loss <span class="token operator">=</span> valid_mse                        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Saving model (epoch = &#123;:4d&#125;, loss = &#123;:.4f&#125;)'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> curr_min_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># Save model to specified path</span>            early_stop_cnt <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            early_stop_cnt <span class="token operator">+=</span> <span class="token number">1</span>        epoch <span class="token operator">+=</span> <span class="token number">1</span>        loss_record<span class="token punctuation">[</span><span class="token string">'valid'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>valid_mse<span class="token punctuation">)</span>        <span class="token keyword">if</span> early_stop_cnt <span class="token operator">></span> config<span class="token punctuation">[</span><span class="token string">'early_stop'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token comment"># Stop training if your model stops improving for "config['early_stop']" epochs.</span>            <span class="token keyword">break</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Finished training after </span><span class="token interpolation"><span class="token punctuation">&#123;</span>epoch<span class="token punctuation">&#125;</span></span><span class="token string"> epochs.'</span></span><span class="token punctuation">)</span>    <span class="token keyword">return</span> curr_min_loss<span class="token punctuation">,</span> loss_record<span class="token keyword">def</span> <span class="token function">validate</span><span class="token punctuation">(</span>vd_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    total_loss <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> vd_set<span class="token punctuation">:</span>        x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            vd_loss <span class="token operator">=</span> model<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>        total_loss <span class="token operator">+=</span> vd_loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>        total_loss <span class="token operator">=</span> total_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vd_set<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>              <span class="token comment"># compute averaged loss</span>    <span class="token keyword">return</span> total_loss<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>tt_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    total_right <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> tt_set<span class="token punctuation">:</span>        x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>                <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>                 <span class="token keyword">for</span> i<span class="token punctuation">,</span> logit <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logit<span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span> total_right <span class="token operator">+=</span> <span class="token number">1</span>                acc <span class="token operator">=</span> total_right <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tt_set<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>              <span class="token comment"># compute averaged loss</span>    <span class="token keyword">return</span> acc<span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>tt_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> x <span class="token keyword">in</span> tt_set<span class="token punctuation">:</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> preds</code></pre><ul><li><code>toolkit/utils.py</code></li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">def</span> <span class="token function">get_device</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token keyword">def</span> <span class="token function">get_one_hot</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> dim<span class="token punctuation">)</span><span class="token punctuation">:</span>    t <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span>dim<span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span>    t<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>    <span class="token keyword">return</span> t</code></pre><ul><li>训练结果</li></ul><pre class="language-none"><code class="language-none">Now on cpuReading train set finished with 25839 samples in total.Example:(tensor([[[0.2000, 0.1922, 0.2118,  ..., 0.1804, 0.2392, 0.2863],         [0.1922, 0.1843, 0.1647,  ..., 0.2392, 0.2078, 0.2588],         [0.1961, 0.1804, 0.1608,  ..., 0.2039, 0.1569, 0.2000],         ...,         [0.3098, 0.1961, 0.2353,  ..., 0.2980, 0.3255, 0.3412],         [0.2706, 0.1647, 0.2471,  ..., 0.3098, 0.3294, 0.3373],         [0.2392, 0.1686, 0.2157,  ..., 0.3255, 0.3333, 0.3490]]]), 3)Reading valid set finished with 2870 samples in total.Example:(tensor([[[0.1725, 0.1333, 0.1451,  ..., 0.3176, 0.3216, 0.4510],         [0.1333, 0.1333, 0.1255,  ..., 0.3137, 0.3216, 0.4471],         [0.1333, 0.1216, 0.1137,  ..., 0.3137, 0.3216, 0.4471],         ...,         [0.3922, 0.3255, 0.4039,  ..., 0.4000, 0.4510, 0.5137],         [0.3882, 0.3098, 0.3961,  ..., 0.3843, 0.4549, 0.5333],         [0.4000, 0.2745, 0.3725,  ..., 0.3961, 0.4392, 0.5137]]]), 3)Reading test set finished with 6461 samples in total.Example:(tensor([[[0.7373, 0.7608, 0.7255,  ..., 0.8549, 0.8157, 0.8275],         [0.7529, 0.7608, 0.7137,  ..., 0.8588, 0.8314, 0.8157],         [0.7804, 0.7451, 0.7137,  ..., 0.8510, 0.8353, 0.8157],         ...,         [0.4784, 0.5765, 0.5804,  ..., 0.6863, 0.5451, 0.4235],         [0.2549, 0.3373, 0.4588,  ..., 0.5804, 0.5373, 0.5608],         [0.3608, 0.3961, 0.6275,  ..., 0.5569, 0.3176, 0.6314]]]), 3)Epoch    1 completed, tr_loss &#x3D; 1.4529Saving model (epoch &#x3D;    1, loss &#x3D; 1.4529)Epoch    2 completed, tr_loss &#x3D; 1.2995Saving model (epoch &#x3D;    2, loss &#x3D; 1.2995)Epoch    3 completed, tr_loss &#x3D; 1.1131Saving model (epoch &#x3D;    3, loss &#x3D; 1.1131)Epoch    4 completed, tr_loss &#x3D; 1.0275Saving model (epoch &#x3D;    4, loss &#x3D; 1.0275)Epoch    5 completed, tr_loss &#x3D; 1.1062Epoch    6 completed, tr_loss &#x3D; 0.8805Saving model (epoch &#x3D;    6, loss &#x3D; 0.8805)Epoch    7 completed, tr_loss &#x3D; 0.7520Saving model (epoch &#x3D;    7, loss &#x3D; 0.7520)Epoch    8 completed, tr_loss &#x3D; 0.8390Epoch    9 completed, tr_loss &#x3D; 0.8715Epoch   10 completed, tr_loss &#x3D; 0.6758Saving model (epoch &#x3D;   10, loss &#x3D; 0.6758)Epoch   11 completed, tr_loss &#x3D; 0.6634Saving model (epoch &#x3D;   11, loss &#x3D; 0.6634)Epoch   12 completed, tr_loss &#x3D; 0.5063Saving model (epoch &#x3D;   12, loss &#x3D; 0.5063)Epoch   13 completed, tr_loss &#x3D; 0.5055Saving model (epoch &#x3D;   13, loss &#x3D; 0.5055)Epoch   14 completed, tr_loss &#x3D; 0.6266Epoch   15 completed, tr_loss &#x3D; 0.4653Saving model (epoch &#x3D;   15, loss &#x3D; 0.4653)Epoch   16 completed, tr_loss &#x3D; 0.4373Saving model (epoch &#x3D;   16, loss &#x3D; 0.4373)Epoch   17 completed, tr_loss &#x3D; 0.3892Saving model (epoch &#x3D;   17, loss &#x3D; 0.3892)Epoch   18 completed, tr_loss &#x3D; 0.4048Epoch   19 completed, tr_loss &#x3D; 0.4376Epoch   20 completed, tr_loss &#x3D; 0.3657Saving model (epoch &#x3D;   20, loss &#x3D; 0.3657)Epoch   21 completed, tr_loss &#x3D; 0.3765Epoch   22 completed, tr_loss &#x3D; 0.3329Saving model (epoch &#x3D;   22, loss &#x3D; 0.3329)Epoch   23 completed, tr_loss &#x3D; 0.3969Epoch   24 completed, tr_loss &#x3D; 0.3382Epoch   25 completed, tr_loss &#x3D; 0.3283Saving model (epoch &#x3D;   25, loss &#x3D; 0.3283)Epoch   26 completed, tr_loss &#x3D; 0.3192Saving model (epoch &#x3D;   26, loss &#x3D; 0.3192)Epoch   27 completed, tr_loss &#x3D; 0.3671Epoch   28 completed, tr_loss &#x3D; 0.3457Epoch   29 completed, tr_loss &#x3D; 0.3352Epoch   30 completed, tr_loss &#x3D; 0.3461Epoch   31 completed, tr_loss &#x3D; 0.3258Epoch   32 completed, tr_loss &#x3D; 0.3097Saving model (epoch &#x3D;   32, loss &#x3D; 0.3097)Epoch   33 completed, tr_loss &#x3D; 0.3976Epoch   34 completed, tr_loss &#x3D; 0.3364Epoch   35 completed, tr_loss &#x3D; 0.3275Epoch   36 completed, tr_loss &#x3D; 0.3179Epoch   37 completed, tr_loss &#x3D; 0.3415Epoch   38 completed, tr_loss &#x3D; 0.3471Epoch   39 completed, tr_loss &#x3D; 0.3302Epoch   40 completed, tr_loss &#x3D; 0.3407Epoch   41 completed, tr_loss &#x3D; 0.4045Epoch   42 completed, tr_loss &#x3D; 0.3310Epoch   43 completed, tr_loss &#x3D; 0.3626Epoch   44 completed, tr_loss &#x3D; 0.3288Epoch   45 completed, tr_loss &#x3D; 0.3600Epoch   46 completed, tr_loss &#x3D; 0.3866Epoch   47 completed, tr_loss &#x3D; 0.3613Epoch   48 completed, tr_loss &#x3D; 0.3402Epoch   49 completed, tr_loss &#x3D; 0.3562Epoch   50 completed, tr_loss &#x3D; 0.3674Epoch   51 completed, tr_loss &#x3D; 0.3733Epoch   52 completed, tr_loss &#x3D; 0.3461Epoch   53 completed, tr_loss &#x3D; 0.3542Finished training after 53 epochs.0.5304132487231079</code></pre><h2 id="Resnet-amp-DenseNet-5-11-5-12"><a href="#Resnet-amp-DenseNet-5-11-5-12" class="headerlink" title="Resnet &amp; DenseNet (5-11, 5-12)"></a>Resnet &amp; DenseNet (5-11, 5-12)</h2><ul><li><code>main.py</code></li></ul><p>随机生成数据，模拟 <code>batch_size = 4</code>，<code>input_channels = 3</code>, <code>pic_size = 96x96</code> 的情况，然后将其丢入实现的网络中查看运行结果，没有发生错误则说明维度对应正确。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> ResNet <span class="token keyword">import</span> ResNet<span class="token keyword">from</span> DenseNet <span class="token keyword">import</span> DenseNet<span class="token keyword">from</span> icecream <span class="token keyword">import</span> ic <span class="token keyword">as</span> <span class="token keyword">print</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># print(data)</span><span class="token comment"># net = ResNet(3)</span>net <span class="token operator">=</span> DenseNet<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token comment"># print(net(data))</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span></code></pre><ul><li><code>ResNet.py</code></li></ul><p>本文件中实现了 ResNet-18.</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token comment"># Implementation of ResNet-18</span><span class="token keyword">class</span> <span class="token class-name">Residual</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># Stride: to control the height/width of the manipulating data</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>                <span class="token comment"># If in_channels != out_channels</span>        <span class="token comment"># Then use 1x1 conv layer to change channel size</span>        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">)</span> <span class="token keyword">if</span> in_channels <span class="token operator">!=</span> out_channels <span class="token keyword">else</span> <span class="token boolean">None</span>                self<span class="token punctuation">.</span>bn <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>bn2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span>                self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>bn<span class="token punctuation">(</span>y<span class="token punctuation">)</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>y<span class="token punctuation">)</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>y<span class="token punctuation">)</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>y<span class="token punctuation">)</span>                <span class="token keyword">if</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">:</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                <span class="token keyword">return</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x <span class="token operator">+</span> y<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">resnet_block</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> num_residuals<span class="token punctuation">,</span> first_block<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    blk <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_residuals<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> <span class="token keyword">not</span> first_block<span class="token punctuation">:</span>            blk<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Residual<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            blk<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Residual<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>blk<span class="token punctuation">)</span>    <span class="token keyword">class</span> <span class="token class-name">ResNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>start <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>residual <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>            resnet_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            resnet_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            resnet_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            resnet_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>output <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        old_shape <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        x <span class="token operator">=</span> self<span class="token punctuation">.</span>start<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">for</span> rb <span class="token keyword">in</span> self<span class="token punctuation">.</span>residual<span class="token punctuation">:</span>            x <span class="token operator">=</span> rb<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>old_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>output<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x</code></pre><pre class="language-none"><code class="language-none">ic| net: ResNet(           (start): Sequential(             (0): Conv2d(3, 64, kernel_size&#x3D;(7, 7), stride&#x3D;(2, 2), padding&#x3D;(3, 3))             (1): BatchNorm2d(64, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)             (2): ReLU()             (3): MaxPool2d(kernel_size&#x3D;3, stride&#x3D;2, padding&#x3D;1, dilation&#x3D;1, ceil_mode&#x3D;False)           )           (residual): ModuleList(             (0): Sequential(               (0): Residual(                 (conv1): Conv2d(64, 64, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 (conv2): Conv2d(64, 64, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 (bn): BatchNorm2d(64, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (bn2): BatchNorm2d(64, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (relu): ReLU()               )               (1): Residual(                 (conv1): Conv2d(64, 64, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 (conv2): Conv2d(64, 64, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 (bn): BatchNorm2d(64, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (bn2): BatchNorm2d(64, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (relu): ReLU()               )             )             (1): Sequential(               (0): Residual(                 (conv1): Conv2d(64, 128, kernel_size&#x3D;(3, 3), stride&#x3D;(2, 2), padding&#x3D;(1, 1))                 (conv2): Conv2d(128, 128, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 (conv3): Conv2d(64, 128, kernel_size&#x3D;(1, 1), stride&#x3D;(2, 2))                 (bn): BatchNorm2d(128, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (bn2): BatchNorm2d(128, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (relu): ReLU()               )               (1): Residual(                 (conv1): Conv2d(128, 128, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 (conv2): Conv2d(128, 128, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 (bn): BatchNorm2d(128, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (bn2): BatchNorm2d(128, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (relu): ReLU()               )             )             (2): Sequential(               (0): Residual(                 (conv1): Conv2d(128, 256, kernel_size&#x3D;(3, 3), stride&#x3D;(2, 2), padding&#x3D;(1, 1))                 (conv2): Conv2d(256, 256, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 (conv3): Conv2d(128, 256, kernel_size&#x3D;(1, 1), stride&#x3D;(2, 2))                 (bn): BatchNorm2d(256, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (bn2): BatchNorm2d(256, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (relu): ReLU()               )               (1): Residual(                 (conv1): Conv2d(256, 256, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 (conv2): Conv2d(256, 256, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 (bn): BatchNorm2d(256, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (bn2): BatchNorm2d(256, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (relu): ReLU()               )             )             (3): Sequential(               (0): Residual(                 (conv1): Conv2d(256, 512, kernel_size&#x3D;(3, 3), stride&#x3D;(2, 2), padding&#x3D;(1, 1))                 (conv2): Conv2d(512, 512, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 (conv3): Conv2d(256, 512, kernel_size&#x3D;(1, 1), stride&#x3D;(2, 2))                 (bn): BatchNorm2d(512, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (bn2): BatchNorm2d(512, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (relu): ReLU()               )               (1): Residual(                 (conv1): Conv2d(512, 512, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 (conv2): Conv2d(512, 512, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 (bn): BatchNorm2d(512, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (bn2): BatchNorm2d(512, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                 (relu): ReLU()               )             )           )           (output): Sequential(             (0): Flatten(start_dim&#x3D;1, end_dim&#x3D;-1)             (1): Linear(in_features&#x3D;512, out_features&#x3D;10, bias&#x3D;True)           )         )ic| net(data).shape: torch.Size([4, 10])</code></pre><ul><li><code>DenseNet.py</code></li></ul><p>本文件实现了 DenseNet.</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> enum<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token comment"># Implementation of DenseNet</span><span class="token keyword">def</span> <span class="token function">conv_block</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>        nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">DenseBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment"># Out_channels number is the increasing rate of channels</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_convs<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        net <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_convs<span class="token punctuation">)</span><span class="token punctuation">:</span>            in_c <span class="token operator">=</span> in_channels <span class="token operator">+</span> i <span class="token operator">*</span> out_channels            net<span class="token punctuation">.</span>append<span class="token punctuation">(</span>conv_block<span class="token punctuation">(</span>in_c<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span>net<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out_channels <span class="token operator">=</span> in_channels <span class="token operator">+</span> num_convs <span class="token operator">*</span> out_channels        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> blk <span class="token keyword">in</span> self<span class="token punctuation">.</span>net<span class="token punctuation">:</span>            y <span class="token operator">=</span> blk<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">def</span> <span class="token function">transition_block</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>        nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>    <span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">DenseNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>start <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>                dense_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                num_channels<span class="token punctuation">,</span> growth_rate <span class="token operator">=</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">32</span>        num_convs_in_dense_blocks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>                <span class="token keyword">for</span> i<span class="token punctuation">,</span> num_convs <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>num_convs_in_dense_blocks<span class="token punctuation">)</span><span class="token punctuation">:</span>            DB <span class="token operator">=</span> DenseBlock<span class="token punctuation">(</span>num_convs<span class="token punctuation">,</span> num_channels<span class="token punctuation">,</span> growth_rate<span class="token punctuation">)</span>            num_channels <span class="token operator">=</span> DB<span class="token punctuation">.</span>out_channels                        dense_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>DB<span class="token punctuation">)</span>                        <span class="token keyword">if</span> i <span class="token operator">!=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>num_convs_in_dense_blocks<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">:</span>                dense_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span> transition_block<span class="token punctuation">(</span>num_channels<span class="token punctuation">,</span> num_channels <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                num_channels <span class="token operator">=</span> num_channels <span class="token operator">//</span> <span class="token number">2</span>                self<span class="token punctuation">.</span>dense <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span>dense_list<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>output <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_channels<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>start<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>dense<span class="token punctuation">:</span>            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>output<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x</code></pre><pre class="language-none"><code class="language-none">ic| net: DenseNet(           (start): Sequential(             (0): Conv2d(3, 64, kernel_size&#x3D;(7, 7), stride&#x3D;(2, 2), padding&#x3D;(3, 3))             (1): BatchNorm2d(64, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)             (2): ReLU()             (3): MaxPool2d(kernel_size&#x3D;3, stride&#x3D;2, padding&#x3D;1, dilation&#x3D;1, ceil_mode&#x3D;False)           )           (dense): ModuleList(             (0): DenseBlock(               (net): ModuleList(                 (0): Sequential(                   (0): BatchNorm2d(64, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(64, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )                 (1): Sequential(                   (0): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(96, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )                 (2): Sequential(                   (0): BatchNorm2d(128, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(128, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )                 (3): Sequential(                   (0): BatchNorm2d(160, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(160, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )               )             )             (1): Sequential(               (0): BatchNorm2d(192, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)               (1): ReLU()               (2): Conv2d(192, 96, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1))               (3): AvgPool2d(kernel_size&#x3D;2, stride&#x3D;2, padding&#x3D;0)             )             (2): DenseBlock(               (net): ModuleList(                 (0): Sequential(                   (0): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(96, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )                 (1): Sequential(                   (0): BatchNorm2d(128, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(128, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )                 (2): Sequential(                   (0): BatchNorm2d(160, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(160, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )                 (3): Sequential(                   (0): BatchNorm2d(192, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(192, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )               )             )             (3): Sequential(               (0): BatchNorm2d(224, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)               (1): ReLU()               (2): Conv2d(224, 112, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1))               (3): AvgPool2d(kernel_size&#x3D;2, stride&#x3D;2, padding&#x3D;0)             )             (4): DenseBlock(               (net): ModuleList(                 (0): Sequential(                   (0): BatchNorm2d(112, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(112, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )                 (1): Sequential(                   (0): BatchNorm2d(144, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(144, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )                 (2): Sequential(                   (0): BatchNorm2d(176, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(176, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )                 (3): Sequential(                   (0): BatchNorm2d(208, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(208, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )               )             )             (5): Sequential(               (0): BatchNorm2d(240, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)               (1): ReLU()               (2): Conv2d(240, 120, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1))               (3): AvgPool2d(kernel_size&#x3D;2, stride&#x3D;2, padding&#x3D;0)             )             (6): DenseBlock(               (net): ModuleList(                 (0): Sequential(                   (0): BatchNorm2d(120, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(120, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )                 (1): Sequential(                   (0): BatchNorm2d(152, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(152, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )                 (2): Sequential(                   (0): BatchNorm2d(184, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(184, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )                 (3): Sequential(                   (0): BatchNorm2d(216, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)                   (1): ReLU()                   (2): Conv2d(216, 32, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))                 )               )             )           )           (output): Sequential(             (0): BatchNorm2d(248, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)             (1): ReLU()           )           (fc): Sequential(             (0): Flatten(start_dim&#x3D;1, end_dim&#x3D;-1)             (1): Linear(in_features&#x3D;248, out_features&#x3D;10, bias&#x3D;True)           )         )ic| net(data).shape: torch.Size([4, 10])</code></pre>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://tangshusen.me/Dive-into-DL-PyTorch/img/cover.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;《动手学深度学习》原书地址：&lt;a href=&quot;https://github.com/d2l-ai/d2l-zh&quot;&gt;https://github.com/d2l-ai/d2l-zh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;《动手学深度学习》(Pytorch ver.)：&lt;a href=&quot;https://tangshusen.me/Dive-into-DL-PyTorch/#/&quot;&gt;https://tangshusen.me/Dive-into-DL-PyTorch/#/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;知识架构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tangshusen.me/Dive-into-DL-PyTorch/img/book-org.svg&quot; alt=&quot;封面&quot;&gt;&lt;/p&gt;
&lt;p&gt;本文的主要作用是在阅读过程中做一些摘录。对于「机器学习」领域，c7w 虽然曾尝试从各个领域入门，也尝试训过一些模型，但是还是缺少系统性、结构性的学习。希望阅读本书能带来更多的收获吧。&lt;/p&gt;
&lt;p&gt;与前面的一些笔记相比，本文更加侧重于「实践」。也就是说切实地提升自己的代码能力。&lt;/p&gt;
&lt;p&gt;本部分包含：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;{Finished} [5-5] 实现一个可以实现表情识别的类 CNN 网络并训练，重点在于造出一个机器学习的框架，然后评估其准确率。&lt;/li&gt;
&lt;li&gt;{Finished} [5-11, 5-12] 实现 ResNet 和 DenseNet，注意体会怎样才能使得运算维度匹配。&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="理论" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/"/>
    
    <category term="理论/机器学习" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/%E7%90%86%E8%AE%BA-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://www.c7w.tech/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>《动手学深度学习》 Pytorch ver. 阅读摘录 Part B</title>
    <link href="https://www.c7w.tech/dive-into-dl-pytorch-B/"/>
    <id>https://www.c7w.tech/dive-into-dl-pytorch-B/</id>
    <published>2022-01-26T04:01:54.000Z</published>
    <updated>2022-01-27T06:59:48.550Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/cover.png" alt=""></p><ul><li>《动手学深度学习》原书地址：<a href="https://github.com/d2l-ai/d2l-zh">https://github.com/d2l-ai/d2l-zh</a></li><li>《动手学深度学习》(Pytorch ver.)：<a href="https://tangshusen.me/Dive-into-DL-PyTorch/#/">https://tangshusen.me/Dive-into-DL-PyTorch/#/</a></li></ul><p>知识架构：</p><p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/book-org.svg" alt="封面"></p><p>本文的主要作用是在阅读过程中做一些摘录。对于「机器学习」领域， c7w 虽然曾尝试从各个领域入门，也尝试训过一些模型，但是还是缺少系统性、结构性的学习。希望阅读本书能带来更多的收获吧。</p><p>与前面的一些笔记相比，本文更加侧重于「实践」。也就是说切实地提升自己的代码能力。</p><p>Part B 包含：</p><ul><li>§ 5 CNN<ul><li>基本概念：卷积层、填充与步长、多通道、池化、批量归一化</li><li>模型的例子：LeNet、AlexNet、VGG、NiN、GoogLeNet、ResNet、DenseNet</li></ul></li><li>§ 6 RNN<ul><li>语言模型及其计算，N-gram 的概念</li><li>RNN 基本模型及其实现，字符数据集的制作</li><li>GRU, LSTM 的原理</li><li>Deep-RNN, bi-RNN</li></ul></li></ul><a id="more"></a><h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><h4 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h4><ul><li><strong>二维互相关运算</strong></li></ul><p><img src="http://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.1_correlation.svg" alt="img"></p><p>如图所示，输入是一个高和宽均为3的二维数组。我们将该数组的形状记为 $3 \times 3$ 或$（3，3）$。</p><p>核数组的高和宽分别为 2。该数组在卷积计算中又称卷积核或过滤器（filter）。</p><p>卷积核窗口（又称卷积窗口）的形状取决于卷积核的高和宽，即 $2 \times 2$。</p><p>图中的阴影部分为第一个输出元素及其计算所使用的输入和核数组元素：</p><p>$0\times0+1\times1+3\times2+4\times3=19$​​​​。</p><p>在二维互相关运算中，卷积窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，按照特定的步长，依次在输入数组上滑动。</p><p>当卷积窗口滑动到某一位置时，窗口中的输入子数组与核数组按元素相乘并求和，得到输出数组中相应位置的元素。</p><ul><li><strong>从互相关运算到卷积运算</strong></li></ul><p>实际上，卷积运算与互相关运算类似。<strong>为了得到卷积运算的输出，我们只需将核数组左右翻转并上下翻转，再与输入数组做互相关运算</strong>。</p><ul><li><strong>Feature Map 与 Receptive Field</strong></li></ul><p>二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。</p><p>影响元素 $x$ 的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做的 $x$ 感受野（receptive field）。</p><p>以图为例，输入中阴影部分的四个元素是输出中阴影部分元素的感受野。</p><p>我们将图中形状为 $2 \times 2$​​​ 的输出记为 $Y$​​，并考虑一个更深的卷积神经网络：将 $Y$ 与另一个形状为 $2 \times 2$ 的核数组做互相关运算，输出单个元素 $z$。那么，$z$ 在 $Y$ 上的 Receptive Field 为 $Y$ 的全部四个元素，在 $x$ 上的感受野包括其中全部 9 个元素。</p><p>可见，我们可以<strong>通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征</strong>。</p><h4 id="Padding-amp-Stride"><a href="#Padding-amp-Stride" class="headerlink" title="Padding &amp; Stride"></a>Padding &amp; Stride</h4><p>本节我们将介绍卷积层的两个超参数，即填充和步幅。它们可以对给定形状的输入和卷积核改变输出形状。</p><ul><li><strong>Padding</strong></li></ul><p>填充（padding）是指在输入高和宽的两侧填充元素（通常是 0 元素）。</p><p><img src="http://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.2_conv_pad.svg" alt="img"></p><p>图中我们在原输入高和宽的两侧分别添加了值为 0 的元素，使得输入高和宽从 3 变成了 5 ，并导致输出高和宽由 2 增加到 4。</p><p>一般来说，如果在高的两侧一共填充 $p_h$ 行，在宽的两侧一共填充 $p_w$ 列，在很多情况下，我们会设置 $p_h=k_h-1$ 和 $p_w=k_w-1$ 来使输入和输出具有相同的高和宽，其中 $k_h\times k_w$ 是卷积核窗口形状。这样会方便在构造网络时推测每个层的输出形状。</p><p>假设这里 $k_h$ 是奇数，我们会在高的两侧分别填充 $p_h/2$ 行。如果 $k_h$ 是偶数，一种可能是在输入的顶端一侧填充 $\lceil p_h/2\rceil$ 行，而在底端一侧填充 $\lfloor p_h/2\rfloor$​ 行。在宽的两侧填充同理。卷积神经网络经常使用<strong>奇数高宽的卷积核</strong> $k_h \times k_w$，如 1、3、5 和 7，所以两端上的填充个数相等。</p><p>对任意的二维数组 <code>X</code>，设它的第 <code>i</code> 行第 <code>j</code> 列的元素为 <code>X[i,j]</code>。当两端上的填充个数相等，并使输入和输出具有相同的高和宽时，我们就知道输出 <code>Y[i,j]</code> 是由输入以 <code>X[i,j]</code> 为中心的窗口同卷积核进行互相关计算得到的。</p><ul><li><strong>Stride</strong></li></ul><p>在上一节里我们介绍了二维互相关运算。卷积窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输入数组上滑动。我们将每次滑动的行数和列数称为步幅（stride）。</p><p><img src="http://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.2_conv_stride.svg" alt="img"></p><p>目前我们看到的例子里，在高和宽两个方向上步幅均为1。我们也可以使用更大步幅。</p><p>图中展示了在高上步幅为 3、在宽上步幅为 2 的二维互相关运算。可以看到，输出第一列第二个元素时，卷积窗口向下滑动了 3 行，而在输出第一行第二个元素时卷积窗口向右滑动了 2 列。当卷积窗口在输入上再向右滑动 2 列时，由于输入元素无法填满窗口，无结果输出。</p><h4 id="多通道"><a href="#多通道" class="headerlink" title="多通道"></a>多通道</h4><p>前面两节里我们用到的输入和输出都是二维数组，但真实数据的维度经常更高。</p><p>例如，彩色图像在高和宽 2 个维度外还有 RGB（红、绿、蓝）3 个颜色通道。</p><p>假设彩色图像的高和宽分别是 $h$ 和 $w$（像素），那么它可以表示为一个 $3\times h\times w$ 的多维数组。</p><p>我们将大小为 3 的这一维称为通道（channel）维。</p><p>本节我们将介绍含多个输入通道或多个输出通道的卷积核。</p><ul><li><strong>多输入通道</strong></li></ul><p><img src="http://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.3_conv_multi_in.svg" alt="img"></p><p>当输入数据含多个通道时，我们需要构造一个输入通道数与输入数据的通道数相同的卷积核，从而能够与含多通道的输入数据做互相关运算。</p><p>含多个通道的输入数据与多输入通道的卷积核做二维互相关运算的输出：在各个通道上对输入的二维数组和卷积核的二维核数组做互相关运算，再将这些互相关运算的输出相加。</p><ul><li><strong>多输出通道</strong></li></ul><p>当输入通道有多个时，因为我们对各个通道的结果做了累加，所以不论输入通道数是多少，输出通道数总是为 1。设卷积核输入通道数和输出通道数分别为 $c_i$ 和 $c_o$，高和宽分别为 $k_h$ 和 $k_w$。</p><p>如果希望得到含多个通道的输出，我们可以为每个输出通道分别创建形状为 $c_i\times k_h\times k_w$ 的核数组。将它们在输出通道维上连结，卷积核的形状即 $c_o\times c_i\times k_h\times k_w$。</p><ul><li><strong>1 x 1 卷积层</strong></li></ul><p><img src="http://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.3_conv_1x1.svg" alt="img"></p><p>因为使用了最小窗口，$1\times 1$ 卷积失去了卷积层可以识别高和宽维度上相邻元素构成的模式的功能。实际上，$1\times 1$ 卷积的主要计算发生在通道维上。</p><p>值得注意的是，输入和输出具有相同的高和宽。输出中的每个元素来自输入中在高和宽上相同位置的元素<strong>在不同通道之间的按权重累加</strong>。</p><p>假设我们将通道维当作特征维，将高和宽维度上的元素当成数据样本，<strong>那么 $1\times 1$​ 卷积层的作用与全连接层等价</strong>。</p><h4 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h4><p>设任意二维数组 <code>X</code> 的 <code>i</code>行 <code>j</code> 列的元素为 <code>X[i, j]</code>。如果我们构造的 $1 \times 2$卷积核 $[1, -1]$ 输出 <code>Y[i, j]=1</code>，那么说明输入中 <code>X[i, j]</code> 和 <code>X[i, j+1]</code> 数值不一样。这可能意味着物体边缘通过这两个元素之间。</p><p>实际图像里，我们感兴趣的物体不会总出现在固定位置：即使我们连续拍摄同一个物体也极有可能出现像素位置上的偏移。这会导致同一个边缘对应的输出可能出现在卷积输出 <code>Y</code> 中的不同位置，进而对后面的模式识别造成不便。</p><p>在本节中我们介绍池化（pooling）层，它的提出是<strong>为了缓解卷积层对位置的过度敏感性</strong>。</p><ul><li><strong>2D-MaxPooling &amp; Mean Pooling</strong></li></ul><p><img src="http://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.4_pooling.svg" alt="img"></p><p>同卷积层一样，池化层每次对输入数据的一个固定形状窗口（又称池化窗口）中的元素计算输出。</p><p>不同于卷积层里计算输入和核的互相关性，池化层直接计算池化窗口内元素的最大值或者平均值。该运算也分别叫做最大池化或平均池化。</p><p>让我们再次回到本节开始提到的物体边缘检测的例子。现在我们将卷积层的输出作为 $2\times 2$ 最大池化的输入。设该卷积层输入是 <code>X</code>、池化层输出为 <code>Y</code>。无论是 <code>X[i, j]</code> 和 <code>X[i, j+1]</code> 值不同，还是 <code>X[i, j+1]</code> 和 <code>X[i, j+2]</code> 不同，池化层输出均有 <code>Y[i, j]=1</code>。也就是说，使用 $2\times 2$ 最大池化层时，只要卷积层识别的模式在高和宽上移动不超过一个元素，我们依然可以将它检测出来。</p><ul><li><strong>Padding &amp; Stride</strong></li></ul><p>同卷积层一样，池化层也可以在输入的高和宽两侧的填充并调整窗口的移动步幅来改变输出形状。池化层填充和步幅与卷积层填充和步幅的工作机制一样。我们将通过 <code>nn</code> 模块里的二维最大池化层 <code>MaxPool2d</code> 来演示池化层填充和步幅的工作机制。</p><pre class="language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># C_o * C_i * K_h * K_w</span><span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span></code></pre><p>输出：<br><pre class="language-none"><code class="language-none">tensor([[[[ 0.,  1.,  2.,  3.],          [ 4.,  5.,  6.,  7.],          [ 8.,  9., 10., 11.],          [12., 13., 14., 15.]]]])</code></pre></p><p>默认情况下，<code>MaxPool2d</code> 实例里步幅和池化窗口形状相同。下面使用形状为 $(3, 3)$ 的池化窗口，默认获得形状为 $(3, 3)$ 的步幅。</p><pre class="language-python" data-language="python"><code class="language-python">pool2d <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>pool2d<span class="token punctuation">(</span>X<span class="token punctuation">)</span> </code></pre><p>输出：<br><pre class="language-none"><code class="language-none">tensor([[[[10.]]]])</code></pre></p><p>我们可以手动指定步幅和填充。</p><pre class="language-python" data-language="python"><code class="language-python">pool2d <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>pool2d<span class="token punctuation">(</span>X<span class="token punctuation">)</span></code></pre><p>输出：<br><pre class="language-none"><code class="language-none">tensor([[[[ 5.,  7.],          [13., 15.]]]])</code></pre></p><p>当然，我们也可以指定非正方形的池化窗口，并分别指定高和宽上的填充和步幅。</p><pre class="language-python" data-language="python"><code class="language-python">pool2d <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>pool2d<span class="token punctuation">(</span>X<span class="token punctuation">)</span></code></pre><p>输出：<br><pre class="language-none"><code class="language-none">tensor([[[[ 1.,  3.],          [ 9., 11.],          [13., 15.]]]])</code></pre></p><ul><li><strong>多通道</strong></li></ul><p>在处理多通道输入数据时，<strong>池化层对每个输入通道分别池化，而不是像卷积层那样将各通道的输入按通道相加</strong>。</p><p>这意味着池化层的输出通道数与输入通道数相等。下面将数组 <code>X</code> 和 <code>X+1</code> 在通道维上连结来构造通道数为 2 的输入。</p><pre class="language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> X <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>X</code></pre><p>输出：<br><pre class="language-none"><code class="language-none">tensor([[[[ 0.,  1.,  2.,  3.],          [ 4.,  5.,  6.,  7.],          [ 8.,  9., 10., 11.],          [12., 13., 14., 15.]],         [[ 1.,  2.,  3.,  4.],          [ 5.,  6.,  7.,  8.],          [ 9., 10., 11., 12.],          [13., 14., 15., 16.]]]])</code></pre></p><p>池化后，我们发现输出通道数仍然是2。</p><pre class="language-python" data-language="python"><code class="language-python">pool2d <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>pool2d<span class="token punctuation">(</span>X<span class="token punctuation">)</span></code></pre><p>输出：<br><pre class="language-none"><code class="language-none">tensor([[[[ 5.,  7.],          [13., 15.]],         [[ 6.,  8.],          [14., 16.]]]])</code></pre></p><h4 id="批量归一化"><a href="#批量归一化" class="headerlink" title="批量归一化"></a>批量归一化</h4><p>本节我们介绍批量归一化（batch normalization）层，它能让较深的神经网络的训练变得更加容易。</p><ul><li>为什么要有 Batch Normalization?</li></ul><p>在预测回归问题里，我们对输入数据做了标准化处理：处理后的任意一个特征在数据集中所有样本上的均值为 0、标准差为 1。标准化处理输入数据使各个特征的分布相近：这往往更容易训练出有效的模型。</p><p>通常来说，数据标准化预处理对于浅层模型就足够有效了。随着模型训练的进行，当每层中参数更新时，靠近输出层的输出较难出现剧烈变化。但对深层神经网络来说，即使输入数据已做标准化，训练中模型参数的更新依然很容易造成靠近输出层输出的剧烈变化。这种计算数值的不稳定性通常令我们难以训练出有效的深度模型。</p><p>批量归一化的提出正是为了应对深度模型训练的挑战。在模型训练时，批量归一化利用小批量上的均值和标准差，不断调整神经网络中间输出，从而使整个神经网络在各层的中间输出的数值更稳定。<strong>批量归一化和下一节将要介绍的残差网络为训练和设计深度模型提供了两类重要思路</strong>。</p><ul><li>怎么做 Batch Normalization?</li></ul><p>对全连接层和卷积层做批量归一化的方法稍有不同。下面我们将分别介绍这两种情况下的批量归一化。</p><p><strong>对 Fully Connected Layer 的 Batch Normalization</strong></p><p>我们先考虑如何对全连接层做批量归一化。通常，我们将批量归一化层置于全连接层中的仿射变换和激活函数之间。设全连接层的输入为 $\boldsymbol{u}$​​，权重参数和偏差参数分别为 $\boldsymbol{W}$​ ​和 $\boldsymbol{b}$​​，激活函数为 $\phi$​​。设批量归一化的运算符为 $\text{BN}$​​。那么，使用批量归一化的全连接层的输出为 $\phi(\text{BN}(\boldsymbol{Wu+b}))$​。</p><p>下面我们解释 $\text{BN}$​ 算符是什么。</p><p>考虑一个由 $m$​​ 个样本组成的 Mini-batch，仿射变换的输出为一个新的 Mini-batch $\mathcal{B} = {\boldsymbol{x}^{(1)}, \ldots, \boldsymbol{x}^{(m)} }$​​。它们正是批量归一化层的输入。对于小批量 $\mathcal{B}$​ ​中任意样本 $\boldsymbol{x}^{(i)} \in \mathbb{R}^d, 1 \leq i \leq m$​​，批量归一化层的输出同样是 $d$​ ​维向量$\boldsymbol{y}^{(i)} = \text{BN}(\boldsymbol{x}^{(i)})$​，并由以下几步求得。</p><script type="math/tex; mode=display">\boldsymbol{\mu}_\mathcal{B} \leftarrow \frac{1}{m}\sum_{i = 1}^{m} \boldsymbol{x}^{(i)} \\\boldsymbol{\sigma}_\mathcal{B}^2 \leftarrow \frac{1}{m} \sum_{i=1}^{m}(\boldsymbol{x}^{(i)} - \boldsymbol{\mu}_\mathcal{B})^2 \\ \hat{\boldsymbol{x}}^{(i)} \leftarrow \frac{\boldsymbol{x}^{(i)} - \boldsymbol{\mu}_\mathcal{B}}{\sqrt{\boldsymbol{\sigma}_\mathcal{B}^2 + \epsilon}}</script><p>这里 $\epsilon &gt; 0$ 是一个很小的常数，是为了保证分母大于 0。在上面标准化的基础上，批量归一化层引入了两个可以学习的模型参数，拉伸（scale）参数 $\boldsymbol{\gamma}$ 和偏移（shift）参数 $\boldsymbol{\beta}$。这两个参数和 $\boldsymbol{x}^{(i)}$ 形状相同，皆为 $d$ 维向量。它们与 $\boldsymbol{x}^{(i)}$ 分别做 Hadamard Product（符号$\odot$​）和加法计算：</p><script type="math/tex; mode=display">{\boldsymbol{y}}^{(i)} \leftarrow \boldsymbol{\gamma} \odot \hat{\boldsymbol{x}}^{(i)} + \boldsymbol{\beta}</script><p>至此，我们得到了 $\boldsymbol{x}^{(i)}$​ ​的批量归一化的输出 $\boldsymbol{y}^{(i)}$​​。值得注意的是，可学习的拉伸和偏移参数保留了不对 $\hat{\boldsymbol{x}}^{(i)}$ ​​做批量归一化的可能：此时只需学出 $\boldsymbol{\gamma} = \sqrt{\boldsymbol{\sigma}_\mathcal{B}^2 + \epsilon}$ ​​和 $\boldsymbol{\beta} = \boldsymbol{\mu}_\mathcal{B}$​​。我们可以对此这样理解：如果批量归一化无益，理论上，学出的模型可以不使用批量归一化。</p><p><strong>对 Conv. Layer 的 Batch Normalization</strong></p><p>对卷积层来说，批量归一化发生在卷积计算之后、应用激活函数之前。</p><p>如果卷积计算输出多个通道，我们需要对这些通道的输出分别做批量归一化，且<strong>每个通道都拥有独立的拉伸和偏移参数，并均为标量</strong>。</p><p>设小批量中有 $m$ 个样本，在单个通道上，假设卷积计算输出的高和宽分别为 $p$ 和 $q$。我们需要对该通道中 $m \times p \times q$ 个元素同时做批量归一化。对这些元素做标准化计算时，我们使用相同的均值和方差，即该通道中 $m \times p \times q$​ 个元素的均值和方差。</p><p><strong>预测时的 Batch Normalization</strong></p><p>使用批量归一化训练时，我们可以将批量大小设得大一点，从而使批量内样本的均值和方差的计算都较为准确。将训练好的模型用于预测时，我们希望模型对于任意输入都有确定的输出。因此，<strong>单个样本的输出不应取决于批量归一化所需要的随机小批量中的均值和方差</strong>。一种常用的方法是通过移动平均<strong>估算整个训练数据集的样本均值和方差</strong>，并在预测时使用它们得到确定的输出。可见，和丢弃层一样，批量归一化层在训练模式和预测模式下的计算结果也是不一样的。</p><ul><li>实现（Simple ver.）</li></ul><p>与我们刚刚自己定义的 <code>BatchNorm</code> 类相比，Pytorch 中 <code>nn</code> 模块定义的 <code>BatchNorm1d</code> 和 <code>BatchNorm2d</code> 类使用起来更加简单，二者分别用于全连接层和卷积层，都需要指定输入的 <code>num_features</code> 参数值。下面我们用 PyTorch 实现使用批量归一化的 LeNet。</p><pre class="language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># in_channels, out_channels, kernel_size</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># kernel_size, stride</span>                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                d2l<span class="token punctuation">.</span>FlattenLayer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span></code></pre><h3 id="CNN-的例子"><a href="#CNN-的例子" class="headerlink" title="CNN 的例子"></a>CNN 的例子</h3><h4 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h4><p>之前我们曾使用 MLP 对 Fashion-MNIST 数据集中的图像进行分类。每张图像高和宽均是 28 像素。我们将图像中的像素逐行展开，得到长度为 784 的向量，并输入进全连接层中。然而，这种分类方法有一定的局限性。</p><ol><li>图像在同一列邻近的像素在这个向量中可能相距较远。它们构成的模式可能难以被模型识别。</li><li>对于大尺寸的输入图像，使用全连接层容易造成模型过大。假设输入是高和宽均为 1000 像素的彩色照片（含 3 个通道）。即使全连接层输出个数仍是 256，该层权重参数的形状是$ 3,000,000\times 256$​：它占用了大约 3 GB 的内存或显存。这带来过复杂的模型和过高的存储开销。</li></ol><p>卷积层尝试解决这两个问题。一方面，卷积层保留输入形状，使图像的像素在高和宽两个方向上的相关性均可能被有效识别；另一方面，卷积层通过滑动窗口将同一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大。</p><p>卷积神经网络就是含卷积层的网络。本节里我们将介绍一个早期用来识别手写数字图像的卷积神经网络：LeNet。</p><p><img src="http://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.5_lenet.png" alt="img"></p><p>LeNet分为卷积层块和全连接层块两个部分。下面我们分别介绍这两个模块。</p><p>卷积层块里的基本单位是<strong>卷积层后接最大池化层</strong>：</p><ul><li>卷积层用来识别图像里的空间模式，如线条和物体局部</li><li>之后的最大池化层则用来降低卷积层对位置的敏感性</li></ul><p>卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用 $5\times 5$​ 的窗口，并在输出上使用 sigmoid 激活函数。第一个卷积层输出通道数为 6，第二个卷积层输出通道数则增加到 16。这是因为第二个卷积层比第一个卷积层的输入的高和宽要小，所以增加输出通道使两个卷积层的参数尺寸类似。卷积层块的两个最大池化层的窗口形状均为 $2\times 2$​​，且步幅为 2。由于池化窗口与步幅形状相同，池化窗口在输入上每次滑动所覆盖的区域互不重叠。</p><p>卷积层块的输出形状为 (批量大小, 通道, 高, 宽)。当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本变平（flatten）。也就是说，全连接层的输入形状将变成二维，其中第二维是每个样本变平后的向量表示，且向量长度为通道、高和宽的乘积。全连接层块含 3 个全连接层。它们的输出个数分别是 120、84 和 10，其中 10 为输出的类别个数。</p><p>下面我们通过 <code>Sequential</code> 类来实现 LeNet 模型。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LeNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>LeNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># in_channels, out_channels, kernel_size</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># kernel_size, stride</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>        feature <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>feature<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> output</code></pre><p>这里使用 GPU 进行计算，对相关函数的修改如下：</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># 本函数已保存在d2lzh_pytorch包中方便以后使用</span><span class="token keyword">def</span> <span class="token function">train_ch5</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> test_iter<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    net <span class="token operator">=</span> net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"training on "</span><span class="token punctuation">,</span> device<span class="token punctuation">)</span>    loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        train_l_sum<span class="token punctuation">,</span> train_acc_sum<span class="token punctuation">,</span> n<span class="token punctuation">,</span> batch_count<span class="token punctuation">,</span> start <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> train_iter<span class="token punctuation">:</span>            X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            y <span class="token operator">=</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            y_hat <span class="token operator">=</span> net<span class="token punctuation">(</span>X<span class="token punctuation">)</span>            l <span class="token operator">=</span> loss<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y<span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            train_l_sum <span class="token operator">+=</span> l<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            train_acc_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>y_hat<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            n <span class="token operator">+=</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            batch_count <span class="token operator">+=</span> <span class="token number">1</span>        test_acc <span class="token operator">=</span> evaluate_accuracy<span class="token punctuation">(</span>test_iter<span class="token punctuation">,</span> net<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'</span>              <span class="token operator">%</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> train_l_sum <span class="token operator">/</span> batch_count<span class="token punctuation">,</span> train_acc_sum <span class="token operator">/</span> n<span class="token punctuation">,</span> test_acc<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 本函数已保存在d2lzh_pytorch包中方便以后使用。该函数将被逐步改进。</span><span class="token keyword">def</span> <span class="token function">evaluate_accuracy</span><span class="token punctuation">(</span>data_iter<span class="token punctuation">,</span> net<span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> device <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">and</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 如果没指定device就使用net的device</span>        device <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>device    acc_sum<span class="token punctuation">,</span> n <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>                net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 评估模式, 这会关闭 dropout</span>                acc_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>                net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 改回训练模式</span>            <span class="token keyword">else</span><span class="token punctuation">:</span> <span class="token comment"># 自定义的模型, 3.13节之后不会用到, 不考虑GPU</span>                <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token string">'is_training'</span> <span class="token keyword">in</span> net<span class="token punctuation">.</span>__code__<span class="token punctuation">.</span>co_varnames<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 如果有 is_training 这个参数</span>                    <span class="token comment"># 将 is_training 设置成 False</span>                    acc_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">,</span> is_training<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>                 <span class="token keyword">else</span><span class="token punctuation">:</span>                    acc_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>             n <span class="token operator">+=</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> acc_sum <span class="token operator">/</span> n</code></pre><h4 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h4><p><img src="http://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.6_alexnet.png" alt="img"></p><ul><li>Larger parameter size</li><li>Use ReLU instead of sigmoid</li><li>Introducing Dropout</li><li>Data augmentation</li></ul><h4 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h4><p>VGG 提出了可以通过重复使用简单的基础块来构建深度模型的思路。</p><p>VGG块的组成规律是：连续使用数个相同的填充为 1、窗口形状为 $3\times 3$ 的卷积层后接上一个步幅为 2、窗口形状为 $2\times 2$​ ​的最大池化层。卷积层保持输入的高和宽不变，而池化层则对其减半。我们使用<code>vgg_block</code>函数来实现这个基础的VGG 块，它可以指定卷积层的数量和输入输出通道数。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">vgg_block</span><span class="token punctuation">(</span>num_convs<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>    blk <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_convs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            blk<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            blk<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        blk<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    blk<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 这里会使宽高减半</span>    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>blk<span class="token punctuation">)</span></code></pre><p>现在我们构造一个 VGG 网络。它有 5 个 <code>vgg_block</code>，前 2 块使用单卷积层 <code>num_convs=1</code>，而后 3 块使用双卷积层 <code>num_convs=2</code>。第一块的输入输出通道分别是 1（因为下面要使用的 Fashion-MNIST 数据的通道数为 1）和 64，之后每次对输出通道数翻倍，直到变为 512。因为这个网络使用了 8 个卷积层和 3 个全连接层，所以经常被称为 VGG-11。</p><pre class="language-python" data-language="python"><code class="language-python">conv_arch <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 经过5个 vgg_block, 宽高会减半5次, 变成 224/32 = 7</span>fc_features <span class="token operator">=</span> <span class="token number">512</span> <span class="token operator">*</span> <span class="token number">7</span> <span class="token operator">*</span> <span class="token number">7</span> <span class="token comment"># c * w * h</span>fc_hidden_units <span class="token operator">=</span> <span class="token number">4096</span> <span class="token comment"># 任意</span><span class="token keyword">def</span> <span class="token function">vgg</span><span class="token punctuation">(</span>conv_arch<span class="token punctuation">,</span> fc_features<span class="token punctuation">,</span> fc_hidden_units<span class="token operator">=</span><span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 卷积层部分</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>num_convs<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>conv_arch<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 每经过一个vgg_block都会使宽高减半</span>        net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"vgg_block_"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> vgg_block<span class="token punctuation">(</span>num_convs<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># 全连接层部分</span>    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"fc"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>d2l<span class="token punctuation">.</span>FlattenLayer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                 nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>fc_features<span class="token punctuation">,</span> fc_hidden_units<span class="token punctuation">)</span><span class="token punctuation">,</span>                                 nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                 nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                 nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>fc_hidden_units<span class="token punctuation">,</span> fc_hidden_units<span class="token punctuation">)</span><span class="token punctuation">,</span>                                 nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                 nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                 nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>fc_hidden_units<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>                                <span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> net</code></pre><h4 id="NiN"><a href="#NiN" class="headerlink" title="NiN"></a>NiN</h4><p>前几节介绍的 LeNet、AlexNet 和 VGG 在设计上的共同之处是：先以由卷积层构成的模块充分抽取空间特征，再以由全连接层构成的模块来输出分类结果。其中，AlexNet 和 VGG 对 LeNet 的改进主要在于如何对这两个模块加宽（增加通道数）和加深。</p><p>本节我们介绍网络中的网络（NiN）。它提出了另外一个思路，即串联多个由卷积层和“全连接”层构成的小网络来构建一个深层网络。NiN使用 $1\times 1$ 卷积层来替代全连接层，从而使空间信息能够自然传递到后面的层中去。</p><p><img src="http://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.8_nin.svg" alt="img"></p><p>左图是 AlexNet 和 VGG 的网络结构局部，右图是 NiN 的网络结构局部。</p><p><strong>NiN 块</strong>是 NiN 中的基础块。它由一个卷积层加两个充当全连接层的 $1\times 1$ 卷积层串联而成。其中第一个卷积层的超参数可以自行设置，而第二和第三个卷积层的超参数一般是固定的。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">nin_block</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> stride<span class="token punctuation">,</span> padding<span class="token punctuation">)</span><span class="token punctuation">:</span>    blk <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> stride<span class="token punctuation">,</span> padding<span class="token punctuation">)</span><span class="token punctuation">,</span>                        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> blk</code></pre><p><strong>NiN 模型</strong>使用卷积窗口形状分别为 $11\times 11$​、$5\times 5$​ 和 $3\times 3$ ​的卷积层，相应的输出通道数也与 AlexNet 中的一致。每个 NiN 块后接一个步幅为 2、窗口形状为 $3\times 3$​​ 的最大池化层。</p><p>除使用 NiN 块以外，NiN 还有一个设计与 AlexNet 显著不同：NiN 去掉了 AlexNet 最后的3个全连接层，取而代之地，NiN 使用了输出通道数等于标签类别数的NiN 块，然后使用全局平均池化层对每个通道中所有元素求平均并直接用于分类。这里的全局平均池化层即窗口形状等于输入空间维形状的平均池化层。NiN 的这个设计的好处是可以显著减小模型参数尺寸，从而缓解过拟合。然而，该设计有时会造成获得有效模型的训练时间的增加。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">GlobalAvgPool2d</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>GlobalAvgPool2d<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> F<span class="token punctuation">.</span>avg_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>    nin_block<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">11</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nin_block<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nin_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>     nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token comment"># 标签类别数是10</span>    nin_block<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    GlobalAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>     <span class="token comment"># 将四维的输出转成二维的输出，其形状为(批量大小, 10)</span>    d2l<span class="token punctuation">.</span>FlattenLayer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h4 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h4><p><img src="http://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.9_inception.svg" alt="img"></p><p>图为 Inception 块的结构。从这里我们可以意识到的一点是，以 Block 为单位来拼凑模型的这种方法逐渐火热…</p><h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><p>让我们先思考一个问题：对神经网络模型添加新的层，充分训练后的模型是否只可能更有效地降低训练误差？</p><p>理论上，原模型解的空间只是新模型解的空间的子空间。也就是说，如果我们能将新添加的层训练成恒等映射 $f(x) = x$​，新模型和原模型将同样有效。由于新模型可能得出更优的解来拟合训练数据集，因此添加层似乎更容易降低训练误差。</p><p>然而在实践中，添加过多的层后训练误差往往不降反升。即使利用批量归一化带来的数值稳定性使训练深层模型更加容易，该问题仍然存在。针对这一问题，残差网络被提出。</p><ul><li>残差块</li></ul><p>让我们聚焦于神经网络局部。如图所示，设输入为 $\boldsymbol{x}$。假设我们希望学出的理想映射为 $f(\boldsymbol{x})$，从而作为图上方激活函数的输入。左图虚线框中的部分需要直接拟合出该映射 $f(\boldsymbol{x})$，而右图虚线框中的部分则需要拟合出有关恒等映射的残差映射 $f(\boldsymbol{x})-\boldsymbol{x}$​。</p><p><img src="http://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.11_residual-block.svg" alt="img"></p><p>残差映射在实际中往往更容易优化。以本节开头提到的恒等映射作为我们希望学出的理想映射 $f(\boldsymbol{x})$。我们只需将图中右图虚线框内上方的加权运算（如仿射）的权重和偏差参数学成 0，那么 $f(\boldsymbol{x})$ 即为恒等映射。</p><p>实际中，当理想映射 $f(\boldsymbol{x})$ 极接近于恒等映射时，残差映射也易于捕捉恒等映射的细微波动。右图也是 ResNet 的基础块，即<strong>残差块</strong>（residual block）。在残差块中，输入可通过跨层的数据线路更快地向前传播。</p><p>ResNet 沿用了 VGG 全 $3\times 3$ 卷积层的设计。残差块里首先有 2 个有相同输出通道数的 $3\times 3$ 卷积层。每个卷积层后接一个批量归一化层和ReLU激活函数。然后我们将输入跳过这两个卷积运算后直接加在最后的ReLU激活函数前。这样的设计要求两个卷积层的输出与输入形状一样，从而可以相加。如果想改变通道数，就需要引入一个额外的 $1\times 1$​​ 卷积层来将输入变换成需要的形状后再做相加运算。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Residual</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 本类已保存在d2lzh_pytorch包中方便以后使用</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> use_1x1conv<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Residual<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> use_1x1conv<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> <span class="token boolean">None</span>        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>bn2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        Y <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        Y <span class="token operator">=</span> self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>Y<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">:</span>            X <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>X<span class="token punctuation">)</span>        <span class="token keyword">return</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>Y <span class="token operator">+</span> X<span class="token punctuation">)</span></code></pre><ul><li>ResNet 模型</li></ul><pre class="language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>         nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">resnet_block</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> num_residuals<span class="token punctuation">,</span> first_block<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> first_block<span class="token punctuation">:</span>        <span class="token keyword">assert</span> in_channels <span class="token operator">==</span> out_channels <span class="token comment"># 第一个模块的通道数同输入通道数一致</span>    blk <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_residuals<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> <span class="token keyword">not</span> first_block<span class="token punctuation">:</span>            blk<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Residual<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> use_1x1conv<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            blk<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Residual<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>blk<span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"resnet_block1"</span><span class="token punctuation">,</span> resnet_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> first_block<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"resnet_block2"</span><span class="token punctuation">,</span> resnet_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"resnet_block3"</span><span class="token punctuation">,</span> resnet_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"resnet_block4"</span><span class="token punctuation">,</span> resnet_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"global_avg_pool"</span><span class="token punctuation">,</span> d2l<span class="token punctuation">.</span>GlobalAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># GlobalAvgPool2d的输出: (Batch, 512, 1, 1)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"fc"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>d2l<span class="token punctuation">.</span>FlattenLayer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> </code></pre><h4 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h4><p>ResNet 中的跨层连接设计引申出了数个后续工作。本节我们介绍其中的一个：稠密连接网络。</p><p><img src="http://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.12_densenet.svg" alt="img"></p><p>图中将部分前后相邻的运算抽象为模块 A 和模块 B。</p><p>与 ResNet 的主要区别在于，DenseNet 里模块 B 的输出不是像 ResNet 那样和模块 A 的输出相加，而是在通道维上连结。这样模块 A 的输出可以直接传入模块 B 后面的层。在这个设计里，模块 A 直接跟模块 B 后面的所有层连接在了一起。这也是它被称为“稠密连接”的原因。</p><ul><li>DenseBlock</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">conv_block</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>    blk <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>                         nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> blk<span class="token keyword">class</span> <span class="token class-name">DenseBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_convs<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>DenseBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        net <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_convs<span class="token punctuation">)</span><span class="token punctuation">:</span>            in_c <span class="token operator">=</span> in_channels <span class="token operator">+</span> i <span class="token operator">*</span> out_channels            net<span class="token punctuation">.</span>append<span class="token punctuation">(</span>conv_block<span class="token punctuation">(</span>in_c<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span>net<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out_channels <span class="token operator">=</span> in_channels <span class="token operator">+</span> num_convs <span class="token operator">*</span> out_channels <span class="token comment"># 计算输出通道数</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> blk <span class="token keyword">in</span> self<span class="token punctuation">.</span>net<span class="token punctuation">:</span>            Y <span class="token operator">=</span> blk<span class="token punctuation">(</span>X<span class="token punctuation">)</span>            X <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 在通道维上将输入和输出连结</span>        <span class="token keyword">return</span> X</code></pre><ul><li>过渡层</li></ul><p>由于每个稠密块都会带来通道数的增加，使用过多则会带来过于复杂的模型。过渡层用来控制模型复杂度。它通过 $1\times1$ ​卷积层来减小通道数，并使用步幅为 2 的平均池化层减半高和宽，从而进一步降低模型复杂度。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">transition_block</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>    blk <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>             nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> blk</code></pre><ul><li>DenseNet 模型</li></ul><pre class="language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>         nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>num_channels<span class="token punctuation">,</span> growth_rate <span class="token operator">=</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">32</span>  <span class="token comment"># num_channels为当前的通道数</span>num_convs_in_dense_blocks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> num_convs <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>num_convs_in_dense_blocks<span class="token punctuation">)</span><span class="token punctuation">:</span>    DB <span class="token operator">=</span> DenseBlock<span class="token punctuation">(</span>num_convs<span class="token punctuation">,</span> num_channels<span class="token punctuation">,</span> growth_rate<span class="token punctuation">)</span>    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"DenseBlock_%d"</span> <span class="token operator">%</span> i<span class="token punctuation">,</span> DB<span class="token punctuation">)</span>    <span class="token comment"># 上一个稠密块的输出通道数</span>    num_channels <span class="token operator">=</span> DB<span class="token punctuation">.</span>out_channels    <span class="token comment"># 在稠密块之间加入通道数减半的过渡层</span>    <span class="token keyword">if</span> i <span class="token operator">!=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>num_convs_in_dense_blocks<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">:</span>        net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"transition_block_%d"</span> <span class="token operator">%</span> i<span class="token punctuation">,</span> transition_block<span class="token punctuation">(</span>num_channels<span class="token punctuation">,</span> num_channels <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        num_channels <span class="token operator">=</span> num_channels <span class="token operator">//</span> <span class="token number">2</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"BN"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"relu"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"global_avg_pool"</span><span class="token punctuation">,</span> d2l<span class="token punctuation">.</span>GlobalAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># GlobalAvgPool2d的输出: (Batch, num_channels, 1, 1)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"fc"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>d2l<span class="token punctuation">.</span>FlattenLayer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_channels<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> </code></pre><h2 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h2><h3 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h3><p>语言模型（language model）是自然语言处理的重要技术。自然语言处理中最常见的数据是文本数据。</p><p>我们可以把一段自然语言文本看作一段离散的时间序列。假设一段长度为 $T$ 的文本中的词依次为 $w_1, w_2, \ldots, w_T$，那么在离散的时间序列中，$w_t$（$1 \leq t \leq T$）可看作在时间步（time step）$t$ 的输出或标签。</p><p>给定一个长度为 $T$ 的词的序列 $w_1, w_2, \ldots, w_T$，语言模型将计算该序列的概率：$P(w_1, w_2, \ldots, w_T)$.</p><p>语言模型可用于提升语音识别和机器翻译的性能。</p><p>例如，在语音识别中，给定一段“厨房里食油用完了”的语音，有可能会输出“厨房里食油用完了”和“厨房里石油用完了”这两个读音完全一样的文本序列。如果语言模型判断出前者的概率大于后者的概率，我们就可以根据相同读音的语音输出“厨房里食油用完了”的文本序列。</p><p>在机器翻译中，如果对英文“you go first”逐词翻译成中文的话，可能得到“你走先”“你先走”等排列方式的文本序列。如果语言模型判断出“你先走”的概率大于其他排列方式的文本序列的概率，我们就可以把“you go first”翻译成“你先走”。</p><h4 id="语言模型的计算"><a href="#语言模型的计算" class="headerlink" title="语言模型的计算"></a>语言模型的计算</h4><p>根据《概率论》课程学过的有关知识，我们不难理解：</p><script type="math/tex; mode=display">P(w_1, w_2, \ldots, w_T) = \prod_{t=1}^T P(w_t \mid w_1, \ldots, w_{t-1})</script><p>那么，这些概率该如何获得呢？</p><p>设训练数据集为一个大型文本语料库，如维基百科的所有条目。词的概率可以通过<strong>该词在训练数据集中的相对词频来计算</strong>。例如，$P(w_1)$ 可以计算为 $w_1$ 在训练数据集中的词频（词出现的次数）与训练数据集的总词数之比。因此，根据条件概率定义，一个词在给定前几个词的情况下的条件概率也可以通过训练数据集中的相对词频计算。再例如，$P(w_2 \mid w_1)$ 可以计算为 $w_1, w_2$ 两词相邻的频率与 $w_1$ 词频的比值，因为该比值即 $P(w_1, w_2)$ 与 $P(w_1)$ 之比；而 $P(w_3 \mid w_1, w_2)$ 同理可以计算为 $w_1$、$w_2$ 和 $w_3$ 三词相邻的频率与 $w_1$ 和 $w_2$ 两词相邻的频率的比值。以此类推。</p><h4 id="N-grams"><a href="#N-grams" class="headerlink" title="N-grams"></a>N-grams</h4><p>当序列长度增加时，计算和存储多个词共同出现的概率的复杂度会呈指数级增加。$n$​ 元语法通过马尔可夫假设（虽然并不一定成立）简化了语言模型的计算。这里的马尔可夫假设是指，<strong>一个词的出现只与前面 $n$ ​个词相关</strong>。</p><p>如果 $n=1$，那么有 $P(w_3 \mid w_1, w_2) = P(w_3 \mid w_2)$。</p><p>如果基于 $n-1$ 阶马尔可夫链，我们可以将语言模型改写为：$P(w_1, w_2, \ldots, w_T) \approx \prod_{t=1}^T P(w_t \mid w_{t-(n-1)}, \ldots, w_{t-1}) $。</p><p>当 $n$ 分别为 1、2 和 3 时，我们将其分别称作一元语法（unigram）、二元语法（bigram）和三元语法（trigram）。</p><p>当 $n$ 较小时，$n$ 元语法往往并不准确。然而，当 $n$ 较大时，$n$ 元语法需要计算并存储大量的词频和多词相邻频率。那么，有没有方法在语言模型中更好地平衡以上这两点呢？我们将在本章探究这样的方法。</p><h3 id="RNN-1"><a href="#RNN-1" class="headerlink" title="RNN"></a>RNN</h3><p>本节将介绍循环神经网络。它并非刚性地记忆所有固定长度的序列，而是通过隐藏状态来存储之前时间步的信息。首先我们回忆一下前面介绍过的多层感知机，然后描述如何添加隐藏状态来将它变成循环神经网络。</p><ul><li>不含隐藏状态的神经网络</li></ul><p>让我们考虑一个含单隐藏层的多层感知机。给定样本数为 $n$、输入个数（特征数或特征向量维度）为 $d$ 的小批量数据样本 $\boldsymbol{X} \in \mathbb{R}^{n \times d}$。设隐藏层的激活函数为 $\phi$，那么隐藏层的输出 $\boldsymbol{H} \in \mathbb{R}^{n \times h}$ 计算为</p><script type="math/tex; mode=display">\boldsymbol{H} = \phi(\boldsymbol{X} \boldsymbol{W}_{xh} + \boldsymbol{b}_h)</script><p>其中隐藏层权重参数 $\boldsymbol{W}_{xh} \in \mathbb{R}^{d \times h}$，隐藏层偏差参数 $\boldsymbol{b}_h \in \mathbb{R}^{1 \times h}$，$h$ 为隐藏单元个数。上式相加的两项形状不同，因此将按照广播机制相加。把隐藏变量 $\boldsymbol{H}$ 作为输出层的输入，且设输出个数为 $q$​​（如分类问题中的类别数），输出层的输出为 $\boldsymbol{O} = \boldsymbol{H} \boldsymbol{W}_{hq} + \boldsymbol{b}_q$.​ 其中输出变量 $\boldsymbol{O} \in \mathbb{R}^{n \times q}$, 输出层权重参数 $\boldsymbol{W}_{hq} \in \mathbb{R}^{h \times q}$, 输出层偏差参数 $\boldsymbol{b}_q \in \mathbb{R}^{1 \times q}$。如果是分类问题，我们可以使用 $\text{softmax}(\boldsymbol{O})$ 来计算输出类别的概率分布。</p><ul><li>含隐藏状态的 RNN</li></ul><p>现在我们考虑输入数据存在时间相关性的情况。假设 $\boldsymbol{X}_t \in \mathbb{R}^{n \times d}$ 是序列中时间步 $t$ 的小批量输入，$\boldsymbol{H}_t \in \mathbb{R}^{n \times h}$ 是该时间步的隐藏变量。</p><p>与多层感知机不同的是，这里我们保存上一时间步的隐藏变量 $\boldsymbol{H}_{t-1}$，并引入一个新的权重参数 $\boldsymbol{W}_{hh} \in \mathbb{R}^{h \times h}$，该参数用来描述在当前时间步如何使用上一时间步的隐藏变量。</p><p>具体来说，时间步 $t$ 的隐藏变量的计算由当前时间步的输入和上一时间步的隐藏变量共同决定：</p><script type="math/tex; mode=display">\boldsymbol{H}_t = \phi(\boldsymbol{X}_t \boldsymbol{W}_{xh} + \boldsymbol{H}_{t-1} \boldsymbol{W}_{hh} + \boldsymbol{b}_h)</script><p>与多层感知机相比，我们在这里添加了 $\boldsymbol{H}_{t-1} \boldsymbol{W}_{hh}$ 一项。由上式中相邻时间步的隐藏变量 $\boldsymbol{H}_t$ ​和 $\boldsymbol{H}_{t-1}$ ​之间的关系可知，这里的隐藏变量能够捕捉截至当前时间步的序列的历史信息，就像是神经网络当前时间步的状态或记忆一样。因此，该隐藏变量也称为隐藏状态。</p><p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter06/6.2_rnn.svg" alt="img"></p><p>由于隐藏状态在当前时间步的定义使用了上一时间步的隐藏状态，上式的计算是循环的。使用循环计算的网络即循环神经网络（recurrent neural network）。</p><p>而在时间步 $t$，输出层的输出和多层感知机中的计算类似：$\boldsymbol{O}_t = \boldsymbol{H}_t \boldsymbol{W}_{hq} + \boldsymbol{b}_q$.</p><h3 id="字符数据集的制作"><a href="#字符数据集的制作" class="headerlink" title="字符数据集的制作"></a>字符数据集的制作</h3><ul><li>读取数据集</li><li><p>建立字符索引 idx_to_char 与 char_to_idx</p></li><li><p>时序数据的采样</p><ul><li>随机采样：在随机采样中，每个样本是原始序列上任意截取的一段序列。相邻的两个随机小批量在原始序列上的位置不一定相毗邻。因此，我们无法用一个小批量最终时间步的隐藏状态来初始化下一个小批量的隐藏状态。在训练模型时，每次随机采样前都需要重新初始化隐藏状态。</li><li>相邻采样：令相邻的两个随机小批量在原始序列上的位置相毗邻。这时候，我们就可以用一个小批量最终时间步的隐藏状态来初始化下一个小批量的隐藏状态，从而使下一个小批量的输出也取决于当前小批量的输入，并如此循环下去。<ul><li>在训练模型时，我们只需在每一个迭代周期开始时初始化隐藏状态。</li><li>当多个相邻小批量通过传递隐藏状态串联起来时，模型参数的梯度计算将依赖所有串联起来的小批量序列。同一迭代周期中，随着迭代次数的增加，梯度的计算开销会越来越大。为了使模型参数的梯度计算只依赖一次迭代读取的小批量序列，我们可以在每次读取小批量前将隐藏状态从计算图中分离出来。</li></ul></li></ul></li></ul><h3 id="RNN-的实现"><a href="#RNN-的实现" class="headerlink" title="RNN 的实现"></a>RNN 的实现</h3><h4 id="From-scratch"><a href="#From-scratch" class="headerlink" title="From scratch"></a>From scratch</h4><ul><li>单个词的表示：One-hot 向量</li><li>初始化模型参数与模型定义</li><li>预测函数的定义</li><li>裁剪梯度</li><li>模型评估：困惑度<ul><li>困惑度是对交叉熵损失函数做指数运算后得到的值<ul><li>最佳情况下，模型总是把标签类别的概率预测为1，此时困惑度为1；</li><li>最坏情况下，模型总是把标签类别的概率预测为0，此时困惑度为正无穷；</li><li>基线情况下，模型总是预测所有类别的概率都相同，此时困惑度为类别个数。</li></ul></li></ul></li></ul><h4 id="Simple"><a href="#Simple" class="headerlink" title="Simple"></a>Simple</h4><p>Pytorch 实现：大调库</p><pre class="language-python" data-language="python"><code class="language-python">num_hiddens <span class="token operator">=</span> <span class="token number">256</span><span class="token comment"># rnn_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens) # 已测试</span>rnn_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>input_size<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> hidden_size<span class="token operator">=</span>num_hiddens<span class="token punctuation">)</span></code></pre><p>与上一节中实现的循环神经网络不同，这里 <code>rnn_layer</code> 的输入形状为 <code>(时间步数, 批量大小, 输入个数)</code>。其中输入个数即 one-hot 向量长度（词典大小）。</p><p>此外，<code>rnn_layer</code> 作为 <code>nn.RNN</code> 实例，在前向计算后会分别返回<strong>隐藏层的输出 $H$</strong> 和<strong>隐藏状态 $h$</strong>。</p><ul><li>$H$​ 指的是隐藏层在<strong>各个时间步</strong>上计算并输出的隐藏状态，它们通常作为后续输出层的输入，形状为 <code>(时间步数, 批量大小, 隐藏单元个数)</code>。</li><li>$h$ 指的是隐藏层在<strong>最后时间步</strong>的隐藏状态：当隐藏层有多层时，每一层的隐藏状态都会记录在该变量中；对于像长短期记忆（LSTM），隐藏状态是一个元组 $(h, c)$，即 hidden state 和 cell state。</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># 本类已保存在d2lzh_pytorch包中方便以后使用</span><span class="token keyword">class</span> <span class="token class-name">RNNModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> rnn_layer<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>RNNModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> rnn_layer        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> rnn_layer<span class="token punctuation">.</span>hidden_size <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token keyword">if</span> rnn_layer<span class="token punctuation">.</span>bidirectional <span class="token keyword">else</span> <span class="token number">1</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>vocab_size <span class="token operator">=</span> vocab_size        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>state <span class="token operator">=</span> <span class="token boolean">None</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># inputs: (batch, seq_len)</span>        <span class="token comment"># 获取 one-hot 向量表示</span>        X <span class="token operator">=</span> d2l<span class="token punctuation">.</span>to_onehot<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> self<span class="token punctuation">.</span>vocab_size<span class="token punctuation">)</span> <span class="token comment"># X 是个 list</span>        Y<span class="token punctuation">,</span> self<span class="token punctuation">.</span>state <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> state<span class="token punctuation">)</span>        <span class="token comment"># 全连接层会首先将 Y 的形状变成 (num_steps * batch_size, num_hiddens)，它的输出</span>        <span class="token comment"># 形状为 (num_steps * batch_size, vocab_size)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>Y<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> Y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> output<span class="token punctuation">,</span> self<span class="token punctuation">.</span>state</code></pre><p>在前面两节中，如果不裁剪梯度，模型将无法正常训练。当总的时间步数较大或者当前时间步较小时，循环神经网络的梯度较容易出现衰减或爆炸。</p><h3 id="RNN-的改进"><a href="#RNN-的改进" class="headerlink" title="RNN 的改进"></a>RNN 的改进</h3><h4 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h4><p>虽然裁剪梯度可以应对梯度爆炸，但无法解决梯度衰减的问题。通常由于这个原因，循环神经网络在实际中较难捕捉时间序列中时间步距离较大的依赖关系。</p><p>门控循环神经网络（gated recurrent neural network）的提出，正是为了更好地捕捉时间序列中时间步距离较大的依赖关系。它通过可以学习的门来控制信息的流动。</p><ul><li>门控循环单元</li></ul><p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter06/6.7_gru_3.svg" alt="img"></p><script type="math/tex; mode=display">\begin{aligned}\boldsymbol{R}_t & = \sigma(\boldsymbol{X}_t \boldsymbol{W}_{xr} + \boldsymbol{H}_{t-1} \boldsymbol{W}_{hr} + \boldsymbol{b}_r),\\\boldsymbol{Z}_t & = \sigma(\boldsymbol{X}_t \boldsymbol{W}_{xz} + \boldsymbol{H}_{t-1} \boldsymbol{W}_{hz} + \boldsymbol{b}_z), \\ \tilde{\boldsymbol{H}}_t & = \text{tanh}(\boldsymbol{X}_t \boldsymbol{W}_{xh} + \left(\boldsymbol{R}_t \odot \boldsymbol{H}_{t-1}\right) \boldsymbol{W}_{hh} + \boldsymbol{b}_h), \\ \boldsymbol{H}_t & = \boldsymbol{Z}_t \odot \boldsymbol{H}_{t-1}  + (1 - \boldsymbol{Z}_t) \odot \tilde{\boldsymbol{H}}_t.\end{aligned}</script><ul><li>重置门有助于捕捉时间序列里短期的依赖关系<ul><li>重置门控制了上一时间步的隐藏状态如何流入当前时间步的候选隐藏状态</li><li>上一时间步的隐藏状态可能包含了时间序列截至上一时间步的全部历史信息</li><li>重置门可以用来丢弃与预测无关的历史信息</li></ul></li><li>更新门有助于捕捉时间序列里长期的依赖关系<ul><li>更新门可以控制隐藏状态应该如何被包含当前时间步信息的候选隐藏状态所更新</li><li>假设更新门在时间步 $t’$ 到 $t$（$t’ &lt; t$）之间一直近似 1。那么，在时间步 $t’$ 到 $t$ 之间的输入信息几乎没有流入时间步 $t$ 的隐藏状态 $\boldsymbol{H}_t$。实际上，这可以看作是较早时刻的隐藏状态 $\boldsymbol{H}_{t’-1}$ 一直通过时间保存并传递至当前时间步 $t$。这个设计可以应对循环神经网络中的梯度衰减问题，并更好地捕捉时间序列中时间步距离较大的依赖关系。</li></ul></li></ul><p>实现也可以直接大调库：</p><pre class="language-python" data-language="python"><code class="language-python">lr <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span> <span class="token comment"># 注意调整学习率</span>gru_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>input_size<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> hidden_size<span class="token operator">=</span>num_hiddens<span class="token punctuation">)</span>model <span class="token operator">=</span> d2l<span class="token punctuation">.</span>RNNModel<span class="token punctuation">(</span>gru_layer<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>d2l<span class="token punctuation">.</span>train_and_predict_rnn_pytorch<span class="token punctuation">(</span>model<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> device<span class="token punctuation">,</span>                                corpus_indices<span class="token punctuation">,</span> idx_to_char<span class="token punctuation">,</span> char_to_idx<span class="token punctuation">,</span>                                num_epochs<span class="token punctuation">,</span> num_steps<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> clipping_theta<span class="token punctuation">,</span>                                batch_size<span class="token punctuation">,</span> pred_period<span class="token punctuation">,</span> pred_len<span class="token punctuation">,</span> prefixes<span class="token punctuation">)</span></code></pre><h4 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h4><p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter06/6.8_lstm_3.svg" alt="img"></p><script type="math/tex; mode=display">\begin{aligned}\boldsymbol{I}_t &= \sigma(\boldsymbol{X}_t \boldsymbol{W}_{xi} + \boldsymbol{H}_{t-1} \boldsymbol{W}_{hi} + \boldsymbol{b}_i),\\\boldsymbol{F}_t &= \sigma(\boldsymbol{X}_t \boldsymbol{W}_{xf} + \boldsymbol{H}_{t-1} \boldsymbol{W}_{hf} + \boldsymbol{b}_f),\\\boldsymbol{O}_t &= \sigma(\boldsymbol{X}_t \boldsymbol{W}_{xo} + \boldsymbol{H}_{t-1} \boldsymbol{W}_{ho} + \boldsymbol{b}_o), \\ \tilde{\boldsymbol{C}}_t &= \text{tanh}(\boldsymbol{X}_t \boldsymbol{W}_{xc} + \boldsymbol{H}_{t-1} \boldsymbol{W}_{hc} + \boldsymbol{b}_c), \\ \boldsymbol{C}_t & = \boldsymbol{F}_t \odot \boldsymbol{C}_{t-1} + \boldsymbol{I}_t \odot \tilde{\boldsymbol{C}}_t, \\ \boldsymbol{H}_t &= \boldsymbol{O}_t \odot \text{tanh}(\boldsymbol{C}_t).\end{aligned}</script><ul><li>遗忘门控制上一时间步的记忆细胞 $\boldsymbol{C}_{t-1}$ 中的信息是否传递到当前时间步，而输入门则控制当前时间步的输入 $\boldsymbol{X}_t$ 通过候选记忆细胞 $\tilde{\boldsymbol{C}}_t$ 如何流入当前时间步的记忆细胞。<ul><li>如果遗忘门一直近似 1 且输入门一直近似 0，过去的记忆细胞将一直通过时间保存并传递至当前时间步。这个设计可以应对循环神经网络中的梯度衰减问题，并更好地捕捉时间序列中时间步距离较大的依赖关系。</li></ul></li><li>当输出门近似 1 时，记忆细胞信息将传递到隐藏状态供输出层使用；当输出门近似 0 时，记忆细胞信息只自己保留。</li></ul><p>实现也是大调库。</p><pre class="language-python" data-language="python"><code class="language-python">lr <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span> <span class="token comment"># 注意调整学习率</span>lstm_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>input_size<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> hidden_size<span class="token operator">=</span>num_hiddens<span class="token punctuation">)</span>model <span class="token operator">=</span> d2l<span class="token punctuation">.</span>RNNModel<span class="token punctuation">(</span>lstm_layer<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span>d2l<span class="token punctuation">.</span>train_and_predict_rnn_pytorch<span class="token punctuation">(</span>model<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> device<span class="token punctuation">,</span>                                corpus_indices<span class="token punctuation">,</span> idx_to_char<span class="token punctuation">,</span> char_to_idx<span class="token punctuation">,</span>                                num_epochs<span class="token punctuation">,</span> num_steps<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> clipping_theta<span class="token punctuation">,</span>                                batch_size<span class="token punctuation">,</span> pred_period<span class="token punctuation">,</span> pred_len<span class="token punctuation">,</span> prefixes<span class="token punctuation">)</span></code></pre><h4 id="Deep-RNN"><a href="#Deep-RNN" class="headerlink" title="Deep-RNN"></a>Deep-RNN</h4><p>本章到目前为止介绍的循环神经网络只有一个单向的隐藏层，在深度学习应用里，我们通常会用到含有多个隐藏层的循环神经网络，也称作深度循环神经网络。</p><p>图中演示了一个有 $L$ 个隐藏层的深度循环神经网络，每个隐藏状态不断传递至当前层的下一时间步和当前时间步的下一层。</p><p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter06/6.9_deep-rnn.svg" alt="img"></p><script type="math/tex; mode=display">\begin{align}\boldsymbol{H}_t^{(1)} &= \phi(\boldsymbol{X}_t \boldsymbol{W}_{xh}^{(1)} + \boldsymbol{H}_{t-1}^{(1)} \boldsymbol{W}_{hh}^{(1)}  + \boldsymbol{b}_h^{(1)}), \\ \boldsymbol{H}_t^{(\ell)} & = \phi(\boldsymbol{H}_t^{(\ell-1)} \boldsymbol{W}_{xh}^{(\ell)} + \boldsymbol{H}_{t-1}^{(\ell)} \boldsymbol{W}_{hh}^{(\ell)}  + \boldsymbol{b}_h^{(\ell)}), 1 \lt \ell \le L, \\ \boldsymbol{O}_t &= \boldsymbol{H}_t^{(L)} \boldsymbol{W}_{hq} + \boldsymbol{b}_q.\end{align}</script><h4 id="bi-RNN"><a href="#bi-RNN" class="headerlink" title="bi-RNN"></a>bi-RNN</h4><p>之前介绍的循环神经网络模型都是假设当前时间步是由前面的较早时间步的序列决定的，因此它们都将信息通过隐藏状态从前往后传递。</p><p>有时候，当前时间步也可能由后面时间步决定。例如，当我们写下一个句子时，可能会根据句子后面的词来修改句子前面的用词。双向循环神经网络通过增加从后往前传递信息的隐藏层来更灵活地处理这类信息。</p><p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter06/6.10_birnn.svg" alt="img"></p><script type="math/tex; mode=display">\begin{aligned}\overrightarrow{\boldsymbol{H}}_t &= \phi(\boldsymbol{X}_t \boldsymbol{W}_{xh}^{(f)} + \overrightarrow{\boldsymbol{H}}_{t-1} \boldsymbol{W}_{hh}^{(f)}  + \boldsymbol{b}_h^{(f)}),\\\overleftarrow{\boldsymbol{H}}_t &= \phi(\boldsymbol{X}_t \boldsymbol{W}_{xh}^{(b)} + \overleftarrow{\boldsymbol{H}}_{t+1} \boldsymbol{W}_{hh}^{(b)}  + \boldsymbol{b}_h^{(b)}),\end{aligned}</script><p>然后我们连结两个方向的隐藏状态 $\overrightarrow{\boldsymbol{H}}_t$ 和 $\overleftarrow{\boldsymbol{H}}_t$ 来得到隐藏状态 $\boldsymbol{H}_t \in \mathbb{R}^{n \times 2h}$，并将其输入到输出层。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://tangshusen.me/Dive-into-DL-PyTorch/img/cover.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;《动手学深度学习》原书地址：&lt;a href=&quot;https://github.com/d2l-ai/d2l-zh&quot;&gt;https://github.com/d2l-ai/d2l-zh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;《动手学深度学习》(Pytorch ver.)：&lt;a href=&quot;https://tangshusen.me/Dive-into-DL-PyTorch/#/&quot;&gt;https://tangshusen.me/Dive-into-DL-PyTorch/#/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;知识架构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tangshusen.me/Dive-into-DL-PyTorch/img/book-org.svg&quot; alt=&quot;封面&quot;&gt;&lt;/p&gt;
&lt;p&gt;本文的主要作用是在阅读过程中做一些摘录。对于「机器学习」领域， c7w 虽然曾尝试从各个领域入门，也尝试训过一些模型，但是还是缺少系统性、结构性的学习。希望阅读本书能带来更多的收获吧。&lt;/p&gt;
&lt;p&gt;与前面的一些笔记相比，本文更加侧重于「实践」。也就是说切实地提升自己的代码能力。&lt;/p&gt;
&lt;p&gt;Part B 包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;§ 5 CNN&lt;ul&gt;
&lt;li&gt;基本概念：卷积层、填充与步长、多通道、池化、批量归一化&lt;/li&gt;
&lt;li&gt;模型的例子：LeNet、AlexNet、VGG、NiN、GoogLeNet、ResNet、DenseNet&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;§ 6 RNN&lt;ul&gt;
&lt;li&gt;语言模型及其计算，N-gram 的概念&lt;/li&gt;
&lt;li&gt;RNN 基本模型及其实现，字符数据集的制作&lt;/li&gt;
&lt;li&gt;GRU, LSTM 的原理&lt;/li&gt;
&lt;li&gt;Deep-RNN, bi-RNN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="理论" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/"/>
    
    <category term="理论/机器学习" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/%E7%90%86%E8%AE%BA-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://www.c7w.tech/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>《动手学深度学习》 Pytorch ver. 阅读摘录 Part A</title>
    <link href="https://www.c7w.tech/dive-into-dl-pytorch-A/"/>
    <id>https://www.c7w.tech/dive-into-dl-pytorch-A/</id>
    <published>2022-01-24T09:22:22.000Z</published>
    <updated>2022-01-26T04:01:23.653Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/cover.png" alt=""></p><ul><li>《动手学深度学习》原书地址：<a href="https://github.com/d2l-ai/d2l-zh">https://github.com/d2l-ai/d2l-zh</a></li><li>《动手学深度学习》(Pytorch ver.)：<a href="https://tangshusen.me/Dive-into-DL-PyTorch/#/">https://tangshusen.me/Dive-into-DL-PyTorch/#/</a></li></ul><p>知识架构：</p><p><img src="https://tangshusen.me/Dive-into-DL-PyTorch/img/book-org.svg" alt="封面"></p><p>本文的主要作用是在阅读过程中做一些摘录。对于「机器学习」领域， c7w 虽然曾尝试从各个领域入门，也尝试训过一些模型，但是还是缺少系统性、结构性的学习。希望阅读本书能带来更多的收获吧。</p><p>与前面的一些笔记相比，本文更加侧重于「实践」。也就是说切实地提升自己的代码能力。</p><p>Part A 包含：</p><ul><li>§ 1 深度学习简介</li><li>§ 2 预备知识：Pytorch</li><li>§ 3 深度学习基础<ul><li>线性回归，Softmax 回归，多层感知机三类基本模型</li><li>权重衰减和 Dropout 两类应对过拟合的方法</li></ul></li><li>§ 4 深度学习计算<ul><li>构造 Pytorch 模型的方式</li><li>模型参数的访问、初始化与共享</li><li>自定义 Layer</li><li>读取与存储</li><li>GPU 计算</li></ul></li></ul><a id="more"></a><h2 id="深度学习简介"><a href="#深度学习简介" class="headerlink" title="深度学习简介"></a>深度学习简介</h2><ul><li><strong>机器学习与深度学习的关系</strong></li></ul><p><strong>机器学习</strong>研究如何使计算机系统利用经验改善性能。它是人工智能领域的分支，也是实现人工智能的一种手段。</p><p>在机器学习的众多研究方向中，<strong>表征学习关注如何自动找出表示数据的合适方式</strong>，以便更好地将输入变换为正确的输出。</p><p>而本书要重点探讨的<strong>深度学习是具有多级表示的表征学习方法</strong>。</p><p>在每一级（从原始数据开始），深度学习通过简单的函数将该级的表示变换为更高级的表示。因此，深度学习模型也可以看作是由许多简单函数复合而成的函数。当这些复合的函数足够多时，深度学习模型就可以表达非常复杂的变换。</p><ul><li><strong>深度学习的一个外在特点：End-to-end</strong></li></ul><p>深度学习的一个外在特点是<strong>端到端的训练</strong>。也就是说，并不是将单独调试的部分拼凑起来组成一个系统，而是将整个系统组建好之后一起训练。</p><p>比如说，计算机视觉科学家之前曾一度将特征抽取与机器学习模型的构建分开处理，像是Canny边缘探测 [20] 和SIFT特征提取 [21] 曾占据统治性地位达10年以上，但这也就是人类能找到的最好方法了。</p><p>当深度学习进入这个领域后，这些特征提取方法就被性能更强的自动优化的逐级过滤器替代了。</p><h2 id="预备知识-Pytorch"><a href="#预备知识-Pytorch" class="headerlink" title="预备知识: Pytorch"></a>预备知识: Pytorch</h2><h3 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h3><ul><li><strong>对 Tensor 的操作：Tensor 的创建</strong></li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">函数</th><th style="text-align:center">功能</th></tr></thead><tbody><tr><td style="text-align:center"><code>Tensor(*sizes)</code></td><td style="text-align:center">基础构造函数</td></tr><tr><td style="text-align:center"><code>tensor(data,)</code></td><td style="text-align:center">类似 <code>np.array</code> 的构造函数</td></tr><tr><td style="text-align:center"><code>ones(*sizes)</code></td><td style="text-align:center">全 1 Tensor</td></tr><tr><td style="text-align:center"><code>zeros(*sizes)</code></td><td style="text-align:center">全 0 Tensor</td></tr><tr><td style="text-align:center"><code>eye(*sizes)</code></td><td style="text-align:center">对角线为 1，其他为 0</td></tr><tr><td style="text-align:center"><code>arange(s,e,step)</code></td><td style="text-align:center">从 s 到 e，步长为 step</td></tr><tr><td style="text-align:center"><code>linspace(s,e,steps)</code></td><td style="text-align:center">从 s 到 e，均匀切分成 steps 份</td></tr><tr><td style="text-align:center"><code>rand/randn(*sizes)</code></td><td style="text-align:center">均匀/标准分布</td></tr><tr><td style="text-align:center"><code>normal(mean,std)/uniform(from,to)</code></td><td style="text-align:center">正态分布/均匀分布</td></tr><tr><td style="text-align:center"><code>randperm(m)</code></td><td style="text-align:center">随机排列</td></tr></tbody></table></div><ul><li><strong>对 Tensor 进行操作时注意其可能的数据共享</strong></li></ul><p>如使用 <code>view()</code> 改变 Tensor 的形状的时候，注意返回的新 Tensor 与源 Tensor 虽然可能有不同的 size，但是是共享 data 的。</p><p>所以如果我们想返回一个真正新的副本（即不共享 data 内存）该怎么办呢？Pytorch 还提供了一个 <code>reshape()</code> 可以改变形状，但是此函数并不能保证返回的是其拷贝，所以不推荐使用。推荐先用 <code>clone</code> 创造一个副本然后再使用 <code>view</code>。</p><p>注：虽然 <code>view</code> 返回的 <code>Tensor</code> 与源 <code>Tensor</code> 是共享 <code>data</code> 的，但是依然是一个新的 <code>Tensor</code>（因为 <code>Tensor</code> 除了包含 <code>data</code> 外还有一些其他属性），二者 <code>id</code>（内存地址）并不一致。</p><p>另外一个常用的函数就是 <code>item()</code>, 它可以将一个标量 <code>Tensor</code> 转换成一个 Python Number。</p><ul><li><strong>广播机制</strong> Broadcasting</li></ul><p>当对两个形状不同的 <code>Tensor</code> 按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个 <code>Tensor</code> 形状相同后再按元素运算。例如：</p><pre class="language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x <span class="token operator">+</span> y<span class="token punctuation">)</span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># x</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># y</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># x+y</span></code></pre><ul><li><strong><code>Tensor</code> 与 <code>ndarray</code></strong> 的转换</li></ul><p>很容易用 <code>numpy()</code> 和 <code>from_numpy()</code> 将 <code>Tensor</code> 和 NumPy 中的数组相互转换。但是需要注意的一点是：两个函数所产生的 <code>Tensor</code> 和 NumPy 中的数组共享相同的内存（所以它们之间的转换很快），改变其中一个时另一个也会改变。</p><p>与之相对比，还有一个常用的将 NumPy 中的 array 转换成 <code>Tensor</code> 的方法就是 <code>torch.tensor()</code>, 需要注意的是，此方法总是会进行数据拷贝（就会消耗更多的时间和空间），所以返回的 <code>Tensor</code>和原来的数据不再共享内存。</p><p>所有在CPU上的 <code>Tensor</code>（除了 <code>CharTensor</code>）都支持与 NumPy 数组相互转换。</p><ul><li><strong><code>Tensor</code> on GPU</strong></li></ul><p>用方法 <code>to()</code> 可以将 <code>Tensor</code> 在 CPU 和 GPU（需要硬件支持）之间相互移动。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># 以下代码只有在PyTorch GPU版本上才会执行</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>          <span class="token comment"># GPU</span>    y <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>x<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>  <span class="token comment"># 直接创建一个在GPU上的Tensor</span>    x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>                       <span class="token comment"># 等价于 .to("cuda")</span>    z <span class="token operator">=</span> x <span class="token operator">+</span> y    <span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>double<span class="token punctuation">)</span><span class="token punctuation">)</span>       <span class="token comment"># to()还可以同时更改数据类型</span></code></pre><h3 id="Autograd"><a href="#Autograd" class="headerlink" title="Autograd"></a>Autograd</h3><ul><li><strong><code>Tensor</code> 的 <code>requires_grad</code> 与 <code>Function</code></strong></li></ul><p>上一节介绍的 <code>Tensor</code> 是这个包的核心类，如果将其属性 <code>requires_grad</code> 设置为 <code>True</code>，它将开始追踪（track）在其上的所有操作（这样就可以利用链式法则进行梯度传播了）。</p><p>完成计算后，可以调用 <code>backward()</code> 来完成所有梯度计算。此 <code>Tensor</code> 的梯度将累积到 <code>.grad</code> 属性中。</p><p>如果不想要被继续追踪，可以调用 <code>.detach()</code> 将其从追踪记录中分离出来，这样就可以防止将来的计算被追踪，这样梯度就传不过去了。此外，还可以用 <code>with torch.no_grad()</code> 将不想被追踪的操作代码块包裹起来，这种方法在评估模型的时候很常用，因为在评估模型时，我们并不需要计算可训练参数（<code>requires_grad=True</code>）的梯度。</p><p><code>Function</code> 是另外一个很重要的类。<code>Tensor</code> 和 <code>Function</code> 互相结合就可以构建一个记录有整个计算过程的有向无环图。每个 <code>Tensor</code> 都有一个 <code>grad_fn</code> 属性，该属性即创建该 <code>Tensor</code> 的 <code>Function</code> , 就是说该 <code>Tensor</code> 是不是通过某些运算得到的，若是，则 <code>grad_fn</code> 返回一个与这些运算相关的对象，否则是 None。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad_fn<span class="token punctuation">)</span><span class="token boolean">None</span><span class="token operator">>></span><span class="token operator">></span> y <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">.</span>grad_fn<span class="token punctuation">)</span><span class="token operator">&lt;</span>AddBackward0 <span class="token builtin">object</span> at <span class="token number">0x7fbb003b4250</span><span class="token operator">></span><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>is_leaf<span class="token punctuation">,</span> y<span class="token punctuation">.</span>is_leaf<span class="token punctuation">)</span><span class="token boolean">True</span> <span class="token boolean">False</span><span class="token operator">>></span><span class="token operator">></span> z <span class="token operator">=</span> y <span class="token operator">*</span> y <span class="token operator">*</span> <span class="token number">3</span><span class="token operator">>></span><span class="token operator">></span> out <span class="token operator">=</span> z<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">,</span> out<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>MulBackward0<span class="token operator">></span><span class="token punctuation">)</span> tensor<span class="token punctuation">(</span><span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>MeanBackward0<span class="token operator">></span><span class="token punctuation">)</span></code></pre><p>注意 x 是直接创建的，所以它没有 <code>grad_fn</code>, 而 y 是通过一个加法操作创建的，所以它有一个为 <code>&lt;AddBackward&gt;</code> 的 <code>grad_fn</code>。像 x 这种直接创建的称为叶子节点，叶子节点对应的 <code>grad_fn</code> 是 <code>None</code>。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment"># 缺失情况下默认 requires_grad = False</span><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>a <span class="token operator">*</span> <span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>a <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span> <span class="token comment"># False</span><span class="token boolean">False</span><span class="token comment"># 通过 .requires_grad_() 来用 in-place 的方式改变 requires_grad 属性</span><span class="token operator">>></span><span class="token operator">></span> a<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0261</span><span class="token punctuation">,</span>  <span class="token number">0.6281</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.1572</span><span class="token punctuation">,</span>  <span class="token number">6.8756</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span> <span class="token comment"># True</span><span class="token boolean">True</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> <span class="token punctuation">(</span>a <span class="token operator">*</span> a<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>grad_fn<span class="token punctuation">)</span><span class="token operator">&lt;</span>SumBackward0 <span class="token builtin">object</span> at <span class="token number">0x7fba80387730</span><span class="token operator">></span></code></pre><ul><li><strong><code>backward()</code></strong></li></ul><p>因为 <code>out</code> 是一个标量，所以调用 <code>backward()</code> 时不需要指定求导变量：</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> out<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 等价于 out.backward(torch.tensor(1.))</span><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">)</span> <span class="token comment"># Out 关于 x 的梯度, d(out)/dx</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4.5000</span><span class="token punctuation">,</span> <span class="token number">4.5000</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">4.5000</span><span class="token punctuation">,</span> <span class="token number">4.5000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p>本质上，反向传播的过程是在计算一系列 Jacobi 矩阵的乘积。</p><p>注意：grad 在反向传播过程中是累加的，这意味着每一次运行反向传播，梯度都会累加之前的梯度，所以<strong>一般在反向传播之前需把梯度清零</strong>。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token comment"># 再来反向传播一次，注意grad是累加的</span><span class="token operator">>></span><span class="token operator">></span> out2 <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> out2<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5.5000</span><span class="token punctuation">,</span> <span class="token number">5.5000</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">5.5000</span><span class="token punctuation">,</span> <span class="token number">5.5000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> out3 <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> out3<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p>注：PyTorch 的 <code>backward</code> 为什么有一个 <code>grad_variables</code> 参数？</p><p>假设 x 经过一番计算得到 y，那么 <code>y.backward(w)</code> 求的不是 y 对 x 的导数，而是 <code>l = torch.sum(y*w)</code> 对 x 的导数。w 可以视为 y 的各分量的权重，也可以视为遥远的损失函数 l 对 y 的偏导数（这正是函数说明文档的含义）。特别地，若 y 为标量，w 取默认值 1.0，才是按照我们通常理解的那样，求 y 对 x 的导数。</p><ul><li><strong>中断梯度传播</strong></li></ul><pre class="language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y1 <span class="token operator">=</span> x <span class="token operator">**</span> <span class="token number">2</span> <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    y2 <span class="token operator">=</span> x <span class="token operator">**</span> <span class="token number">3</span>y3 <span class="token operator">=</span> y1 <span class="token operator">+</span> y2<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>y1<span class="token punctuation">,</span> y1<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span> <span class="token comment"># True</span><span class="token keyword">print</span><span class="token punctuation">(</span>y2<span class="token punctuation">,</span> y2<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span> <span class="token comment"># False</span><span class="token keyword">print</span><span class="token punctuation">(</span>y3<span class="token punctuation">,</span> y3<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span> <span class="token comment"># True</span>Output<span class="token punctuation">:</span><span class="token boolean">True</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>PowBackward0<span class="token operator">></span><span class="token punctuation">)</span> <span class="token boolean">True</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token boolean">False</span>tensor<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>ThAddBackward<span class="token operator">></span><span class="token punctuation">)</span> <span class="token boolean">True</span></code></pre><p>可以看到，上面的 <code>y2</code> 是没有 <code>grad_fn</code> 而且 <code>y2.requires_grad=False</code> 的，而 <code>y3</code> 是有 <code>grad_fn</code> 的。如果我们将<code>y3</code>对<code>x</code>求梯度的话：</p><pre class="language-python" data-language="python"><code class="language-python">y3<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">)</span></code></pre><p>正如我们所理解的，$y_3 = y_1 + y_2 = x^2 + x^3$，其中 $y_2$ 的梯度不被回传，因此 $\dfrac {d y_3} {dx} = 2x$.</p><p>此外，如果我们想要修改 <code>Tensor</code> 的数值，但是又不希望被 <code>autograd</code> 记录（即不会影响反向传播），那么我么可以对 <code>tensor.data</code> 进行操作。</p><pre class="language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>data<span class="token punctuation">)</span> <span class="token comment"># 还是一个tensor</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span> <span class="token comment"># 但是已经是独立于计算图之外</span>y <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> xx<span class="token punctuation">.</span>data <span class="token operator">*=</span> <span class="token number">100</span> <span class="token comment"># 只改变了值，不会记录在计算图，所以不会影响梯度传播</span>y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># 更改data的值也会影响tensor的值</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token boolean">False</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h2 id="深度学习基础"><a href="#深度学习基础" class="headerlink" title="深度学习基础"></a>深度学习基础</h2><h3 id="基础模型"><a href="#基础模型" class="headerlink" title="基础模型"></a>基础模型</h3><h4 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h4><p>首先，回归问题的输出是连续值，而分类问题的输出是离散值，这是二者的区别。</p><ul><li><strong>模型定义</strong>：假设我们采集的样本数为 $n$​，索引为 $i$​ 的样本的特征为 $x_1^{(i)}$​ 和 $x_2^{(i)}$​，标签为 $y^{(i)}$​。对于索引为 $i$​ 的房屋，线性回归模型的房屋价格预测表达式为 <script type="math/tex">\hat{y}^{(i)} = x_1^{(i)} w_1 + x_2^{(i)} w_2 + b</script>​</li><li><strong>损失函数</strong>：$\ell^{(i)}(w_1, w_2, b) = \frac{1}{2} \left(\hat{y}^{(i)} - y^{(i)}\right)^2$​, $ \ell(w_1, w_2, b) =\frac{1}{n} \sum_{i=1}^n \ell^{(i)}(w_1, w_2, b) =\frac{1}{n} \sum_{i=1}^n \frac{1}{2}\left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right)^2$​</li></ul><p>在模型训练中，我们希望找出一组模型参数，记为 $w_1^<em>, w_2^</em>, b^<em>$，来使训练样本平均损失最小：$ w_1^</em>, w_2^<em>, b^</em> = \underset{w_1, w_2, b}{\arg\min} \ell(w_1, w_2, b) $</p><ul><li><strong>优化算法</strong></li></ul><p>当模型和损失函数形式较为简单时，上面的误差最小化问题的解可以直接用公式表达出来。这类解叫作<strong>解析解</strong>。本节使用的线性回归和平方误差刚好属于这个范畴。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作<strong>数值解</strong>。</p><p>在求数值解的优化算法中，<strong>小批量随机梯度下降</strong>（Mini-batch SGD, mini-batch stochastic gradient descent）在深度学习中被广泛使用。它的算法很简单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch）$\mathcal{B}$​，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数 learning_rate $\eta$ 的乘积作为模型参数在本次迭代的减小量。</p><p>在训练本节讨论的线性回归模型的过程中，模型的每个参数将作如下迭代：</p><script type="math/tex; mode=display">\begin{aligned} w_1 &\leftarrow w_1 - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \frac{ \partial \ell^{(i)}(w_1, w_2, b) }{\partial w_1} = w_1 - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}x_1^{(i)} \left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right), \\w_2 &\leftarrow w_2 - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \frac{ \partial \ell^{(i)}(w_1, w_2, b) }{\partial w_2} = w_2 - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}x_2^{(i)} \left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right), \\b &\leftarrow b - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \frac{ \partial \ell^{(i)}(w_1, w_2, b) }{\partial b} = b - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}\left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right). \end{aligned}</script><p>在上式中，$|\mathcal{B}|$ 代表每个小批量中的样本个数（批量大小，batch size），$\eta$ 称作学习率（learning rate）并取正数。需要强调的是，这里的批量大小和学习率的值是人为设定的，并不是通过模型训练学出的，因此叫作超参数（hyperparameter）。我们通常所说的“调参”指的正是调节超参数，例如通过反复试错来找到超参数合适的值。</p><h5 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h5><ul><li>生成数据集</li></ul><pre class="language-python" data-language="python"><code class="language-python">num_inputs <span class="token operator">=</span> <span class="token number">2</span>num_examples <span class="token operator">=</span> <span class="token number">1000</span>true_w <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4</span><span class="token punctuation">]</span>true_b <span class="token operator">=</span> <span class="token number">4.2</span>features <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>num_examples<span class="token punctuation">,</span> num_inputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>labels <span class="token operator">=</span> true_w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> true_w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> true_blabels <span class="token operator">+=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> size<span class="token operator">=</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span></code></pre><ul><li>读取数据</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> Databatch_size <span class="token operator">=</span> <span class="token number">10</span><span class="token comment"># 将训练数据的特征和标签组合</span>dataset <span class="token operator">=</span> Data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span>features<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token comment"># 随机读取小批量</span>data_iter <span class="token operator">=</span> Data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></code></pre><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>    <span class="token keyword">break</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2.7723</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6627</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.1058</span><span class="token punctuation">,</span>  <span class="token number">0.7688</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.4901</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.2260</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7227</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2664</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3390</span><span class="token punctuation">,</span>  <span class="token number">0.1162</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.6705</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.7930</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.2576</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2928</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">2.0475</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.7440</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.0685</span><span class="token punctuation">,</span>  <span class="token number">1.1920</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.0996</span><span class="token punctuation">,</span>  <span class="token number">0.5106</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.9066</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6247</span><span class="token punctuation">,</span>  <span class="token number">9.3383</span><span class="token punctuation">,</span>  <span class="token number">3.6537</span><span class="token punctuation">,</span>  <span class="token number">3.1283</span><span class="token punctuation">,</span> <span class="token number">17.0213</span><span class="token punctuation">,</span>  <span class="token number">5.6953</span><span class="token punctuation">,</span> <span class="token number">17.6279</span><span class="token punctuation">,</span>         <span class="token number">2.2809</span><span class="token punctuation">,</span>  <span class="token number">4.6661</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 可以看到，对迭代器进行迭代每次拿到的数据也是以 batch 的形式封装成 array</span></code></pre><ul><li>定义模型</li></ul><p>首先，导入 <code>torch.nn</code> 模块。实际上，“nn”是neural networks（神经网络）的缩写。</p><p>顾名思义，该模块定义了大量神经网络的层。之前我们已经用过了 <code>autograd</code>，而 <code>nn</code> 就是利用 <code>autograd</code> 来定义模型。</p><p><code>nn</code> 的核心数据结构是 <code>Module</code>，它是一个抽象概念，既可以表示神经网络中的某个层（layer），也可以表示一个包含很多层的神经网络。在实际使用中，最常见的做法是继承 <code>nn.Module</code>，撰写自己的网络/层。</p><p>一个 <code>nn.Module</code> 实例应该包含一些层以及返回输出的前向传播（forward）方法。下面先来看看如何用 <code>nn.Module</code> 实现一个线性回归模型。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LinearNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_feature<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>LinearNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_feature<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># forward 定义前向传播</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> ynet <span class="token operator">=</span> LinearNet<span class="token punctuation">(</span>num_inputs<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span> <span class="token comment"># 使用print可以打印出网络的结构</span><span class="token comment"># Output:</span>LinearNet<span class="token punctuation">(</span>  <span class="token punctuation">(</span>linear<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>事实上我们还可以用<code>nn.Sequential</code>来更加方便地搭建网络，<code>Sequential</code>是一个有序的容器，网络层将按照在传入<code>Sequential</code>的顺序依次被添加到计算图中。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># 写法一</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># 此处还可以传入其他层</span>    <span class="token punctuation">)</span><span class="token comment"># 写法二</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'linear'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># net.add_module ......</span><span class="token comment"># 写法三</span><span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDictnet <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span>          <span class="token punctuation">(</span><span class="token string">'linear'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>          <span class="token comment"># ......</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>Output<span class="token punctuation">:</span>Sequential<span class="token punctuation">(</span>  <span class="token punctuation">(</span>linear<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></code></pre><p>可以通过 <code>net.parameters()</code> 来查看模型所有的可学习参数，此函数将返回一个生成器。<br><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">)</span></code></pre><br>输出：<br><pre class="language-none"><code class="language-none">Parameter containing:tensor([[-0.0277,  0.2771]], requires_grad&#x3D;True)Parameter containing:tensor([0.3395], requires_grad&#x3D;True)</code></pre></p><p>注意：<code>torch.nn</code> <strong>仅支持输入一个 batch 的样本</strong>，而不支持单个样本输入，如果只有单个样本，可使用 <code>input.unsqueeze(0)</code> 来添加一维。</p><p>附：<code>unsqueeze()</code> 的使用：</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6444</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5408</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6239</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8880</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7358</span><span class="token punctuation">,</span>  <span class="token number">0.7287</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">1.1660</span><span class="token punctuation">,</span>  <span class="token number">1.3125</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4676</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4620</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1572</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4755</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">0.6389</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.4514</span><span class="token punctuation">,</span>  <span class="token number">0.3339</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># 最外层加壳</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6444</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5408</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6239</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8880</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7358</span><span class="token punctuation">,</span>  <span class="token number">0.7287</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span> <span class="token number">1.1660</span><span class="token punctuation">,</span>  <span class="token number">1.3125</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4676</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4620</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1572</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4755</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span> <span class="token number">0.6389</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.4514</span><span class="token punctuation">,</span>  <span class="token number">0.3339</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 次外层元素</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6444</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5408</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6239</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8880</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7358</span><span class="token punctuation">,</span>  <span class="token number">0.7287</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span> <span class="token number">1.1660</span><span class="token punctuation">,</span>  <span class="token number">1.3125</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4676</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4620</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1572</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4755</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span> <span class="token number">0.6389</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.4514</span><span class="token punctuation">,</span>  <span class="token number">0.3339</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6444</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5408</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6239</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8880</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7358</span><span class="token punctuation">,</span>  <span class="token number">0.7287</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.1660</span><span class="token punctuation">,</span>  <span class="token number">1.3125</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4676</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4620</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1572</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4755</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.6389</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.4514</span><span class="token punctuation">,</span>  <span class="token number">0.3339</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6444</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5408</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6239</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8880</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7358</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span> <span class="token number">0.7287</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.1660</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span> <span class="token number">1.3125</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3.4676</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4620</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1572</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.4755</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.6389</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2.4514</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span> <span class="token number">0.3339</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span><span class="token punctuation">:</span>  File <span class="token string">"&lt;stdin>"</span><span class="token punctuation">,</span> line <span class="token number">1</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>IndexError<span class="token punctuation">:</span> Dimension out of <span class="token builtin">range</span> <span class="token punctuation">(</span>expected to be <span class="token keyword">in</span> <span class="token builtin">range</span> of <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> but got <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 最内层</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6444</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5408</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6239</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8880</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7358</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span> <span class="token number">0.7287</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.1660</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span> <span class="token number">1.3125</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3.4676</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4620</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1572</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.4755</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.6389</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2.4514</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span> <span class="token number">0.3339</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> a<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 一直到最内层</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6444</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5408</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6239</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8880</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7358</span><span class="token punctuation">,</span>  <span class="token number">0.7287</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.1660</span><span class="token punctuation">,</span>  <span class="token number">1.3125</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4676</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4620</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1572</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4755</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.6389</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.4514</span><span class="token punctuation">,</span>  <span class="token number">0.3339</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> a<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 某一层</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6444</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5408</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6239</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8880</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7358</span><span class="token punctuation">,</span>  <span class="token number">0.7287</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">1.1660</span><span class="token punctuation">,</span>  <span class="token number">1.3125</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4676</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4620</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1572</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4755</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">0.6389</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.4514</span><span class="token punctuation">,</span>  <span class="token number">0.3339</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><ul><li>初始化模型参数</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> initinit<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 也可以直接修改bias的data: net[0].bias.data.fill_(0)</span></code></pre><ul><li>定义损失函数</li></ul><p>PyTorch 在 <code>nn</code> 模块中提供了各种损失函数，这些损失函数可看作是一种特殊的层，PyTorch 也将这些损失函数实现为 <code>nn.Module</code> 的子类。我们现在使用它提供的均方误差损失作为模型的损失函数。</p><pre class="language-python" data-language="python"><code class="language-python">loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><ul><li>定义优化算法</li></ul><p>同样，我们也无须自己实现小批量随机梯度下降算法。<code>torch.optim</code> 模块提供了很多常用的优化算法比如 SGD、Adam 和 RMSProp 等。下面我们创建一个用于优化 <code>net</code> 所有参数的优化器实例，并指定学习率为 0.03 的小批量随机梯度下降（SGD）为优化算法。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optimoptimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.03</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span></code></pre><p>输出：<br><pre class="language-none"><code class="language-none">SGD (Parameter Group 0    dampening: 0    lr: 0.03    momentum: 0    nesterov: False    weight_decay: 0)</code></pre></p><p>我们还可以为不同子网络设置不同的学习率，这在 fine-tune 时经常用到。例：<br><pre class="language-python" data-language="python"><code class="language-python">optimizer <span class="token operator">=</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span><span class="token punctuation">[</span>                <span class="token comment"># 如果对某个参数不指定学习率，就使用最外层的默认学习率</span>                <span class="token punctuation">&#123;</span><span class="token string">'params'</span><span class="token punctuation">:</span> net<span class="token punctuation">.</span>subnet1<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> <span class="token comment"># lr=0.03</span>                <span class="token punctuation">&#123;</span><span class="token string">'params'</span><span class="token punctuation">:</span> net<span class="token punctuation">.</span>subnet2<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.01</span><span class="token punctuation">&#125;</span>            <span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.03</span><span class="token punctuation">)</span></code></pre></p><p>有时候我们不想让学习率固定成一个常数，那如何调整学习率呢？主要有两种做法。一种是修改 <code>optimizer.param_groups</code> 中对应的学习率，另一种是更简单也是较为推荐的做法 —— <strong>新建优化器</strong>，由于optimizer十分轻量级，构建开销很小，故而可以构建新的 optimizer。但是后者对于使用动量的优化器（如 Adam），会丢失动量等状态信息，可能会造成损失函数的收敛出现震荡等情况。<br><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># 调整学习率</span><span class="token keyword">for</span> param_group <span class="token keyword">in</span> optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>    param_group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span> <span class="token operator">*=</span> <span class="token number">0.1</span> <span class="token comment"># 学习率为之前的0.1倍</span></code></pre></p><ul><li>训练模型</li></ul><p>通过调用 <code>optim</code> 实例的 <code>step</code> 函数来迭代模型参数。按照小批量随机梯度下降的定义，我们在 <code>step</code> 函数中指明批量大小，从而对批量中样本梯度求平均。</p><pre class="language-python" data-language="python"><code class="language-python">num_epochs <span class="token operator">=</span> <span class="token number">3</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>        output <span class="token operator">=</span> net<span class="token punctuation">(</span>X<span class="token punctuation">)</span>        l <span class="token operator">=</span> loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> y<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 梯度清零，等价于net.zero_grad()</span>        l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch %d, loss: %f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> l<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>输出：<br><pre class="language-none"><code class="language-none">epoch 1, loss: 0.000457epoch 2, loss: 0.000081epoch 3, loss: 0.000198</code></pre></p><h4 id="Softmax-Regression"><a href="#Softmax-Regression" class="headerlink" title="Softmax Regression"></a>Softmax Regression</h4><p>线性回归模型适用于<strong>输出为连续值</strong>的情景。</p><p>在另一类情景中，模型输出可以是一个像图像类别这样的<strong>离散值</strong>。对于这样的离散值预测问题，我们可以使用诸如 softmax 回归在内的<strong>分类模型</strong>。</p><p>和线性回归不同，softmax 回归的<strong>输出单元从一个变成了多个</strong>，且引入了 softmax 运算使输出更适合离散值的预测和训练。本节以 softmax 回归模型为例，介绍神经网络中的分类模型。</p><p>softmax 回归跟线性回归一样将输入特征与权重做线性叠加。与线性回归的一个主要不同在于，softmax 回归的<strong>输出值个数等于标签里的类别数</strong>。</p><ul><li>模型定义</li></ul><script type="math/tex; mode=display">\begin{aligned} o_1 &= x_1 w_{11} + x_2 w_{21} + x_3 w_{31} + x_4 w_{41} + b_1,\\ o_2 &= x_1 w_{12} + x_2 w_{22} + x_3 w_{32} + x_4 w_{42} + b_2,\\ o_3 &= x_1 w_{13} + x_2 w_{23} + x_3 w_{33} + x_4 w_{43} + b_3. \\\end{aligned}</script><script type="math/tex; mode=display">\hat{y}_1, \hat{y}_2, \hat{y}_3 = \text{softmax}(o_1, o_2, o_3)</script><p>其中：</p><script type="math/tex; mode=display">\hat{y_1} = \frac{ \exp(o_1)}{\sum_{i=1}^3 \exp(o_i)},\quad \hat{y_2} = \frac{ \exp(o_2)}{\sum_{i=1}^3 \exp(o_i)},\quad \hat{y_3} = \frac{ \exp(o_3)}{\sum_{i=1}^3 \exp(o_i)}.</script><ul><li>损失函数：Cross Entropy</li></ul><script type="math/tex; mode=display">H\left(\boldsymbol y^{(i)}, \boldsymbol {\hat y}^{(i)}\right ) = -\sum_{j=1}^q y_j^{(i)} \log \hat y_j^{(i)},</script><p>交叉熵只关心<strong>对正确类别</strong>的预测概率，因为只要其值足够大，就可以确保分类结果正确。</p><p>假设训练数据集的样本数为 $n$​，交叉熵损失函数定义为 $\ell(\boldsymbol{\Theta}) = \frac{1}{n} \sum_{i=1}^n H\left(\boldsymbol y^{(i)}, \boldsymbol {\hat y}^{(i)}\right ) $​. 其中$\boldsymbol{\Theta}$​​代表模型参数。</p><p>注意：这里的交叉熵是 H = - [ 实际值 * log(预测值) ] 的求和。而 log(预测值) 却又可以替换为是预测时的 logits $o_i$​​​，二者之间只差了一个系数。因此背后实现可以直接用 logits 参与简化计算。</p><blockquote><p>数据集与相关包的介绍：Fashion-MNIST</p><p>本节我们将使用 torchvision 包，它是服务于 PyTorch 深度学习框架的，主要用来构建计算机视觉模型。 torchvision 主要由以下几部分构成：</p><ol><li><code>torchvision.datasets</code>: 一些加载数据的函数及常用的数据集接口；</li><li><code>torchvision.models</code>: 包含常用的模型结构（含预训练模型），例如 AlexNet、VGG、ResNet 等；</li><li><code>torchvision.transforms</code>: 常用的图片变换，例如裁剪、旋转等；</li><li><code>torchvision.utils</code>: 其他的一些有用的方法。</li></ol></blockquote><h4 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a>感知机</h4><ul><li>仅添加隐藏层：即便再添加更多的隐藏层，将线性隐藏层间彼此相接依然只能与仅含输出层的单层神经网络等价。</li></ul><p>上述问题的根源在于全连接层只是对数据做仿射变换（affine transformation），而多个仿射变换的叠加仍然是一个仿射变换。</p><p>解决问题的一个方法是引入非线性变换，例如对隐藏变量使用按元素运算的非线性函数进行变换，然后再作为下一个全连接层的输入。</p><p>这个非线性函数被称为激活函数（activation function）。下面我们介绍几个常用的激活函数。</p><ul><li>$Relu(x) = \max(0, x)$.</li><li>$sigmoid(x) =\sigma(x) = \dfrac 1 {1 + e^{-x}}$.</li><li>$\text{tanh}(x) = \frac{1 - \exp(-2x)}{1 + \exp(-2x)}$.</li></ul><p>多层感知机就是含有至少一个隐藏层的由全连接层组成的神经网络，且每个隐藏层的输出通过激活函数进行变换。多层感知机的层数和各隐藏层中隐藏单元个数都是超参数。</p><h3 id="应对过拟合"><a href="#应对过拟合" class="headerlink" title="应对过拟合"></a>应对过拟合</h3><h4 id="L2-Regularization"><a href="#L2-Regularization" class="headerlink" title="L2 Regularization"></a>L2 Regularization</h4><ul><li><strong>权重衰减</strong>是一种应对过拟合的方法</li><li>权重衰减等价于 $L_2$ 范数正则化（regularization）。正则化通过为模型损失函数添加惩罚项使学出的模型参数值较小，是应对过拟合的常用手段。我们先描述 $L_2$ 范数正则化，再解释它为何又称权重衰减。</li></ul><p>$L_2$ 范数正则化在模型原损失函数基础上添加 $L_2$ 范数惩罚项，从而得到训练所需要最小化的函数。</p><p>$L_2$ 范数惩罚项指的是模型权重参数每个元素的平方和与一个正的常数的乘积。即定义新的 Loss Function 为：</p><script type="math/tex; mode=display">\ell(w, b) + \frac{\lambda}{2n} \|\boldsymbol{w}\|^2</script><p>为什么 $L_2$ Regularization 能起到“权重衰减”的作用呢？我们考虑 Optimizer 的迭代方式…</p><script type="math/tex; mode=display">\begin{aligned} w_1 &\leftarrow \left(1- \frac{\eta\lambda}{|\mathcal{B}|} \right)w_1 - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}x_1^{(i)} \left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right),\\ w_2 &\leftarrow \left(1- \frac{\eta\lambda}{|\mathcal{B}|} \right)w_2 - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}x_2^{(i)} \left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right). \end{aligned}</script><p>这是因为如果我们对损失函数求梯度，就必然带有了和原有的 $w$ 有关的一项。然后我们在做优化迭代的过程中，$L_2$ 范数正则化令权重 $w_1$ 和 $w_2$ 先自乘小于 1 的数，再减去不含惩罚项的梯度。因此，$L_2$ 范数正则化又叫权重衰减。</p><p>权重衰减通过惩罚绝对值较大的模型参数为需要学习的模型增加了限制，这可能对过拟合有效。实际场景中，我们有时也在惩罚项中添加偏差元素的平方和。</p><h5 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h5><ul><li>定义 L2 范数惩罚项</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">l2_penalty</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token punctuation">(</span>w<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span></code></pre><ul><li>Train (From scratch)</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">fit_and_plot</span><span class="token punctuation">(</span>lambd<span class="token punctuation">)</span><span class="token punctuation">:</span>    w<span class="token punctuation">,</span> b <span class="token operator">=</span> init_params<span class="token punctuation">(</span><span class="token punctuation">)</span>    train_ls<span class="token punctuation">,</span> test_ls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> train_iter<span class="token punctuation">:</span>            <span class="token comment"># 添加了L2范数惩罚项</span>            l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token operator">+</span> lambd <span class="token operator">*</span> l2_penalty<span class="token punctuation">(</span>w<span class="token punctuation">)</span>            l <span class="token operator">=</span> l<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> w<span class="token punctuation">.</span>grad <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>                w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>                b<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>            l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            d2l<span class="token punctuation">.</span>sgd<span class="token punctuation">(</span><span class="token punctuation">[</span>w<span class="token punctuation">,</span> b<span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>        train_ls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>train_features<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">,</span> train_labels<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        test_ls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>test_features<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">,</span> test_labels<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    d2l<span class="token punctuation">.</span>semilogy<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> train_ls<span class="token punctuation">,</span> <span class="token string">'epochs'</span><span class="token punctuation">,</span> <span class="token string">'loss'</span><span class="token punctuation">,</span>                 <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> test_ls<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'L2 norm of w:'</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><ul><li>Train (Simple)</li></ul><p>这里我们直接在构造优化器实例时通过 <code>weight_decay</code> 参数来指定权重衰减超参数。默认下，PyTorch 会对权重和偏差同时衰减。我们可以分别对权重和偏差构造优化器实例，从而只对权重衰减。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">fit_and_plot_pytorch</span><span class="token punctuation">(</span>wd<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 对权重参数衰减。权重名称一般是以weight结尾</span>    net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>net<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>net<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    optimizer_w <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>params<span class="token operator">=</span><span class="token punctuation">[</span>net<span class="token punctuation">.</span>weight<span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span>wd<span class="token punctuation">)</span> <span class="token comment"># 对权重参数衰减</span>    optimizer_b <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>params<span class="token operator">=</span><span class="token punctuation">[</span>net<span class="token punctuation">.</span>bias<span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span>  <span class="token comment"># 不对偏差参数衰减</span>    train_ls<span class="token punctuation">,</span> test_ls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> train_iter<span class="token punctuation">:</span>            l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer_w<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer_b<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># 对两个 optimizer 实例分别调用 step 函数，从而分别更新权重和偏差</span>            optimizer_w<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer_b<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        train_ls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>train_features<span class="token punctuation">)</span><span class="token punctuation">,</span> train_labels<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        test_ls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>test_features<span class="token punctuation">)</span><span class="token punctuation">,</span> test_labels<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    d2l<span class="token punctuation">.</span>semilogy<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> train_ls<span class="token punctuation">,</span> <span class="token string">'epochs'</span><span class="token punctuation">,</span> <span class="token string">'loss'</span><span class="token punctuation">,</span>                 <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> test_ls<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'L2 norm of w:'</span><span class="token punctuation">,</span> net<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><p>除了前一节介绍的权重衰减以外，深度学习模型常常使用丢弃法（Dropout）来应对过拟合问题。丢弃法有一些不同的变体。本节中提到的丢弃法特指倒置丢弃法（inverted dropout）。</p><p>当对某个隐藏层使用丢弃法时，该层的隐藏单元将有一定概率被丢弃掉。设丢弃概率为 $p$，那么有 $p$ 的概率其输出 $h_i$ 会被清零，有 $1-p$ 的概率 $h_i$ 会除以 $1-p$ 做拉伸。</p><p>丢弃概率是丢弃法的超参数。具体来说，设随机变量 $\xi_i$ 为 0 和 1 的概率分别为 $p$ 和 $1-p$ 。使用丢弃法时我们计算新的隐藏单元 $ h_i’ = \frac{\xi_i}{1-p} h_i $，由于 $E(\xi_i) = 1-p$，因此</p><script type="math/tex; mode=display">E(h_i') = \frac{E(\xi_i)}{1-p}h_i = h_i</script><p>即<strong>丢弃法不改变其输入的期望值</strong>。</p><ul><li>实现（Simple）</li></ul><pre class="language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>        d2l<span class="token punctuation">.</span>FlattenLayer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> num_hiddens1<span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>drop_prob1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># Here</span>        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hiddens1<span class="token punctuation">,</span> num_hiddens2<span class="token punctuation">)</span><span class="token punctuation">,</span>         nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>drop_prob2<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># Here</span>        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hiddens2<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token keyword">for</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>param<span class="token punctuation">,</span> mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span></code></pre><blockquote><ul><li><strong>数值稳定性</strong></li></ul><p>深度模型有关数值稳定性的典型问题是衰减（vanishing）和爆炸（explosion）。</p><p>当神经网络的层数较多时，模型的数值稳定性容易变差。假设一个层数为 $L$ 的多层感知机的第 $l$ 层 $\boldsymbol{H}^{(l)}$ 的权重参数为 $\boldsymbol{W}^{(l)}$，输出层 $\boldsymbol{H}^{(L)}$ 的权重参数为 $\boldsymbol{W}^{(L)}$。</p><p>为了便于讨论，不考虑偏差参数，且设所有隐藏层的激活函数为恒等映射 $\phi(x) = x$。</p><p>给定输入 $\boldsymbol{X}$，多层感知机的第 $l$ 层的输出 $\boldsymbol{H}^{(l)} = \boldsymbol{X} \boldsymbol{W}^{(1)} \boldsymbol{W}^{(2)} \ldots \boldsymbol{W}^{(l)}$。</p><p>此时，如果层数$l$较大，$\boldsymbol{H}^{(l)}$ 的计算可能会出现衰减或爆炸。</p><p>举个例子，假设输入和所有层的权重参数都是标量，如权重参数为 0.2 和 5，多层感知机的第 30 层输出为输入 $\boldsymbol{X}$ 分别与 $0.2^{30} \approx 1 \times 10^{-21}$（衰减）和 $5^{30} \approx 9 \times 10^{20}$（爆炸）的乘积。</p><p>类似地，当层数较多时，梯度的计算也更容易出现衰减或爆炸。</p><ul><li><strong>模型初始化</strong></li></ul><p>在神经网络中，通常需要随机初始化模型参数。下面我们来解释这样做的原因。</p><p>考虑多层感知机模型。如果将每个隐藏单元的参数都初始化为相等的值，那么在正向传播时每个隐藏单元将根据相同的输入计算出相同的值，并传递至输出层。</p><p>在反向传播中，每个隐藏单元的参数梯度值相等。因此，这些参数在使用基于梯度的优化算法迭代后值依然相等。</p><p>之后的迭代也是如此。在这种情况下，无论隐藏单元有多少，隐藏层本质上只有 1 个隐藏单元在发挥作用。</p><p>因此，正如在前面的实验中所做的那样，我们通常将神经网络的模型参数，特别是权重参数，进行随机初始化。</p><p>PyTorch 中 <code>nn.Module</code> 的模块参数都采取了较为合理的初始化策略。</p></blockquote><h2 id="深度学习计算"><a href="#深度学习计算" class="headerlink" title="深度学习计算"></a>深度学习计算</h2><h3 id="模型构造"><a href="#模型构造" class="headerlink" title="模型构造"></a>模型构造</h3><ul><li>可以通过继承<code>Module</code>类来构造模型，重载 <code>__init__</code> 函数和 <code>forward</code> 函数。</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 声明带有模型参数的层，这里声明了两个全连接层</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 调用 MLP 父类 Module 的构造函数来进行必要的初始化。这样在构造实例时还可以指定其他函数</span>        <span class="token comment"># 参数，如“模型参数的访问、初始化和共享”一节将介绍的模型参数 params</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MLP<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span> <span class="token comment"># 隐藏层</span>        self<span class="token punctuation">.</span>act <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>output <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment"># 输出层</span>    <span class="token comment"># 定义模型的前向计算，即如何根据输入 x 计算返回所需要的模型输出</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        a <span class="token operator">=</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>output<span class="token punctuation">(</span>a<span class="token punctuation">)</span></code></pre><ul><li><code>Sequential</code>、<code>ModuleList</code>、<code>ModuleDict</code>类都继承自<code>Module</code>类。</li></ul><p><strong><code>Sequential</code></strong></p><pre class="language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> MySequential<span class="token punctuation">(</span>        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>         <span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span></code></pre><p><strong><code>ModuleList</code></strong></p><pre class="language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># # 类似 List 的 append 操作</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 类似 List 的索引访问</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token comment"># net(torch.zeros(1, 784)) # 会报 NotImplementedError</span></code></pre><p><code>ModuleList</code>仅仅是一个储存各种模块的列表，这些模块之间没有联系也没有顺序（所以不用保证相邻层的输入输出维度匹配），而且没有实现 <code>forward</code> 功能需要自己实现，所以上面执行 <code>net(torch.zeros(1, 784))</code> 会报<code>NotImplementedError</code>；而 <code>Sequential</code> 内的模块需要按照顺序排列，要保证相邻层的输入输出大小相匹配，内部 <code>forward</code> 功能已经实现。此外，<code>ModuleList</code> 不同于一般的 Python 的 <code>list</code>，加入到 <code>ModuleList</code> 里面的所有模块的参数会被自动添加到整个网络中。</p><p><strong><code>ModuleDict</code></strong></p><p><code>ModuleDict</code> 接收一个子模块的字典作为输入, 然后也可以类似字典那样进行添加访问操作。</p><pre class="language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleDict<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>    <span class="token string">'linear'</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token string">'act'</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>net<span class="token punctuation">[</span><span class="token string">'output'</span><span class="token punctuation">]</span> <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span> <span class="token comment"># 添加</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token string">'linear'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 访问</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>output<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token comment"># net(torch.zeros(1, 784)) # 会报NotImplementedError</span></code></pre><p>和 <code>ModuleList</code> 一样，<code>ModuleDict</code> 实例仅仅是存放了一些模块的字典，并没有定义 <code>forward</code> 函数需要自己定义。同样，<code>ModuleDict</code> 也与Python的 <code>Dict</code> 有所不同，<code>ModuleDict</code> 里的所有模块的参数会被自动添加到整个网络中。</p><ul><li>与<code>Sequential</code>不同，<code>ModuleList</code>和<code>ModuleDict</code>并没有定义一个完整的网络，它们只是将不同的模块存放在一起，需要自己定义<code>forward</code>函数。</li><li>虽然<code>Sequential</code>等类可以使模型构造更加简单，但直接继承<code>Module</code>类可以极大地拓展模型构造的灵活性。</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FancyMLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>FancyMLP<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>rand_weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token comment"># 不可训练参数（常数参数）</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment"># 使用创建的常数参数，以及 nn.functional 中的 relu 函数和 mm 函数</span>        x <span class="token operator">=</span> nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>rand_weight<span class="token punctuation">.</span>data<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment"># 复用全连接层。等价于两个全连接层共享参数</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment"># 控制流，这里我们需要调用 item 函数来返回标量进行比较</span>        <span class="token keyword">while</span> x<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">:</span>            x <span class="token operator">/=</span> <span class="token number">2</span>        <span class="token keyword">if</span> x<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">0.8</span><span class="token punctuation">:</span>            x <span class="token operator">*=</span> <span class="token number">10</span>        <span class="token keyword">return</span> x<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><h3 id="模型参数的访问、初始化与共享"><a href="#模型参数的访问、初始化与共享" class="headerlink" title="模型参数的访问、初始化与共享"></a>模型参数的访问、初始化与共享</h3><p>本节用到的模型：</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> initnet <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># pytorch 已进行默认初始化</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>Y <span class="token operator">=</span> net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>Output<span class="token punctuation">:</span>Sequential<span class="token punctuation">(</span>  <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><ul><li><strong>访问模型参数</strong></li></ul><p>对于 <code>Sequential</code> 实例（派生自 <code>Module</code>）中含模型参数的层，我们可以通过 <code>Module</code> 类的 <code>parameters()</code> 或者 <code>named_parameters</code> 方法来访问所有参数（以迭代器的形式返回），后者除了返回参数 <code>Tensor</code> 外还会返回其名字。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&lt;</span><span class="token keyword">class</span> <span class="token string">'generator'</span><span class="token operator">></span><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> param<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token number">0.</span>weight torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token number">0.</span>bias torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token number">2.</span>weight torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token number">2.</span>bias torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p>接下来访问单层的参数。对于使用 <code>Sequential</code> 类构造的神经网络，我们可以通过方括号 <code>[]</code> 来访问网络的任一层。索引 0 表示隐藏层为 <code>Sequential</code> 实例最先添加的层。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> param<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>param<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>weight torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span><span class="token keyword">class</span> <span class="token string">'torch.nn.parameter.Parameter'</span><span class="token operator">></span>bias torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span><span class="token keyword">class</span> <span class="token string">'torch.nn.parameter.Parameter'</span><span class="token operator">></span></code></pre><p>返回的 <code>param</code> 的类型为 <code>torch.nn.parameter.Parameter</code>，其实这是 <code>Tensor</code> 的子类，和 <code>Tensor</code> 不同的是如果一个 <code>Tensor</code> 是 <code>Parameter</code>，那么它会自动被添加到模型的参数列表里。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>weight1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>weight2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>n <span class="token operator">=</span> MyModel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> n<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span>    Output<span class="token punctuation">:</span>weight1</code></pre><ul><li><strong>初始化模型参数</strong></li></ul><p>PyTorch 中 <code>nn.Module</code> 的模块参数都采取了较为合理的初始化策略，但我们经常需要使用其他方法来初始化权重。</p><p>PyTorch 的 <code>init</code> 模块里提供了多种预设的初始化方法。在下面的例子中，我们将权重参数初始化成均值为 0、标准差为 0.01 的正态分布随机数，并依然将偏差参数清零。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token string">'weight'</span> <span class="token keyword">in</span> name<span class="token punctuation">:</span>        init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>param<span class="token punctuation">,</span> mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> param<span class="token punctuation">.</span>data<span class="token punctuation">)</span>Output<span class="token punctuation">:</span><span class="token number">0.</span>weight tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0030</span><span class="token punctuation">,</span>  <span class="token number">0.0094</span><span class="token punctuation">,</span>  <span class="token number">0.0070</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0010</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.0001</span><span class="token punctuation">,</span>  <span class="token number">0.0039</span><span class="token punctuation">,</span>  <span class="token number">0.0105</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0126</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.0105</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0135</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0047</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0006</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token number">2.</span>weight tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0074</span><span class="token punctuation">,</span>  <span class="token number">0.0051</span><span class="token punctuation">,</span>  <span class="token number">0.0066</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p>下面使用常数来初始化权重参数。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token string">'bias'</span> <span class="token keyword">in</span> name<span class="token punctuation">:</span>        init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>param<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> param<span class="token punctuation">.</span>data<span class="token punctuation">)</span>Output<span class="token punctuation">:</span><span class="token number">0.</span>bias tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token number">2.</span>bias tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p>有时候我们需要的初始化方法并没有在 <code>init</code> 模块中提供。这时，可以实现一个初始化方法，从而能够像使用其他初始化方法那样使用它。</p><p>首先参考 normal_ 的实现：</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">normal_</span><span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> tensor<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>mean<span class="token punctuation">,</span> std<span class="token punctuation">)</span></code></pre><p>类似地，我们可以实现自定义的初始化方法：</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">init_weight_</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        tensor<span class="token punctuation">.</span>uniform_<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        tensor <span class="token operator">*=</span> <span class="token punctuation">(</span>tensor<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">>=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token string">'weight'</span> <span class="token keyword">in</span> name<span class="token punctuation">:</span>        init_weight_<span class="token punctuation">(</span>param<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> param<span class="token punctuation">.</span>data<span class="token punctuation">)</span></code></pre><p>此外，我们还可以通过直接改变这些参数的 <code>data</code> 来达到改写模型参数值的同时不会影响梯度的效果。</p><ul><li><strong>共享模型参数</strong></li></ul><p>在有些情况下，我们希望在多个层之间共享模型参数。</p><p>共享模型参数的方法: <code>Module</code> 类的 <code>forward</code> 函数里多次调用同一个层。</p><p>此外，如果我们传入 <code>Sequential</code> 的模块是同一个 <code>Module</code> 实例的话参数也是共享的。</p><pre class="language-python" data-language="python"><code class="language-python">linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>linear<span class="token punctuation">,</span> linear<span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>param<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> param<span class="token punctuation">.</span>data<span class="token punctuation">)</span>Output<span class="token punctuation">:</span>Sequential<span class="token punctuation">(</span>  <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token number">0.</span>weight tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 这里只输出了一次参数列表，证明二者共享</span></code></pre><p>因为模型参数里包含了梯度，所以在反向传播计算时，这些共享的参数的梯度是累加的。</p><h3 id="自定义-Layer"><a href="#自定义-Layer" class="headerlink" title="自定义 Layer"></a>自定义 Layer</h3><p>本节将介绍如何使用 <code>Module</code>来自定义层，从而可以被重复调用。</p><ul><li><strong>不含模型参数的自定义层</strong></li></ul><p>事实上，自定义层和自定义模型类似，因为我们可以直接把一个 Packed 的模型视为是一个 Layer。</p><p>举个例子，下面的 <code>CenteredLayer</code> 类通过继承 <code>Module</code> 类自定义了一个将输入减掉均值后输出的层，并将层的计算定义在了 <code>forward</code> 函数里。这个层里不含模型参数。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">class</span> <span class="token class-name">CenteredLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>CenteredLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> x <span class="token operator">-</span> x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>然后，我们就可以实例化这个 Layer，然后做 Forward Feeding.</p><pre class="language-python" data-language="python"><code class="language-python">layer <span class="token operator">=</span> CenteredLayer<span class="token punctuation">(</span><span class="token punctuation">)</span>layer<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">)</span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><ul><li><strong>含模型参数的自定义层</strong></li></ul><p>之前我们介绍了 <code>Parameter</code> 类其实是 <code>Tensor</code> 的子类，如果一个 <code>Tensor</code> 是 <code>Parameter</code>，那么它会自动被添加到模型的参数列表里。 // 在这里可以推测这个参数列表是 <code>nn.Module</code> 的数据成员…?</p><p>所以在自定义含模型参数的层时，我们应该将参数定义成 <code>Parameter</code>。</p><p>除了直接定义成 <code>Parameter</code> 类外，还可以使用 <code>ParameterList</code> 和 <code>ParameterDict</code> 分别定义参数的列表和字典。</p><ul><li><strong><code>ParameterList</code></strong></li></ul><p><code>ParameterList</code>接收一个 <code>Parameter</code> 实例的列表作为输入然后得到一个参数列表，使用的时候可以用索引来访问某个参数，另外也可以使用 <code>append</code> 和 <code>extend</code> 在列表后面新增参数。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyDense</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyDense<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>params <span class="token operator">=</span> nn<span class="token punctuation">.</span>ParameterList<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>params<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> xnet <span class="token operator">=</span> MyDense<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span></code></pre><p>Output:</p><pre class="language-none"><code class="language-none">MyDense(  (params): ParameterList(      (0): Parameter containing: [torch.FloatTensor of size 4x4]      (1): Parameter containing: [torch.FloatTensor of size 4x4]      (2): Parameter containing: [torch.FloatTensor of size 4x4]      (3): Parameter containing: [torch.FloatTensor of size 4x1]  ))</code></pre><ul><li><strong><code>ParameterDict</code></strong></li></ul><p><code>ParameterDict</code> 接收一个 <code>Parameter</code> 实例的字典作为输入然后得到一个参数字典，然后可以按照字典的规则使用了。</p><p>例如使用 <code>update()</code> 新增参数，使用 <code>keys()</code> 返回所有键值，使用 <code>items()</code> 返回所有键值对等等。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyDictDense</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MyDictDense<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>params <span class="token operator">=</span> nn<span class="token punctuation">.</span>ParameterDict<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>                <span class="token string">'linear1'</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token string">'linear2'</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>params<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">'linear3'</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span> <span class="token comment"># 新增</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> choice<span class="token operator">=</span><span class="token string">'linear1'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span>choice<span class="token punctuation">]</span><span class="token punctuation">)</span>net <span class="token operator">=</span> MyDictDense<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span></code></pre><p>Output:</p><pre class="language-none"><code class="language-none">MyDictDense(  (params): ParameterDict(      (linear1): Parameter containing: [torch.FloatTensor of size 4x4]      (linear2): Parameter containing: [torch.FloatTensor of size 4x1]      (linear3): Parameter containing: [torch.FloatTensor of size 4x2]  ))</code></pre><p>于是我们可以根据不同的 key 进行不同的 forward feeding.</p><pre class="language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token string">'linear1'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token string">'linear2'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token string">'linear3'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.5082</span><span class="token punctuation">,</span> <span class="token number">1.5574</span><span class="token punctuation">,</span> <span class="token number">2.1651</span><span class="token punctuation">,</span> <span class="token number">1.2409</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>MmBackward<span class="token operator">></span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8783</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>MmBackward<span class="token operator">></span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">2.2193</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.6539</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>MmBackward<span class="token operator">></span><span class="token punctuation">)</span></code></pre><h3 id="读取与存储"><a href="#读取与存储" class="headerlink" title="读取与存储"></a>读取与存储</h3><p>到目前为止，我们介绍了如何处理数据以及如何构建、训练和测试深度学习模型。</p><p>然而在实际中，我们有时需要把训练好的模型部署到很多不同的设备。</p><p>在这种情况下，我们可以把内存中训练好的模型参数存储在硬盘上供后续读取使用。</p><ul><li><strong>读写 <code>Tensor</code></strong></li></ul><p>我们可以直接使用 <code>save</code> 函数和 <code>load</code> 函数分别存储和读取 <code>Tensor</code>。</p><p><code>save</code> 使用 Python 的 pickle 库将对象进行序列化，然后将序列化的对象保存到硬盘。</p><p>使用 <code>save</code> 可以保存各种对象，包括 <code>nn.Module</code>, <code>Tensor</code>, <code>dict</code> 等等。</p><p>而 <code>load</code> 使用 unpickle 工具将 pickle 的对象文件反序列化为内存。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nnx <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token string">'x.pt'</span><span class="token punctuation">)</span>x2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'x.pt'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x2<span class="token punctuation">)</span> <span class="token comment"># tensor([1., 1., 1.])</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'xy.pt'</span><span class="token punctuation">)</span>xy_list <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'xy.pt'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>xy_list<span class="token punctuation">)</span> <span class="token comment"># [tensor([1., 1., 1.]), tensor([0., 0., 0., 0.])]</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">'x'</span><span class="token punctuation">:</span> x<span class="token punctuation">,</span> <span class="token string">'y'</span><span class="token punctuation">:</span> y<span class="token punctuation">&#125;</span><span class="token punctuation">,</span> <span class="token string">'xy_dict.pt'</span><span class="token punctuation">)</span>xy <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'xy_dict.pt'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>xy<span class="token punctuation">)</span> <span class="token comment"># &#123;'x': tensor([1., 1., 1.]), 'y': tensor([0., 0., 0., 0.])&#125;</span></code></pre><ul><li><strong>读写模型</strong></li></ul><p>PyTorch 中保存和加载训练模型有两种常见的方法:</p><ol><li>仅保存和加载模型参数(<code>state_dict</code>)；</li><li>保存和加载整个模型。</li></ol><p><strong>保存和加载模型的 <code>state_dict()</code> 成员（Recommended）</strong></p><p>保存：</p><pre class="language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span> <span class="token comment"># 推荐的文件后缀名是 pt 或 pth</span></code></pre><p>加载：</p><pre class="language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> TheModelClass<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="GPU-计算"><a href="#GPU-计算" class="headerlink" title="GPU 计算"></a>GPU 计算</h3><p>到目前为止，我们一直在使用 CPU 计算。</p><p>对复杂的神经网络和大规模的数据来说，使用 CPU 来计算可能不够高效。</p><p>在本节中，我们将介绍如何使用单块 NVIDIA GPU 来计算。</p><p>可以通过 <code>nvidia-smi</code> 命令来查看显卡信息。</p><pre class="language-none"><code class="language-none">Wed Jan 26 11:48:28 2022+-----------------------------------------------------------------------------+| NVIDIA-SMI 457.49       Driver Version: 457.49       CUDA Version: 11.1     ||-------------------------------+----------------------+----------------------+| GPU  Name            TCC&#x2F;WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage&#x2F;Cap|         Memory-Usage | GPU-Util  Compute M. ||                               |                      |               MIG M. ||&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;||   0  GeForce GTX 1650   WDDM  | 00000000:01:00.0 Off |                  N&#x2F;A || N&#x2F;A   43C    P8     4W &#x2F;  N&#x2F;A |    359MiB &#x2F;  4096MiB |      8%      Default ||                               |                      |                  N&#x2F;A |+-------------------------------+----------------------+----------------------+</code></pre><ul><li><strong>计算设备</strong></li></ul><p>PyTorch 可以指定用来存储和计算的设备，如使用内存的 CPU 或者使用显存的 GPU。</p><p>默认情况下，PyTorch 会将数据创建在内存，然后利用 CPU 来计算。</p><p>用 <code>torch.cuda.is_available()</code> 查看 GPU 是否可用:<br><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nntorch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 输出 True</span></code></pre></p><p>GPU 的相关信息查询：<br><pre class="language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 查看 GPU 数量，输出 1</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>current_device<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 查看当前 GPU 索引号，输出 0</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>get_device_name<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># 根据索引号查看 GPU 名字，输出 'GeForce GTX 1050'</span></code></pre></p><ul><li><strong><code>Tensor</code> 的 GPU 计算</strong></li></ul><p>默认情况下，<code>Tensor</code> 会被存在内存上。因此，之前我们每次打印 <code>Tensor</code> 的时候看不到 GPU 相关标识。<br><pre class="language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># tensor([1, 2, 3])</span></code></pre><br>使用 <code>.cuda()</code> 可以将CPU上的 <code>Tensor</code> 转换（复制）到GPU上。</p><p>如果有多块GPU，我们用 <code>.cuda(i)</code>来表示第 $i$ 块 GPU 及相应的显存（$i$ 从 0 开始）且 <code>cuda(0)</code> 和 <code>cuda()</code> 等价。</p><pre class="language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> x<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># tensor([1, 2, 3], device='cuda:0')</span></code></pre><p>可以通过 <code>Tensor</code> 的 <code>device</code> 属性来查看该 <code>Tensor</code> 所在的设备。<br><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># device(type='cuda', index=0)</span></code></pre><br>可以直接在创建的时候就指定设备。<br><pre class="language-python" data-language="python"><code class="language-python">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token comment"># or</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># tensor([1, 2, 3], device='cuda:0')</span></code></pre><br>如果对在 GPU 上的数据进行运算，那么结果还是存放在 GPU 上。<br><pre class="language-python" data-language="python"><code class="language-python">y <span class="token operator">=</span> x<span class="token operator">**</span><span class="token number">2</span><span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span> <span class="token comment"># tensor([1, 4, 9], device='cuda:0')</span></code></pre><br>需要注意的是，<strong>存储在不同位置中的数据是不可以直接进行计算的</strong>。即存放在 CPU 上的数据不可以直接与存放在 GPU 上的数据进行运算，位于不同 GPU 上的数据也是不能直接进行计算的。</p><ul><li><strong>模型的 GPU 计算</strong></li></ul><p>同 <code>Tensor</code> 类似，PyTorch 模型也可以用类似的方式转移到 GPU 上。</p><ul><li><code>.cuda(i)</code></li><li><code>.cpu()</code></li><li><code>.to(device)</code></li></ul><p>我们也可以通过检查模型的参数的 <code>device</code> 属性来查看存放模型的设备。</p><p>同样的，需要保证模型输入的 <code>Tensor</code> 和模型都在同一设备上，否则会报错。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://tangshusen.me/Dive-into-DL-PyTorch/img/cover.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;《动手学深度学习》原书地址：&lt;a href=&quot;https://github.com/d2l-ai/d2l-zh&quot;&gt;https://github.com/d2l-ai/d2l-zh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;《动手学深度学习》(Pytorch ver.)：&lt;a href=&quot;https://tangshusen.me/Dive-into-DL-PyTorch/#/&quot;&gt;https://tangshusen.me/Dive-into-DL-PyTorch/#/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;知识架构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tangshusen.me/Dive-into-DL-PyTorch/img/book-org.svg&quot; alt=&quot;封面&quot;&gt;&lt;/p&gt;
&lt;p&gt;本文的主要作用是在阅读过程中做一些摘录。对于「机器学习」领域， c7w 虽然曾尝试从各个领域入门，也尝试训过一些模型，但是还是缺少系统性、结构性的学习。希望阅读本书能带来更多的收获吧。&lt;/p&gt;
&lt;p&gt;与前面的一些笔记相比，本文更加侧重于「实践」。也就是说切实地提升自己的代码能力。&lt;/p&gt;
&lt;p&gt;Part A 包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;§ 1 深度学习简介&lt;/li&gt;
&lt;li&gt;§ 2 预备知识：Pytorch&lt;/li&gt;
&lt;li&gt;§ 3 深度学习基础&lt;ul&gt;
&lt;li&gt;线性回归，Softmax 回归，多层感知机三类基本模型&lt;/li&gt;
&lt;li&gt;权重衰减和 Dropout 两类应对过拟合的方法&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;§ 4 深度学习计算&lt;ul&gt;
&lt;li&gt;构造 Pytorch 模型的方式&lt;/li&gt;
&lt;li&gt;模型参数的访问、初始化与共享&lt;/li&gt;
&lt;li&gt;自定义 Layer&lt;/li&gt;
&lt;li&gt;读取与存储&lt;/li&gt;
&lt;li&gt;GPU 计算&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="理论" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/"/>
    
    <category term="理论/机器学习" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/%E7%90%86%E8%AE%BA-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://www.c7w.tech/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>GAMES101 PA 报告兼课程重点算法回顾</title>
    <link href="https://www.c7w.tech/games101-pa/"/>
    <id>https://www.c7w.tech/games101-pa/</id>
    <published>2022-01-18T13:19:54.000Z</published>
    <updated>2022-01-29T15:20:05.858Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2022/01/28/hIQTsycbV6xeojp.png" alt="output-4"></p><p><img src="https://s2.loli.net/2022/01/29/GZtErdMFQcBfN8P.png" alt="7-256"></p><p>GAMES101 2020-Spring 对应的 8 次 PA 整理。</p><p>仓库地址：<a href="https://github.com/c7w/GAMES101-HW-2020-Spring">https://github.com/c7w/GAMES101-HW-2020-Spring</a></p><p><em>　　Warning: FYI, these codes may be ugly and buggy.</em></p><a id="more"></a><h2 id="PA1"><a href="#PA1" class="headerlink" title="PA1"></a>PA1</h2><blockquote><p>本次作业的任务是填写一个<strong>旋转矩阵</strong>和一个<strong>透视投影矩阵</strong>。</p><p>给定三维下三个点 $v_0(2.0, 0.0, −2.0), v_1(0.0, 2.0, −2.0), v_2(−2.0, 0.0, −2.0)$​，你需要将这三个点的坐标变换为屏幕坐标并在屏幕上绘制出对应的线框三角形 (在代码框架中，我们已经提供了 draw_triangle 函数，所以你只需要去构建变换矩阵即可)。</p><p>简而言之，我们需要进行模型、视图、投影、视口等变换来将三角形显示在屏幕上。在提供的代码框架中，我们留下了模型变换和投影变换的部分给你去完成。</p></blockquote><h3 id="算法回顾"><a href="#算法回顾" class="headerlink" title="算法回顾"></a>算法回顾</h3><p>拍照的第一步是模型变换，也就是把模型放在合适的位置上。第二步是找好角度放相机（View Transformation），也就是视图变换。第三步是做投影变换，将照片定格。</p><ul><li>视图变换：定义 $M_{view}$ 变换相机，使得经过该变换满足 $\vec e = \vec 0, \hat g = -\hat z, \hat t = \hat y $，其中：$\vec e$ 为相机所在位置， $\hat g$ 为相机看的方向，$\hat t$ 为相机的向上方向。</li></ul><script type="math/tex; mode=display">M_{view} = R_{view}T_{view} \ (**)\\T_{view} = \begin{bmatrix} 1&0&0&-x_e\\0&1&0&-y_e\\0&0&1&-z_e\\0&0&0&1\end{bmatrix}\\R_{view}^{-1} = \begin{bmatrix} x_{\hat g \times \hat t}&x_{\hat t}&x_{-\hat g}&0\\y_{\hat g \times \hat t}&y_{\hat t}&y_{-\hat g}&0\\z_{\hat g \times \hat t}&z_{\hat t}&z_{-\hat g}&0\\0&0&0&1\end{bmatrix}\\R_{view} = (R_{view}^{-1})^T =\begin{bmatrix} x_{\hat g \times \hat t}&y_{\hat g \times \hat t}&z_{\hat g \times \hat t}&0\\x_{\hat t}&y_{\hat t}&z_{\hat t}&0\\x_{-\hat g}&y_{-\hat g}&z_{-\hat g}&0\\0&0&0&1\end{bmatrix}\\</script><p>我们要做的，是把所有物体都应用这个变换，保证相机与物体的相对位置不变。</p><ul><li>投影变换</li></ul><p><strong>首先将摄像机的视锥压成正方体 $M_{persp\rightarrow ortho}$​，然后进行正交投影 $M_{ortho}$​​。</strong></p><p>这里我们略去透视投影矩阵的推导，直接给出透视投影转换为正交投影矩阵的表示形式。具体的推导可以通过考虑以下特殊点，代入特殊值来决定矩阵的元素。</p><ul><li>近平面的坐标不改变</li><li>远平面的 $x,y$ 坐标被压缩至与近平面相同</li><li>近平面中心点与远平面中心点的位置不变</li></ul><script type="math/tex; mode=display">M_{persp\rightarrow ortho} = \begin{bmatrix}n & 0 & 0 & 0 \\0 & n & 0 & 0 \\0 & 0 & n+f & -nf \\0 & 0 & 1 & 0\end{bmatrix} \\\\</script><p>值得注意的是，在我们平常的应用中，我们并不是直接使用 $l, r, b,t$ 来描述一个近平面的位置，而是更倾向于使用 $fovY$​(<strong>field-of-view</strong>, 垂直视角) 和 <strong>aspect ratio</strong> 这两个量来描述一个近平面。</p><p>使用这两个量我们可以轻松地计算出 $l,r,b,t$ 四个近平面参数。</p><p><img src="https://i.loli.net/2021/11/06/NZbxWisdEH78plf.png" alt="image-20211106214646265"></p><p>然后我们使用正交投影映射到 $[-1, 1]^3$。</p><script type="math/tex; mode=display">M_{\text {ortho }}=\left[\begin{array}{cccc}\frac{2}{r-l} & 0 & 0 & 0 \\0 & \frac{2}{t-b} & 0 & 0 \\0 & 0 & \frac{2}{n-f} & 0 \\0 & 0 & 0 & 1\end{array}\right]\left[\begin{array}{cccc}1 & 0 & 0 & -\frac{r+l}{2} \\0 & 1 & 0 & -\frac{t+b}{2} \\0 & 0 & 1 & -\frac{n+f}{2} \\0 & 0 & 0 & 1\end{array}\right]</script><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="https://s2.loli.net/2022/01/28/ftcK5nhEdYaGwPp.png" alt="1"></p><h2 id="PA2"><a href="#PA2" class="headerlink" title="PA2"></a>PA2</h2><blockquote><p>任务如下：</p><ul><li><code>rasterize_triangle()</code>: 执行三角形栅格化算法</li><li><code>static bool insideTriangle()</code>: 测试点是否在三角形内</li><li>正确实现深度缓冲算法</li><li>Super-sampling</li></ul></blockquote><h3 id="算法回顾-1"><a href="#算法回顾-1" class="headerlink" title="算法回顾"></a>算法回顾</h3><ul><li>检测点在三角形内</li></ul><p>我们考虑如下的三个叉积。$\overrightarrow {P_0P_1} \times \overrightarrow {P_0Q}$, $\overrightarrow {P_1P_2} \times \overrightarrow {P_1Q}$, $\overrightarrow {P_2P_0} \times \overrightarrow {P_2Q}$ 如果 z 坐标的符号相同，那么点 Q 就一定在三角形内。但是，如果对屏幕的所有元素采样，造成了没有必要的资源浪费。我们使用<strong>包围盒</strong>（Bounding Box）的概念，取三角形边界点的 x, y 坐标分别的最小值或最大值，作为包围盒 x, y 坐标的最小值与最大值。这样我们就能得到一张带锯齿的图像了。</p><ul><li>Super-sampling</li></ul><p>而在我们具体解决问题的时候，我们选择 Supersampling 的方式，也就是将某个像素分为 $N\times N$​ 个采样点，然后对这些采样点的像素值取平均。</p><ul><li>深度缓冲</li></ul><p>为了解决这个问题，图形学引入了深度缓存的概念。想法就是对屏幕的所有像素额外记录其当前显示物体的最浅深度（深度取正值，表示距离相机的远近）。这样类似于动态规划的算法最终复杂度是 $O(n)$ 的。而且如果我们假设在同一深度处不会出现两个模型，那么不同模型的着色顺序对结果是没有影响的。</p><p><img src="https://i.loli.net/2021/11/10/vkn5R7zfhoNZTjC.png" alt="image-20211110140334554"></p><h3 id="实验结果-1"><a href="#实验结果-1" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="https://s2.loli.net/2022/01/28/ma6wt8dVnjGMTq4.png" alt="2-1"></p><p><img src="https://s2.loli.net/2022/01/28/GDWpa1w9JLNsXz6.png" alt="2-2"></p><h2 id="PA3"><a href="#PA3" class="headerlink" title="PA3"></a>PA3</h2><blockquote><p>任务：</p><ul><li>参数插值</li><li>Blinn-Phong 模型</li><li>Texture Mapping</li><li>Bump Mapping &amp; Displacement Mapping</li><li>尝试更多模型</li><li>双线性插值</li></ul></blockquote><h3 id="算法回顾-2"><a href="#算法回顾-2" class="headerlink" title="算法回顾"></a>算法回顾</h3><ul><li>重心坐标插值</li></ul><p>当我们知道了三角形的三个顶点的属性的时候，如果我们想要实现在三角形内部属性的平滑过渡，就要引入重心坐标的概念。对于一个三角形 ABC 来说，其中 $(x,y) = \alpha A + \beta B + \gamma C$，若 $\alpha + \beta + \gamma = 1$，则称 $(\alpha, \beta, \gamma)$ 为该三角形内的 $(x,y)$ 点的重心坐标，其中 $\alpha, \beta, \gamma \ge 0$。</p><p><img src="https://i.loli.net/2021/11/11/U4jEISXchwARgZV.png" alt="image-20211111231732485"></p><ul><li>BP</li></ul><script type="math/tex; mode=display">\begin{aligned}L &=L_{a}+L_{d}+L_{s} \\&=k_{a} I_{a}+k_{d}\left(I / r^{2}\right) \max (0, \mathbf{n} \cdot \mathbf{l})+k_{s}\left(I / r^{2}\right) \max (0, \mathbf{n} \cdot \mathbf{h})^{p}\end{aligned}</script><h3 id="实验结果-2"><a href="#实验结果-2" class="headerlink" title="实验结果"></a>实验结果</h3><ul><li>Normal</li></ul><p><img src="https://s2.loli.net/2022/01/28/K8ISoYs59h2wdPg.png" alt="output-2"></p><ul><li>BP</li></ul><p><img src="https://s2.loli.net/2022/01/28/oVBEDL2NuwRpkGO.png" alt="output-3"></p><ul><li>Texture</li></ul><p><img src="https://s2.loli.net/2022/01/28/hIQTsycbV6xeojp.png" alt="output-4"></p><ul><li>Bump Mapping &amp; Displacement Mapping</li></ul><p><img src="https://s2.loli.net/2022/01/28/HJiSMxQa4udzjPF.png" alt="output-5"></p><p><img src="https://s2.loli.net/2022/01/28/vXV89tQPTSUpDeA.png" alt="output-6"></p><ul><li>Bunny</li></ul><p><img src="https://s2.loli.net/2022/01/28/ERkHN7PlVSQF4qm.png" alt="bunny"></p><ul><li>双线性插值前/后 (Shrink texture.png by 50%)</li></ul><p><img src="https://s2.loli.net/2022/01/28/fm9AjRGu2rngCLw.png" alt="output-small"></p><p><img src="https://s2.loli.net/2022/01/28/I5jeWBENHgndFtC.png" alt="output-small2"></p><h3 id="实验框架"><a href="#实验框架" class="headerlink" title="实验框架"></a>实验框架</h3><ul><li><code>main.cpp</code><ul><li><code>Eigen::Matrix4f get_view_matrix(Eigen::Vector3f eye_pos)</code></li><li><code>Eigen::Matrix4f get_model_matrix(float angle)</code></li><li><code>Eigen::Matrix4f get_projection_matrix(float eye_fov, float aspect_ratio, float zNear, float zFar)</code></li><li><code>struct Light &#123;Eigen::Vector3f position; Eigen::Vector3f intensity;&#125;;</code></li><li>Shaders<ul><li><code>Eigen::Vector3f texture_fragment_shader(const fragment_shader_payload&amp; payload)</code></li><li><code>Eigen::Vector3f phong_fragment_shader(const fragment_shader_payload&amp; payload)</code><ul><li>定义 $k_d, k_s, k_a, lights, amb_light, eye_pos$​</li><li>返回 $result_color * 255.0$</li></ul></li><li><code>Eigen::Vector3f displacement_fragment_shader(const fragment_shader_payload&amp; payload)</code></li><li><code>Eigen::Vector3f bump_fragment_shader(const fragment_shader_payload&amp; payload)</code></li></ul></li><li><code>int main()</code><ul><li>读取模型，然后将模型中的各个面建立 Triangle 对象</li><li>建立 Rasterizer 类对象，设置材质</li><li>调用渲染函数，然后使用 OpenCV 库保存渲染结果</li></ul></li></ul></li><li><code>OBJ_Loader.h</code>：加载模型用</li><li><p><code>Rasterizer.hpp/Rasterizer.cpp</code></p><ul><li>其中的 rasterizer 子类内包括了一些必备的结构和函数</li><li><code>std::vector&lt;Eigen::Vector3f&gt; frame_buf;</code></li><li><code>std::vector&lt;float&gt; depth_buf;</code></li></ul></li><li><p><code>Texture.hpp/Texture.cpp</code></p><ul><li><code>cv::Mat image_data;</code> // Raw data</li><li><code>int width, height;</code></li><li><code>Vector3f getColor(float u, float v);</code></li></ul></li><li><code>Triangle.hpp/Triangle.cpp</code><ul><li><code>Vector4f v[3];</code> // Original coordinates of the triangle</li><li><code>Vector3f color[3]; Vector2f tex_coords[3]; Vector3f normal[3];</code> // Color, texture_coord, normal vector for each vertex</li></ul></li></ul><h2 id="PA4"><a href="#PA4" class="headerlink" title="PA4"></a>PA4</h2><blockquote><p>使用 <strong>De Casteljau 算法</strong> 生成贝塞尔曲线。</p></blockquote><h3 id="算法回顾-3"><a href="#算法回顾-3" class="headerlink" title="算法回顾"></a>算法回顾</h3><p>（1）先考虑三个控制点，生成二次贝塞尔曲线。</p><p><img src="https://i.loli.net/2021/12/01/fE6FrtaL2sDQIGT.png" alt="image-20211201194418429"></p><p>（2）再考虑四个控制点，生成三次贝塞尔曲线。</p><p><img src="https://i.loli.net/2021/12/01/wR7VDnSPCrLxkKY.png" alt="image-20211201194528603"></p><p>(3) 代数形式：插值！</p><p><img src="https://i.loli.net/2021/12/01/pmW5vVa61urdbxI.png" alt="image-20211201194639946"></p><p>给定 $n+1$ 个控制点，有贝塞尔曲线如下：</p><script type="math/tex; mode=display">b^n(t) = b^n_0(t) = \sum_{j=0}^nb_jB_j^n(t) \\B_{i}^{n}(t)=\left(\begin{array}{l}n\\i\end{array}\right) t^{i}(1-t)^{n-i}</script><h3 id="实验结果-3"><a href="#实验结果-3" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="https://s2.loli.net/2022/01/29/kHpBU6wfgcvxi7W.png" alt="4"></p><h2 id="PA5"><a href="#PA5" class="headerlink" title="PA5"></a>PA5</h2><blockquote><p>在光线追踪中，最重要的操作之一就是找到光线与物体的交点。</p><p>一旦找到光线与物体的交点，就可以执行着色并返回像素颜色。</p><p>在这次作业中，我们需要实现两个部分：光线的生成和光线与三角的相交。</p><p>具体来说，我们需要修改：</p><ul><li><code>Renderer.cpp</code> 中的 <code>Render()</code>：这里你需要为每个像素生成一条对应的光线，然后调用函数 <code>castRay()</code> 来得到颜色，最后将颜色存储在帧缓冲区的相应像素中。</li><li><code>Triangle.hpp</code> 中的 <code>rayTriangleIntersect()</code>: v0, v1, v2 是三角形的三个顶点，orig 是光线的起点，dir 是光线单位化的方向向量。tnear, u, v 是你需要使用我们课上推导的 Moller-Trumbore 算法来更新的参数。</li></ul></blockquote><h3 id="算法回顾-4"><a href="#算法回顾-4" class="headerlink" title="算法回顾"></a>算法回顾</h3><ul><li>Whitted-style Ray Tracing</li></ul><p><img src="https://s2.loli.net/2022/01/14/T1xAeVvrhOoGJK4.png" alt="image-20220114155905503"></p><ul><li>Möller Trumbore 算法</li></ul><p>Möller Trumbore 算法，可以直接判断交点是否在三角形内（需要用到克莱姆法则）：</p><script type="math/tex; mode=display">\begin{gathered}\overrightarrow{\mathbf{O}}+t \overrightarrow{\mathbf{D}}=\left(1-b_{1}-b_{2}\right) \overrightarrow{\mathbf{P}}_{0}+b_{1} \overrightarrow{\mathbf{P}}_{1}+b_{2} \overrightarrow{\mathbf{P}}_{2} \\\text { Where: } \\{\left[\begin{array}{c}t \\b_{1} \\b_{2}\end{array}\right]=\frac{1}{\overrightarrow{\mathbf{S}}_{1} \bullet \overrightarrow{\mathbf{E}}_{1}}\left[\begin{array}{cc}\overrightarrow{\mathbf{S}}_{2} \cdot \overrightarrow{\mathbf{E}}_{2} \\\overrightarrow{\mathbf{S}}_{1} \cdot \overrightarrow{\mathbf{S}} \\\overrightarrow{\mathbf{S}}_{2} \cdot \overrightarrow{\mathbf{D}}\end{array}\right]} \\\text { Cost = (1 div, 27 mul, 17 add) } \\\overrightarrow{\mathbf{E}}_{1}=\overrightarrow{\mathbf{P}}_{1}-\overrightarrow{\mathbf{P}}_{0} \\\overrightarrow{\mathbf{E}}_{2}=\overrightarrow{\mathbf{P}}_{2}-\overrightarrow{\mathbf{P}}_{0} \\\overrightarrow{\mathbf{S}}=\overrightarrow{\mathbf{O}}-\overrightarrow{\mathbf{P}}_{0} \\\overrightarrow{\mathbf{S}}_{1}=\overrightarrow{\mathbf{D}} \times \overrightarrow{\mathbf{E}}_{2} \\\overrightarrow{\mathbf{S}}_{2}=\overrightarrow{\mathbf{S}} \times \overrightarrow{\mathbf{E}}_{1}\end{gathered}</script><h3 id="实验结果-4"><a href="#实验结果-4" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="https://s2.loli.net/2022/01/29/ZeSLqlF65o7vfD8.png" alt="5"></p><h2 id="PA6"><a href="#PA6" class="headerlink" title="PA6"></a>PA6</h2><blockquote><p>在之前的编程练习中，我们实现了基础的光线追踪算法，具体而言是光线传输、光线与三角形求交。</p><p>我们采用了这样的方法寻找光线与场景的交点：<strong>遍历场景中的所有物体，判断光线是否与它相交。</strong></p><p>在场景中的物体数量不大时，该做法可以取得良好的结果，但当物体数量增多、模型变得更加复杂，该做法将会变得非常低效。</p><p>因此，我们需要加速结构来加速求交过程。</p><p>在本次练习中，我们重点关注：<strong>物体划分算法 Bounding Volume Hierarchy (BVH)</strong>。</p><p>本练习要求你实现 Ray-Bounding Volume 求交与 BVH 查找，附加内容为使用 <strong>SAH 加速</strong>算法对 BVH 查找进行改进。</p></blockquote><h3 id="算法回顾-5"><a href="#算法回顾-5" class="headerlink" title="算法回顾"></a>算法回顾</h3><h4 id="包围盒求交"><a href="#包围盒求交" class="headerlink" title="包围盒求交"></a>包围盒求交</h4><p>我们将（包围盒）长方体理解成三个对面所分划出的空间的交集。我们一般使用的包围体积便是长方体，且长方体是与坐标轴平行的，即轴对齐包围盒（AABB）。选用 AABB 式包围盒有利于加速计算。判断光线和 AABB 类包围盒的求交方法如下：</p><p><img src="https://s2.loli.net/2022/01/14/5rMlAnIw3gQBVNL.png" alt="image-20220114163501816"></p><p>核心思想：只有当光线进入所有三个对面后，光线才进入了包围盒；若光线从某一个对面出射，则光线便从包围盒中射出。于是我们可以计算三个对面分别对应的 $t_{min}$​​ 和 $t_{max}$​​，然后对其求交。当且仅当 $t_{enter} \lt t_{exit}$​​ 且 $t_{exit} \ge 0$​​，光线才可能与包围盒有交点。</p><h4 id="BVH"><a href="#BVH" class="headerlink" title="BVH"></a>BVH</h4><p>通过对含有物体的向量沿轴划分建立二叉树，并且对于二叉树的每一个结点建立其包围盒。</p><p><img src="https://s2.loli.net/2022/01/16/zbLpGw5E7SCgQAu.png" alt="image-20220116102930688"></p><p>如何进行划分？</p><ul><li>沿着最长的维度来划分</li><li>划分端点取中位数<ul><li>取三角形的重心</li></ul></li></ul><p><img src="https://s2.loli.net/2022/01/16/xtKaWO7lJ2Rm8Xb.png" alt="image-20220116103520101"></p><p>使用 BVH 算法，即使包围盒可能在空间上有相交，但是我们却解决了 kd-Tree 存在的问题。</p><h4 id="SAH-加速"><a href="#SAH-加速" class="headerlink" title="SAH 加速"></a>SAH 加速</h4><p>（BVH）构建过程中最重要的问题就是如何对图元进行划分…划分时要<strong>尽可能减少划分后两部分包围盒重叠的体积</strong>，因为<strong>重叠的体积越大，光线穿过重叠区域的可能性越大，遍历两个子树的可能性就越高，计算消耗越多</strong>。</p><p>因为我们最终的目的是要减少划分后左右子节点重叠的体积，因此一般<strong>在图元跨度最大的坐标轴上进行划分</strong>。这里，图元的跨度可以用图元的包围盒来衡量也可以用图元的质心来衡量。</p><p>两种最简单的划分方法是：</p><ul><li>取坐标轴跨度的中点 $t_{\operatorname{mid}}=\frac{t_{\max }+t_{\min }}{2}$​ ，若节点的坐标小于 $t_{mid}$ 则将其划分到左节点，否则将其划分到右节点（中点划分）。</li><li>最左边的 $\frac n 2$​ 个被划分到左节点，剩下的被划分到右节点（等量划分）。 // 作业框架中 Naive 的划分由此实现</li></ul><p>一种更为常用且效果更好的方法是<strong>基于表面积的启发式评估划分方法</strong>（Surface Area Heuristic，SAH），这种方法通过对求交代价和遍历代价进行评估，给出了每一种划分的代价（Cost），而我们的目的便是去寻找代价最小的划分。</p><p>假设当前节点的包围体中存在 $n$​ 个物体，设对每一个物体求交的代价为 $t(i)$​​ ，如果不做划分依次对其求交则总的代价为：</p><script type="math/tex; mode=display">\sum t(i)=t(1)+t(2)+\cdots+t(n)</script><p>如果这些物体划分为 2 组，这两组物体分别处于它们的包围盒 A 和 B 中。设光线击中它们的概率分别为 $p_A$​​​​​​​ 和 $p_B$​​​​​​ ，需要注意包围盒 A 和 B 之间存在重叠，且它们并不一定会填满其父节点的包围体，因此 $p_A$​​​ 和 $p_B$​​ 的和不一定为1，且它们的和越大说明 A 和 B 的重叠程度越大。综上所述，当前节点求交的代价可以写为：</p><script type="math/tex; mode=display">c(A,B) = p_A \sum_{i \in A}t(i) + p_B \sum_{i \in B}t(i) + t_{traverse}</script><p>其中 $t_{traverse}$​​​ 代表遍历树状结构的代价。一般来说，我们假设对所有图元的求交代价是相同的，可设 $t(i) \equiv 1$​​​，又遍历的代价小于求交的代价，可设 $t_{traverse} = 0.125$​​ 。设包围盒A中图元的个数为 $a$​，B中图元的个数为 $b$，则：</p><script type="math/tex; mode=display">c(A,B) = \frac {S(A)} {S(C)}a + \frac {S(B)} {S(C)}b + 0.125</script><p>SAH 考虑到了图元在空间中的分布也考虑到了子节点包围体的重叠程度，在实际应用中拥有很好的效果。</p><p>然后我们就可以借助一定的辅助空间，在 $O(n)$​ 的时间内完成这个划分过程。这里我们<s>偷懒</s>采用一种 $O(n \log n)$ 的分划方式：</p><ul><li>将物体按照质心顺序排序. $O(n \log n)$</li><li>$\forall k$​，记录 $a_i := \cup_{i \le k} \ S(i)$​. $O(n)$​​</li><li>$\forall k$​，记录 $b_i := \cup_{i \gt k} \ S(i)$​. $O(n)$​</li><li>$\forall k$​，考虑划分 $[0, k] \ || \ [k+1, n)$​，计算其代价并更新最小代价. $O(n)$​</li></ul><p>参考资料：<a href="https://zhuanlan.zhihu.com/p/50720158">https://zhuanlan.zhihu.com/p/50720158</a></p><h3 id="实验结果-5"><a href="#实验结果-5" class="headerlink" title="实验结果"></a>实验结果</h3><p>采用 SAH 加速前，进行 RT 用时 8 min 35 secs；使用 SAH 加速后，用时为 8 min 48 secs。</p><p>// Warning: this code may be buggy!</p><p>// 没错用了这 ** 优化又慢了我也不知道x</p><p>// 我感觉包围盒算法就需要大改，anyway 领会精神吧x</p><p><img src="https://s2.loli.net/2022/01/18/Y9Nh7QAUxfncCgV.png" alt="6-1"></p><h3 id="实验框架-1"><a href="#实验框架-1" class="headerlink" title="实验框架"></a>实验框架</h3><ul><li><code>main.cpp</code><ul><li>创建场景（1280x960）与预处理<ul><li>导入模型为 MeshTriangle 类对象，并添加入场景；</li><li>将光源添加入场景；</li><li>对场景执行 buildBVH()</li></ul></li><li>创建 <code>Renderer</code> 类对象渲染器，并开始渲染</li></ul></li><li><code>Vector.hpp, Vector.cpp</code>：向量类，提供了向量 <code>Vector3f</code>, <code>Vector2f</code> 的基本操作</li><li><code>Object.hpp</code>：抽象类<ul><li>提供了以下接口：<ul><li><code>bool intersect(const Ray&amp;)</code></li><li><code>bool intersect(const Ray&amp; ray, float&amp; distance, int&amp; index) const</code></li><li><code>Intersection getIntersection(Ray _ray)</code></li><li><code>void getSurfaceProperties(const Vector3f &amp;, const Vector3f &amp;, const uint32_t &amp;, const Vector2f &amp;, Vector3f &amp;, Vector2f &amp;) const</code></li><li><code>virtual Vector3f evalDiffuseColor(const Vector2f &amp;) const</code></li><li><code>virtual Bounds3 getBounds()</code></li></ul></li><li>总结来说，首先是判断有无交点和获取交点的接口，然后是获取表面属性和计算颜色的接口，然后是获取包围盒的接口。</li><li><code>Triangle.hpp/Sphere.hpp</code>：继承自 <code>Object</code>，重载上述函数并实现为对应对象</li></ul></li><li><code>Ray.hpp</code><ul><li><code>Vector3f orig, direction;</code>, <code>double t, t_min, t_max;</code></li></ul></li><li><code>Light.hpp</code>：<code>Vector3f position, intensity;</code><ul><li><code>AreaLight.hpp</code>：<code>Vector3f u, v, normal; double length;</code></li></ul></li><li><code>Intersection.hpp</code>：<ul><li><code>bool happened;</code></li><li><code>Vector3f coords, normal;</code></li><li><code>double distance;</code></li><li><code>Object* obj;</code></li><li><code>Material* m;</code></li></ul></li><li><code>Material.hpp</code>：存储表面属性<ul><li>表面类型： <code>enum MaterialType &#123; DIFFUSE_AND_GLOSSY, REFLECTION_AND_REFRACTION, REFLECTION &#125;;</code></li><li>表面颜色（反射，辐射），折射率，BP 模型中的 $k_d, k_s, p$​</li></ul></li><li><code>Bounds3.hpp</code>：包围盒相关函数<ul><li>求对角线，维数，表面积，中心点；</li><li>与另外一个包围盒求交，求并；</li><li>检测两个包围盒是否互相包含或者重叠；</li><li>判断与光线是否相交；</li></ul></li><li><code>BVH.hpp/BVH.cpp</code>：加速结构<ul><li><code>enum class SplitMethod &#123; NAIVE, SAH &#125;;</code></li><li>与光线求交<ul><li><code>Intersection Intersect(const Ray &amp;ray) const;</code></li><li><code>Intersection getIntersection(BVHBuildNode* node, const Ray&amp; ray)const;</code></li><li><code>bool IntersectP(const Ray &amp;ray) const;</code></li></ul></li><li>本质是一颗二叉树，拥有树形结构<ul><li><code>BVHBuildNode* root;</code></li><li><code>BVHBuildNode* recursiveBuild(std::vector&lt;Object*&gt;objects);</code></li><li><code>BVHBuildNode* recursiveBuildSAH(std::vector&lt;Object*&gt;objects);</code></li></ul></li><li>存储其图元 primitive 的指针<ul><li><code>std::vector&lt;Object*&gt; primitives;</code></li></ul></li></ul></li><li><code>Renderer.hpp / Renderer.cpp</code><ul><li>给定一个场景，创建渲染任务</li><li>管理任务过程中的 framebuffer 等等图像数据</li><li>管理整个渲染流程以及数据最终的写入文件</li></ul></li><li><code>Scene.hpp / Scene.cpp</code><ul><li>图像相关的设定<ul><li><code>int width, height;</code></li><li><code>double fov;</code></li><li><code>Vector3f backgroundColor;</code></li><li><code>maxDepth;</code></li></ul></li><li>模型相关的设定 Get / Set<ul><li><code>void Add(Object *object);</code></li><li><code>void Add(std::unique_ptr&lt;Light&gt; light);</code></li></ul></li><li>与光线求交的函数：<code>Intersection intersect(const Ray&amp; ray) const;</code></li><li>BVH 相关：<ul><li><code>BVHAccel *bvh = nullptr;</code></li><li><code>void buildBVH();</code></li></ul></li><li>渲染主函数：<ul><li><code>Vector3f castRay(const Ray &amp;ray, int depth) const;</code> // Important!</li><li><code>bool trace(const Ray &amp;ray, const std::vector&lt;Object*&gt; &amp;objects, float &amp;tNear, uint32_t &amp;index, Object **hitObject);</code></li></ul></li></ul></li></ul><h2 id="PA7"><a href="#PA7" class="headerlink" title="PA7"></a>PA7</h2><blockquote><ul><li>实现 Path Tracing 算法</li></ul></blockquote><h3 id="算法回顾-6"><a href="#算法回顾-6" class="headerlink" title="算法回顾"></a>算法回顾</h3><pre class="language-none"><code class="language-none">def ray_generation(camPos, pixel):Uniformly choose N samples from the pixelpixel_radiance &#x3D; 0.0for sample in the pixel:Shoot a ray r(camPos, cam_to_sample)if ray r hit the scene at p:pixel_radiance +&#x3D; 1 &#x2F; N * shade(p, sample_to_cam)    return pixel_radiancedef shade(p, wo):# Contributions from the light sourceL_dir &#x3D; 0.0Uniformly sample the light at x&#39; (pdf_light &#x3D; 1&#x2F;A)Shoot a ray from p to x&#39;if the ray is not blocked in the middle:L_dir &#x3D; L_i * f_r * cos \theta * cos \theta&#39; &#x2F; |x&#39;-p|^2 &#x2F; pdf_light        # Contributions from other places    L_indir &#x3D; 0.0    If test Russian Roulette with probability P_RR :        Uniformly sample the hemisphere toward wi (pdf_hemi &#x3D; 1 &#x2F; 2pi)        Trace a ray r(p, wi)        If ray r hit a non-emitting object at q:            L_indir &#x3D; shade(q, -wi) * f_r * cos \theta &#x2F; pdf_hemi &#x2F; P_RR        Return L_dir + L_indir</code></pre><h3 id="实验结果-6"><a href="#实验结果-6" class="headerlink" title="实验结果"></a>实验结果</h3><ul><li>SPP = 16 / 32 / 64 / 256</li></ul><p><img src="https://s2.loli.net/2022/01/29/pwevmYcRyDqBPxh.png" alt="7-16"></p><p><img src="https://s2.loli.net/2022/01/29/1OrJUsgTSLocbwK.png" alt="7-32"></p><p><img src="https://s2.loli.net/2022/01/29/7aCgFk6KOdqS4bM.png" alt="7-64"></p><p><img src="https://s2.loli.net/2022/01/29/GZtErdMFQcBfN8P.png" alt="7-256"></p><h2 id="PA8"><a href="#PA8" class="headerlink" title="PA8"></a>PA8</h2><blockquote><ul><li>连接绳子约束，正确的构造绳子 </li><li>半隐式欧拉法</li><li>显式欧拉法</li><li>显式 Verlet</li><li>阻尼</li></ul></blockquote><h3 id="算法回顾-7"><a href="#算法回顾-7" class="headerlink" title="算法回顾"></a>算法回顾</h3><ul><li>显式/半隐式欧拉法</li></ul><script type="math/tex; mode=display">\boldsymbol{f}_{a \rightarrow b}=k_{s} \frac{\boldsymbol{b}-\boldsymbol{a}}{\|\boldsymbol{b}-\boldsymbol{a}\|}(\|\boldsymbol{b}-\boldsymbol{a}\|-l) \\f_{b \rightarrow a} = - f_{ a \rightarrow b}</script><script type="math/tex; mode=display">\begin{aligned}&\mathrm{F}=\mathrm{ma} \\&\mathrm{v}(\mathrm{t}+1)=\mathrm{v}(\mathrm{t})+\mathrm{a}(\mathrm{t}) * \mathrm{dt} \\&\mathrm{x}(\mathrm{t}+1)=\mathrm{x}(\mathrm{t})+\mathrm{v}(\mathrm{t}) * \mathrm{dt} \\&\mathrm{x}(\mathrm{t}+1)=\mathrm{x}(\mathrm{t})+\mathrm{v}(\mathrm{t}+1) * \mathrm{dt}\end{aligned}</script><p>倒数第二行为显式欧拉法，最后一行为半隐式欧拉法。</p><ul><li>显式 Verlet</li></ul><script type="math/tex; mode=display">x(t+1)=x(t)+[x(t)-x(t-1)]+a(t) * d t * d t</script><ul><li>阻尼</li></ul><script type="math/tex; mode=display">x(t+1) =x(t)+(1-\text {damping\_factor }) *[x(t)-x(t-1)]+a(t) * d t * d t</script>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2022/01/28/hIQTsycbV6xeojp.png&quot; alt=&quot;output-4&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2022/01/29/GZtErdMFQcBfN8P.png&quot; alt=&quot;7-256&quot;&gt;&lt;/p&gt;
&lt;p&gt;GAMES101 2020-Spring 对应的 8 次 PA 整理。&lt;/p&gt;
&lt;p&gt;仓库地址：&lt;a href=&quot;https://github.com/c7w/GAMES101-HW-2020-Spring&quot;&gt;https://github.com/c7w/GAMES101-HW-2020-Spring&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;　　Warning: FYI, these codes may be ugly and buggy.&lt;/em&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="理论" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/"/>
    
    <category term="理论/计算机图形学" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/%E7%90%86%E8%AE%BA-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="图形学" scheme="https://www.c7w.tech/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>GAMES101 现代计算机图形学基础 笔记（下）</title>
    <link href="https://www.c7w.tech/games101-cont/"/>
    <id>https://www.c7w.tech/games101-cont/</id>
    <published>2022-01-16T14:27:32.000Z</published>
    <updated>2022-01-29T10:43:40.391Z</updated>
    
    <content type="html"><![CDATA[<p>GAMES 101 现代计算机图形学基础 笔记（下篇）.</p><ul><li>光线追踪（Whitted-style，求交算法，加速结构，辐射度量学，路径追踪）</li><li>材质与外观</li><li>动画与模拟</li></ul><a id="more"></a><h2 id="光线追踪-Ray-Tracing"><a href="#光线追踪-Ray-Tracing" class="headerlink" title="光线追踪 Ray Tracing"></a>光线追踪 Ray Tracing</h2><h3 id="从问题出发"><a href="#从问题出发" class="headerlink" title="从问题出发"></a>从问题出发</h3><p>如何用光栅化的手法解决阴影的问题？</p><p>重要思想：点不在阴影中，当且仅当点必须同时被光源和摄像机看到。</p><ol><li>从光源看向场景（用 Z-buffer’ 记录深度）</li><li>从摄像机看向场景</li><li>如果两深度相同，则无需阴影；若两深度不同，则在阴影中。</li></ol><p>这样做存在的问题：</p><ul><li>Hard shadows（阴影被 0/1 化，无法表示阴影的程度）</li></ul><p>提出光线追踪，就是为了解决光线追踪无法很好地处理<strong>全局效果</strong>的问题。</p><ul><li>Soft Shadows</li><li>Glossy reflection</li><li>Indirect illumination (光线会弹射不止一次)</li></ul><p>光线追踪生成的图片质量很高，但是是离线的算法，运作速度也很慢。</p><h3 id="基础算法"><a href="#基础算法" class="headerlink" title="基础算法"></a>基础算法</h3><h4 id="相关定义"><a href="#相关定义" class="headerlink" title="相关定义"></a>相关定义</h4><ul><li><p>光线</p><ul><li>光线沿直线传播</li><li>光线和光线并不会发生碰撞</li><li>光线总是从光源发出，终止于人的眼睛（我们需要模拟的就是这个过程）<ul><li>根据光路的可逆性，我们可以假设“感知光线”从人眼出发…</li></ul></li></ul></li><li><p>光线投射</p></li></ul><p><img src="https://s2.loli.net/2022/01/14/wJAXG9b1VIEuSLt.png" alt="image-20220114154759095"></p><p>对于我们眼前的成像平面的每一个像素点，从人眼发出一条“感知光线”经过这个像素点，可能会触碰到场景中的某个位置。如果该位置和光源的连线上无其它物体的遮挡，那么我们就可以直接对其进行着色计算。</p><p><img src="https://s2.loli.net/2022/01/14/wCFDdpmHioMkrEL.png" alt="image-20220114155221509"></p><h4 id="Whitted-style-Ray-Tracing"><a href="#Whitted-style-Ray-Tracing" class="headerlink" title="Whitted-style Ray Tracing"></a>Whitted-style Ray Tracing</h4><p><img src="https://s2.loli.net/2022/01/14/T1xAeVvrhOoGJK4.png" alt="image-20220114155905503"></p><p>思路：模拟光线不断弹射的过程，并记录光线在每一个弹射点的衰减率。如上图中，对于玻璃球，需要模拟其反射和折射光路。具体的技术实现见下。</p><h4 id="光线和物体表面交点的求法"><a href="#光线和物体表面交点的求法" class="headerlink" title="光线和物体表面交点的求法"></a>光线和物体表面交点的求法</h4><ul><li>对于隐式表面</li></ul><p>光线的定义：原点 $\vec o$​​，传播方向 $\vec d \ (||\vec d||=1)$​​​，光线定义为 $\vec r(t) = \vec o +t\vec d, \ t\ge0$​​。</p><p>球的定义：$\vec p: (\vec p - \vec c)^2 - R^2 = 0$.</p><script type="math/tex; mode=display">\begin{aligned}&(\mathbf{o}+t \mathbf{d}-\mathbf{c})^{2}-R^{2}=0 \\&a t^{2}+b t+c=0, \text { where } \\&a=\mathbf{d} \cdot \mathbf{d} \\&b=2(\mathbf{o}-\mathbf{c}) \cdot \mathbf{d} \\&c=(\mathbf{o}-\mathbf{c}) \cdot(\mathbf{o}-\mathbf{c})-R^{2} \\&t=\frac{-b \pm \sqrt{b^{2}-4 a c}}{2 a}\end{aligned}</script><ul><li>对于显式表面</li></ul><p>一个简单的想法是对模型的所有三角形表面做遍历，然后选择 $t$ 最小的那个。（可能不存在，可以优化*）</p><p>于是，接下来我们仅考虑光线如何与单个三角形求交。</p><p>定义平面为 $(p-p’) \cdot N = 0$.</p><script type="math/tex; mode=display">\begin{aligned}&\left(\mathbf{p}-\mathbf{p}^{\prime}\right) \cdot \mathbf{N}=\left(\mathbf{o}+t \mathbf{d}-\mathbf{p}^{\prime}\right) \cdot \mathbf{N}=0 \\&t=\frac{\left(\mathbf{p}^{\prime}-\mathbf{o}\right) \cdot \mathbf{N}}{\mathbf{d} \cdot \mathbf{N}} \quad \text { Check: } 0 \leq t<\infty\end{aligned}</script><p>然后判断交点是否在三角形内。</p><p>此外还有 Möller Trumbore 算法，可以直接判断交点是否在三角形内（需要用到克莱姆法则）：</p><script type="math/tex; mode=display">\begin{gathered}\overrightarrow{\mathbf{O}}+t \overrightarrow{\mathbf{D}}=\left(1-b_{1}-b_{2}\right) \overrightarrow{\mathbf{P}}_{0}+b_{1} \overrightarrow{\mathbf{P}}_{1}+b_{2} \overrightarrow{\mathbf{P}}_{2} \\\text { Where: } \\{\left[\begin{array}{c}t \\b_{1} \\b_{2}\end{array}\right]=\frac{1}{\overrightarrow{\mathbf{S}}_{1} \bullet \overrightarrow{\mathbf{E}}_{1}}\left[\begin{array}{cc}\overrightarrow{\mathbf{S}}_{2} \cdot \overrightarrow{\mathbf{E}}_{2} \\\overrightarrow{\mathbf{S}}_{1} \cdot \overrightarrow{\mathbf{S}} \\\overrightarrow{\mathbf{S}}_{2} \cdot \overrightarrow{\mathbf{D}}\end{array}\right]} \\\text { Cost = (1 div, 27 mul, 17 add) } \\\overrightarrow{\mathbf{E}}_{1}=\overrightarrow{\mathbf{P}}_{1}-\overrightarrow{\mathbf{P}}_{0} \\\overrightarrow{\mathbf{E}}_{2}=\overrightarrow{\mathbf{P}}_{2}-\overrightarrow{\mathbf{P}}_{0} \\\overrightarrow{\mathbf{S}}=\overrightarrow{\mathbf{O}}-\overrightarrow{\mathbf{P}}_{0} \\\overrightarrow{\mathbf{S}}_{1}=\overrightarrow{\mathbf{D}} \times \overrightarrow{\mathbf{E}}_{2} \\\overrightarrow{\mathbf{S}}_{2}=\overrightarrow{\mathbf{S}} \times \overrightarrow{\mathbf{E}}_{1}\end{gathered}</script><p>该怎样加速与模型求交呢(*)？</p><ul><li><p>Naive algorithm = #pixels ⨉ # traingles (⨉ #bounces) 太慢了，不能满足我们的需求</p></li><li><p>Improved Algorithm: Bounding Volume</p><ul><li>这里我们仍然引入“包围盒”的思想，这里称为 Bounding Volume</li><li>光线能够与模型有交点的必要条件：光线能够与包围模型的一个简单包围体积有交点</li></ul></li></ul><p><img src="https://s2.loli.net/2022/01/14/gtSeZD1FWrcXQCs.png" alt="image-20220114163023985"></p><p>我们将长方体理解成三个对面所分划出的空间的交集。我们一般使用的包围体积便是长方体，且长方体是与坐标轴平行的，即轴对齐包围盒（AABB）。选用 AABB 式包围盒有利于加速计算。判断光线和 AABB 类包围盒的求交方法如下：</p><p><img src="https://s2.loli.net/2022/01/14/5rMlAnIw3gQBVNL.png" alt="image-20220114163501816"></p><p>核心思想：只有当光线进入所有三个对面后，光线才进入了包围盒；若光线从某一个对面出射，则光线便从包围盒中射出。于是我们可以计算三个对面分别对应的 $t_{min}$​​ 和 $t_{max}$​​，然后对其求交。当且仅当 $t_{enter} \lt t_{exit}$​​ 且 $t_{exit} \ge 0$​​，光线才可能与包围盒有交点。</p><h4 id="使用包围盒加速光线追踪"><a href="#使用包围盒加速光线追踪" class="headerlink" title="使用包围盒加速光线追踪"></a>使用包围盒加速光线追踪</h4><h5 id="Uniform-Grids"><a href="#Uniform-Grids" class="headerlink" title="Uniform Grids"></a>Uniform Grids</h5><p>① 预处理</p><p><img src="https://s2.loli.net/2022/01/14/Ggt2BDyranQYdCh.png" alt="image-20220114165308910"></p><p>一般来说，取格子数 #cells = #objs * 27.</p><p>② 光线与场景中模型的求交</p><p><img src="https://s2.loli.net/2022/01/14/qTfEAhQo5OXLcgW.png" alt="image-20220114165353415"></p><p>存在的问题：Teapot in a Stadium，事实上物体模型在空间中的分布可能并不均匀！</p><h5 id="空间划分-Spatial-Partitions"><a href="#空间划分-Spatial-Partitions" class="headerlink" title="空间划分 Spatial Partitions"></a>空间划分 Spatial Partitions</h5><ul><li>Oct-Tree</li><li>Kd-Tree</li><li>BSP-Tree</li></ul><p>这里以 Kd-Tree 为例，Kd-Tree 的具体实现在《数据结构》课程中已详细介绍过，这里便不再赘述。我们将空间模型首先使用 Kd-Tree 预处理，然后针对不同的光线（Query），进行如下操作：</p><ul><li>首先判断光线和最外层包围盒是否有交点，如果有那么：<ul><li>如果包围盒为叶子结点，直接判断光线和包围盒中模型是否相交并求交；</li><li>如果包围盒非叶子结点，那么对其两个子节点的包围盒，分别判断其是否与光线有交，若有则递归地执行此过程。</li></ul></li></ul><p>kd-Tree 存在的问题：</p><ul><li>难以判断实际的物体和包围盒是否相交<ul><li>即使是对于物体全部为三角形的场景，也难以判断单个包围盒和单个三角形是否有交点！</li></ul></li><li>此外，一个物体可能出现在多个叶子结点中…</li></ul><h5 id="Object-Partitions"><a href="#Object-Partitions" class="headerlink" title="Object Partitions"></a>Object Partitions</h5><ul><li>Bounding volume Hierarchy (BVH)</li></ul><p>我们划分的不是空间，而是物体！</p><p><img src="https://s2.loli.net/2022/01/16/zbLpGw5E7SCgQAu.png" alt="image-20220116102930688"></p><p>如何进行划分？</p><ul><li>沿着最长的维度来划分</li><li>划分端点取中位数<ul><li>取三角形的重心</li></ul></li></ul><p><img src="https://s2.loli.net/2022/01/16/xtKaWO7lJ2Rm8Xb.png" alt="image-20220116103520101"></p><p>使用 BVH 算法，即使包围盒可能在空间上有相交，但是我们却解决了 kd-Tree 存在的问题。</p><h4 id="辐射度量学"><a href="#辐射度量学" class="headerlink" title="辐射度量学"></a>辐射度量学</h4><p>辐射度量学提供了精准地描述光这个物理量的方法。</p><ul><li>光照的度量方法和单位</li><li>精确地度量光的时空属性<ul><li>Radiant Flux 辐射通量</li><li>Radiant Intensity 辐射强度</li><li>Irradiance 辐射照度</li><li>Radiance 辐射亮度</li></ul></li><li>使用物理正确的方法来计算光照</li></ul><h5 id="物理量的定义"><a href="#物理量的定义" class="headerlink" title="物理量的定义"></a>物理量的定义</h5><ul><li><strong>Radiant Energy</strong> $Q$ (辐射能量，单位 J)</li><li><strong>Radiant Flux</strong> (又名 <strong>Power</strong>) $\Phi = \frac {dQ} {dt}$​ （辐射通量，单位 W, lm）</li></ul><p><img src="https://s2.loli.net/2022/01/16/z41TFClAOsMcS9I.png" alt="image-20220116104840613"></p><ul><li><strong>Radiant Intensity</strong> $I(\omega) = \frac {d \Phi} {d \omega}$，其中 $\omega$​​ 是立体角，单位为 lm/sr =: cd (坎德拉)，每单位立体角的功率</li></ul><blockquote><p>立体角的定义：</p><p><img src="https://s2.loli.net/2022/01/16/la1fuCOdi9mKokN.png" alt="image-20220116105159216"></p></blockquote><p>特别地，若光源均匀辐射，则我们有 $I = \frac {\Phi} {4\pi}$​。</p><ul><li><strong>Irradiance</strong> $E(x) = \frac { d \Phi(x)} {dA}$，辐照度，单位面积上的辐射通量，单位 lux.</li></ul><p><img src="https://s2.loli.net/2022/01/16/uXeymz4bKvgBPiV.png" alt="image-20220116110821261"></p><ul><li><strong>Radiance</strong> $L(p, \omega) = \frac {d^2\Phi(p, \omega)} {d \omega dA \cos \theta}$​</li></ul><p><img src="https://s2.loli.net/2022/01/16/w8AWzY3Cs1HkaZP.png" alt="image-20220116111154506"></p><p>辐射度(亮度)是每单位立体角和每单位投影面积上，由表面反射、发射或接收的能量。辐射度是光线的属性。</p><ul><li>Radiance is power per solid angle per projected unit area;</li><li>Irradiance is power per projected unit area;</li><li>Intensity is power per solid angle;</li><li>That is to say…</li><li>Radiance is intensity per projected unit area;</li><li>Radiance is irradiance per solid angle, 也就是说，irradiance 是一个表面 $dA \cos \theta$接收到的能量，radiance 是该表面朝着某个 $\omega$ 立体角方向辐射出去或接收到的能量，后者具有表明方向的能力。</li></ul><h4 id="双向反射分布函数（BRDF）"><a href="#双向反射分布函数（BRDF）" class="headerlink" title="双向反射分布函数（BRDF）"></a>双向反射分布函数（BRDF）</h4><ul><li>BRDF := Bidirectional Reflectance Distribution Function</li></ul><p>什么是反射？反射可以看做是物体表面吸收了照射到该处的所有能量，然后再辐射出去的一个过程。</p><p>BRDF 这个分布函数是用于描述，对于物体表面一个小面积 $dA$，接收到的来自于立体角 $d \omega_i$ 的 irradiance，会以怎样的方式被辐射出去，分布于各个 solid angle 中。即：$BRDF := \frac {dL_r({\omega _r)}} {L(w_i) \cos \theta \ d\omega_i} \rightarrow percentage$​. 即：朝某个方向的辐射度占总照度的比例。</p><p><img src="https://s2.loli.net/2022/01/16/QCrPA8qnHXOhu2W.png" alt="image-20220116114348861"></p><p>使用 BRDF 可以用来定义镜面反射和漫反射。此外，BRDF 还可以用来定义物体表面的材质。</p><p>于是，借助于 BRDF 的定义，我们考虑真实的光线传播。从某个点 $dA$ 向 $\omega_r$ 方向出射的 radiance，可以通过考虑所有 $w_i$ 到达这个点的照度乘以其对应的 BRDF 占比，然后求和得到。</p><p><img src="https://s2.loli.net/2022/01/16/xbeovLICaJnK7sj.png" alt="image-20220116115205963"></p><p>问题：我们考虑的入射 Radiance 可能不仅仅由光源发出，也可能是由其他物体先经过若干次反射得到…</p><h4 id="Rendering-Equation"><a href="#Rendering-Equation" class="headerlink" title="Rendering Equation"></a>Rendering Equation</h4><script type="math/tex; mode=display">L_{o}\left(p, \omega_{o}\right)=L_{e}\left(p, \omega_{o}\right)+\int_{\Omega^{+}} L_{i}\left(p, \omega_{i}\right) f_{r}\left(p, \omega_{i}, \omega_{o}\right)\left(n \cdot \omega_{i}\right) \mathrm{d} \omega_{i}</script><p>经过推导之后，我们得出：</p><p><img src="https://s2.loli.net/2022/01/16/gFjCZGfP3VmcYTs.png" alt="image-20220116151021069"></p><p>全局光照 L = 直接光照 E 和间接光照的集合，其中 K 是反射算符。</p><h4 id="路径追踪"><a href="#路径追踪" class="headerlink" title="路径追踪"></a>路径追踪</h4><blockquote><p><strong>蒙特卡洛积分</strong></p><p>目的是为了解决定积分 $\int_a^bf(x)dx$ 问题。</p><p>做法是在 $[a,b]$​ 间随机采样足够多次，然后将足够多次的结果进行平均后作为函数均值积分。</p><p>例如，我们使用均匀采样的方式：</p><p><img src="https://s2.loli.net/2022/01/16/4MltFzimgEdkbVR.png" alt="image-20220116153649942"></p><p>更一般地，我们有：</p><script type="math/tex; mode=display">\int f(x) \mathrm{d} x=\frac{1}{N} \sum_{i=1}^{N} \frac{f\left(X_{i}\right)}{p\left(X_{i}\right)} \quad X_{i} \sim p(x)</script></blockquote><p>回忆 Whitted-style ray tracing:</p><ul><li>可以做镜面反射和折射的效果</li><li>遇到漫反射平面便停止</li></ul><p>使用渲染方程，我们可以有以下推导过程：</p><p>对于非光源表面 $dA$​​​，我们有：</p><script type="math/tex; mode=display">L_{o}\left(p, \omega_{o}\right)=\int_{\Omega^{+}} L_{i}\left(p, \omega_{i}\right) f_{r}\left(p, \omega_{i}, \omega_{o}\right)\left(n \cdot \omega_{i}\right) \mathrm{d} \omega_{i}</script><p>对 $w_i$​​ 进行 Sample，且 Sample 均匀分布于 $[0, 2\pi]$​​。于是我们可以得出：</p><script type="math/tex; mode=display">L_{o}\left(p, \omega_{o}\right) \approx \frac{1}{N} \sum_{i=1}^{N} \frac{L_{i}\left(p, \omega_{i}\right) f_{r}\left(p, \omega_{i}, \omega_{o}\right)\left(n \cdot \omega_{i}\right)}{p\left(\omega_{i}\right)}</script><p>进而，我们可以提出一种着色算法：</p><p><img src="https://s2.loli.net/2022/01/16/QVLKN1BoPISCDZE.png" alt="image-20220116164125480"></p><p>然而，我们如何继续引入全局光照的概念呢？很简单，只需要考虑如果光线 $r$ 命中某个物体时的情况。也就是说，将该物体表面视为新的光源：</p><p><img src="https://s2.loli.net/2022/01/16/qEcxeKGIJSw1lLb.png" alt="image-20220116164724144"></p><p>我们只需要计算 $q$ 处，$-w_i$ 方向发射的 Radiance，便可以得到渲染结果。</p><p>但是这样做带来的问题是，光线的数目会发生指数爆炸，于是我们只能在采样时取 N=1，即在计算蒙特卡洛积分时取 N=1，然后仅追踪一根光线的情况。</p><p><img src="https://s2.loli.net/2022/01/16/rxEkeSplq6doBgQ.png" alt="image-20220116164911441"></p><p>我们便将这种 N=1 的处理方式称为“路径追踪”。</p><p>为了降低 Noise，我们可以对像平面上的每个像素都追踪多条这样的“路径”，然后将这些路径计算得到的 Radiance 取平均值即可。</p><p><img src="https://s2.loli.net/2022/01/16/gbk2BK9LGTjZ1PV.png" alt="image-20220116165143374"></p><p>此外，我们还需要设置 shade 过程的递归基。为此，我们可以设置最大光线弹射次数，但这样取得的效果不如使用 <code>Russian Roulette</code>（俄罗斯轮盘赌）。也就是说，对于某个点的着色结果，我们给定 $p$ 的概率返回 $result_{old} / p$，$1-p$ 的概率返回 $0$​，这样做我们着色结果的期望仍是 $result_{old}$！</p><p><img src="https://s2.loli.net/2022/01/16/7g4DHb8rNKmeC1M.png" alt="image-20220116165744374"></p><p>目前我们就得到了路径追踪算法的正确版本，即对于每个像平面上的像素点调用 ray_generation 过程，而 shade 过程则加入了这样的几何分布方式来确定光线是否能够继续生存。但是目前来说，我们的算法可能在效率上并不高，在低采样率（SPP, Samples per pixel）的情况下效果并不好：</p><p><img src="https://s2.loli.net/2022/01/16/1M76Bj8Q9lnav3K.png" alt="image-20220116170133804"></p><p>这是因为，如果我们的光源过小，我们需要足够多次采样，才有可能将“追踪用光线”最终命中光源。也就是说，大部分的追踪路径都是无效的：</p><p><img src="https://s2.loli.net/2022/01/16/1j7Tk6HnRyMsVD5.png" alt="image-20220116170327150"></p><p>或许我们能找到更合适的采样概率分布…比如，<strong>对光源采样</strong>！</p><p><img src="https://s2.loli.net/2022/01/16/s8yVDHI3JiXBFeU.png" alt="image-20220116190243440"></p><p>于是：</p><script type="math/tex; mode=display">\begin{aligned}L_{o}\left(x, \omega_{o}\right) &=\int_{\Omega^{+}} L_{i}\left(x, \omega_{i}\right) f_{r}\left(x, \omega_{i}, \omega_{o}\right) \cos \theta \mathrm{d} \omega_{i} \\&=\int_{A} L_{i}\left(x, \omega_{i}\right) f_{r}\left(x, \omega_{i}, \omega_{o}\right) \frac{\cos \theta \cos \theta^{\prime}}{\left\|x^{\prime}-x\right\|^{2}} \mathrm{~d} A\end{aligned}</script><p>在之前我们假设光线可以在采样半球面上均匀射出，而现在我们将点 $dA$ 处的 Radiance 分两部分来考虑：</p><ol><li>光源的直接贡献（不需要 RR 计算）</li><li>其他表面的反射光的贡献（使用 RR）</li></ol><p>这样考虑后，我们得出改进版的路径追踪伪代码如下：</p><p><img src="https://s2.loli.net/2022/01/16/zMDhcL3almKIr6t.png" alt="image-20220116190636646"></p><p>此外，我们还需要考虑光源发出的光束是否可能被障碍物遮挡…</p><p><img src="https://s2.loli.net/2022/01/16/OEXG9d2tikuHncl.png" alt="image-20220116190917657"></p><p>最后，路径追踪的伪代码整理如下：</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">ray_generation</span><span class="token punctuation">(</span>camPos<span class="token punctuation">,</span> pixel<span class="token punctuation">)</span><span class="token punctuation">:</span>Uniformly choose N samples <span class="token keyword">from</span> the pixelpixel_radiance <span class="token operator">=</span> <span class="token number">0.0</span><span class="token keyword">for</span> sample <span class="token keyword">in</span> the pixel<span class="token punctuation">:</span>Shoot a ray r<span class="token punctuation">(</span>camPos<span class="token punctuation">,</span> cam_to_sample<span class="token punctuation">)</span><span class="token keyword">if</span> ray r hit the scene at p<span class="token punctuation">:</span>pixel_radiance <span class="token operator">+=</span> <span class="token number">1</span> <span class="token operator">/</span> N <span class="token operator">*</span> shade<span class="token punctuation">(</span>p<span class="token punctuation">,</span> sample_to_cam<span class="token punctuation">)</span>    <span class="token keyword">return</span> pixel_radiance<span class="token keyword">def</span> <span class="token function">shade</span><span class="token punctuation">(</span>p<span class="token punctuation">,</span> wo<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment"># Contributions from the light source</span>L_dir <span class="token operator">=</span> <span class="token number">0.0</span>Uniformly sample the light at x' <span class="token punctuation">(</span>pdf_light <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span>A<span class="token punctuation">)</span>Shoot a ray <span class="token keyword">from</span> p to x'<span class="token keyword">if</span> the ray <span class="token keyword">is</span> <span class="token keyword">not</span> blocked <span class="token keyword">in</span> the middle<span class="token punctuation">:</span>L_dir <span class="token operator">=</span> L_i <span class="token operator">*</span> f_r <span class="token operator">*</span> cos \theta <span class="token operator">*</span> cos \theta<span class="token string">' / |x'</span><span class="token operator">-</span>p<span class="token operator">|</span><span class="token operator">^</span><span class="token number">2</span> <span class="token operator">/</span> pdf_light        <span class="token comment"># Contributions from other places</span>    L_indir <span class="token operator">=</span> <span class="token number">0.0</span>    If test Russian Roulette <span class="token keyword">with</span> probability P_RR <span class="token punctuation">:</span>        Uniformly sample the hemisphere toward wi <span class="token punctuation">(</span>pdf_hemi <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> 2pi<span class="token punctuation">)</span>        Trace a ray r<span class="token punctuation">(</span>p<span class="token punctuation">,</span> wi<span class="token punctuation">)</span>        If ray r hit a non<span class="token operator">-</span>emitting <span class="token builtin">object</span> at q<span class="token punctuation">:</span>            L_indir <span class="token operator">=</span> shade<span class="token punctuation">(</span>q<span class="token punctuation">,</span> <span class="token operator">-</span>wi<span class="token punctuation">)</span> <span class="token operator">*</span> f_r <span class="token operator">*</span> cos \theta <span class="token operator">/</span> pdf_hemi <span class="token operator">/</span> P_RR        Return L_dir <span class="token operator">+</span> L_indir</code></pre><h2 id="材质与外观-Materials-and-Appearance"><a href="#材质与外观-Materials-and-Appearance" class="headerlink" title="材质与外观 Materials and Appearance"></a>材质与外观 Materials and Appearance</h2><ul><li>Material == BRDF!</li></ul><h3 id="一些材质的例子"><a href="#一些材质的例子" class="headerlink" title="一些材质的例子"></a>一些材质的例子</h3><h4 id="漫反射材料-Diffuse-Lambertian-Material"><a href="#漫反射材料-Diffuse-Lambertian-Material" class="headerlink" title="漫反射材料 Diffuse/Lambertian Material"></a>漫反射材料 Diffuse/Lambertian Material</h4><p>假设入射光的 Radiance 均匀分布：</p><script type="math/tex; mode=display">\begin{aligned}L_{o}\left(\omega_{o}\right) &=\int_{H^{2}} f_{r} L_{i}\left(\omega_{i}\right) \cos \theta_{i} \mathrm{~d} \omega_{i} \\&=f_{r} L_{i} \int_{H^{2}}\left(\omega_{i}\right) \cos \theta_{i} \mathrm{~d} \omega_{i} \\&=\pi f_{r} L_{i} \\f_{r}=\frac{\rho}{\pi} &-\text { albedo (color) }\end{aligned}</script><p>这里 $\rho$ 可以是常数（单通道），也可以是针对不同通道定义了不同数值的向量。</p><h4 id="抛光的金属-Glossy-Material"><a href="#抛光的金属-Glossy-Material" class="headerlink" title="抛光的金属 Glossy Material"></a>抛光的金属 Glossy Material</h4><p><img src="https://s2.loli.net/2022/01/17/9xZHgA8u6icXKyo.png" alt="image-20220117103604496"></p><h4 id="理想反射-折射材质"><a href="#理想反射-折射材质" class="headerlink" title="理想反射/折射材质"></a>理想反射/折射材质</h4><p><img src="https://s2.loli.net/2022/01/17/RgoxIXL2qr3MaD7.png" alt="image-20220117103654766"></p><ul><li>反射：反射定律</li><li>折射：折射定律 Snell’s Law，注意全反射的情况</li><li>能量分配：菲涅尔公式 Fresnel Term</li></ul><blockquote><p>精确的菲涅尔公式：</p><script type="math/tex; mode=display">\begin{aligned}&R_{\mathrm{s}}=\left|\frac{n_{1} \cos \theta_{\mathrm{i}}-n_{2} \cos \theta_{\mathrm{t}}}{n_{1} \cos \theta_{\mathrm{i}}+n_{2} \cos \theta_{\mathrm{t}}}\right|^{2}=\left|\frac{n_{1} \cos \theta_{\mathrm{i}}-n_{2} \sqrt{1-\left(\frac{n_{1}}{n_{2}} \sin \theta_{\mathrm{i}}\right)^{2}}}{n_{1} \cos \theta_{\mathrm{i}}+n_{2} \sqrt{1-\left(\frac{n_{1}}{n_{2}} \sin \theta_{\mathrm{i}}\right)^{2}}}\right|^{2} \\&R_{\mathrm{p}}=\left|\frac{n_{1} \cos \theta_{\mathrm{t}}-n_{2} \cos \theta_{\mathrm{i}}}{n_{1} \cos \theta_{\mathrm{t}}+n_{2} \cos \theta_{\mathrm{i}}}\right|^{2}=\left|\frac{n_{1} \sqrt{1-\left(\frac{n_{1}}{n_{2}} \sin \theta_{\mathrm{i}}\right)^{2}}-n_{2} \cos \theta_{\mathrm{i}}}{n_{1} \sqrt{1-\left(\frac{n_{1}}{n_{2}} \sin \theta_{\mathrm{i}}\right)^{2}}+n_{2} \cos \theta_{\mathrm{i}}}\right|^{2} \\& R_{eff} = \frac 1 2 (R_s + R_p)\end{aligned}</script></blockquote><p>近似后：</p><script type="math/tex; mode=display">\begin{aligned}R(\theta) &=R_{0}+\left(1-R_{0}\right)(1-\cos \theta)^{5} \\R_{0} &=\left(\frac{n_{1}-n_{2}}{n_{1}+n_{2}}\right)^{2}\end{aligned}</script><h4 id="微表面模型-Microfacet-Material"><a href="#微表面模型-Microfacet-Material" class="headerlink" title="微表面模型 Microfacet Material"></a>微表面模型 Microfacet Material</h4><p>虽然物体的表面是粗糙的，但是若从远处看，则可以将物体表面视为是平的。即对于粗糙表面来说：</p><ul><li>从远处看可以视为是平的粗糙表面</li><li>从近处看看到的是高低起伏的高光表面</li></ul><p>从远处看看到的是材质，从近处看看到的是几何。</p><p><img src="https://s2.loli.net/2022/01/17/8ESojAlrTM1sptY.png" alt="image-20220117110551868"></p><p>我们考虑这些微表面的法线的分布情况。如果其分布方差较小，则表面是 Glossy 的；而如果其分布方差较大，我们可以视其表面为 Diffuse 型。</p><p><img src="https://s2.loli.net/2022/01/17/n8QueMgHco16W5R.png" alt="image-20220117111415698"></p><h4 id="各向同性与各向异性材质"><a href="#各向同性与各向异性材质" class="headerlink" title="各向同性与各向异性材质"></a>各向同性与各向异性材质</h4><p>这是一种分类材质的方式。各向同性材质的微表面的法线分布并不具有明确的方向性，而各向异性材质的法线分布却具有，因而后者具有一些特殊的性质。</p><p>从定义上来说，后者的 BRDF 与其绝对方位角 $\Phi$ 有关。</p><h3 id="BRDF-的性质与其测量"><a href="#BRDF-的性质与其测量" class="headerlink" title="BRDF 的性质与其测量"></a>BRDF 的性质与其测量</h3><blockquote><p>BRDF 的性质：</p><ul><li>Non-negativity</li><li>Linearity</li><li>Reciprocity principle： $f_r(w_r \rightarrow w_i) = f_r(w_i \rightarrow w_r)$</li><li>Energy conservation</li><li>Isotropic or anisotropic</li></ul></blockquote><p>测量方法：</p><p><img src="https://s2.loli.net/2022/01/17/cegxist9jRBoTdb.png" alt="image-20220117112601733"></p><ul><li>MERL BRDF Database</li></ul><h2 id="知识补完"><a href="#知识补完" class="headerlink" title="知识补完"></a>知识补完</h2><h3 id="相机、棱镜与光场"><a href="#相机、棱镜与光场" class="headerlink" title="相机、棱镜与光场"></a>相机、棱镜与光场</h3><ul><li>成像 Imaging = Synthesis 合成 + Capture 捕捉</li></ul><h4 id="FOV"><a href="#FOV" class="headerlink" title="FOV"></a>FOV</h4><ul><li>小孔成像：针孔相机</li></ul><p><img src="https://s2.loli.net/2022/01/17/NtqCuUidJ1kSafb.png" alt="image-20220117162312506"></p><p>视场 $FOV = 2 \arctan(\frac {h} {2f})$​，一般我们取 $h=36 * 24mm$ 时 $f$ 的大小作为 $FOV$ 的大小。</p><h4 id="Exposure"><a href="#Exposure" class="headerlink" title="Exposure"></a>Exposure</h4><ul><li>曝光 Exposure = Time * Irradiance</li></ul><p>其中 Time 由快门控制，能量由光圈的大小和焦距决定。此外，ISO 感光度可以视为是后期处理，给感光的多少进行倍增。这些因素都能影响成像的亮度。</p><p><img src="https://s2.loli.net/2022/01/17/73moA5gzpaDlFU9.png" alt="image-20220117163652644"></p><p>原理：ISO 作为后期处理，对于含有噪声的信号，同时将信号放大，噪声也随之被放大，因此会显得 Noisy；F-Number(F-Stop) 一般写作 F<strong>N</strong> 或 F/<strong>N</strong>。这里的 N 可以近似理解为光圈直径的倒数。快门速度变快也会降低 Exposure，而变慢会产生模糊。</p><h4 id="薄透镜-Thin-lens"><a href="#薄透镜-Thin-lens" class="headerlink" title="薄透镜 Thin lens"></a>薄透镜 Thin lens</h4><p>平行光入射，出射光过焦点；过焦点光入射，出射光平行；焦距可任意改变；$\frac 1 f = \frac 1 {z_i} + \frac 1 {z_o}$​。</p><p>利用薄透镜可以解释景深的问题：</p><p><img src="https://s2.loli.net/2022/01/17/r8hei9FOAUZWb7P.png" alt="image-20220117165250088"></p><h4 id="光场-Light-Field-Lumigraph"><a href="#光场-Light-Field-Lumigraph" class="headerlink" title="光场 Light Field / Lumigraph"></a>光场 Light Field / Lumigraph</h4><ul><li>全光函数：我们看到的世界是七维函数</li></ul><p><img src="https://s2.loli.net/2022/01/17/OWevpzGJ1g7kVf4.png" alt="image-20220117171128615"></p><ul><li>光场是全光函数在位置集合上的限制，给定任何一个位置和任何一个方向，输出光线的强度。<ul><li>要想描述一个发光物体对于任何位置任何方向的辐射贡献，我们可以考虑用一个包围盒罩住这个物体，只需要知道这个包围盒上任意一点对于任意方向的辐射贡献，就可以用于替代这个物体的辐射贡献。</li><li>也就是说，对于任何一个物体，我们作全光函数在其包围盒上的限制，只要弄清楚其包围盒上任意一点对于任意方向的光照辐射，就可以用于替代这个发光物体。这样做方便我们进行 Query.</li><li>U-V 平面与 S-T 平面</li><li>光场照相机</li></ul></li></ul><h3 id="颜色与感知"><a href="#颜色与感知" class="headerlink" title="颜色与感知"></a>颜色与感知</h3><ul><li>谱功率密度（SPD），具有线性可加性；</li><li><strong>颜色</strong>事实上是人的一种感知，它并不是光的一种属性；</li><li>人感光的生物基础：视网膜上的 Cone 型细胞</li><li>同色异谱现象的存在</li><li>颜色的混合与匹配<ul><li>加色系统</li></ul></li><li>颜色空间与色域，RGB, XYZ, HSV, Lab, CMYK</li></ul><h2 id="动画与模拟"><a href="#动画与模拟" class="headerlink" title="动画与模拟"></a>动画与模拟</h2><h3 id="质点弹簧系统"><a href="#质点弹簧系统" class="headerlink" title="质点弹簧系统"></a>质点弹簧系统</h3><ul><li>质点弹簧系统：一系列相互连接的质点和弹簧</li></ul><script type="math/tex; mode=display">\boldsymbol{f}_{a \rightarrow b}=k_{s} \frac{\boldsymbol{b}-\boldsymbol{a}}{\|\boldsymbol{b}-\boldsymbol{a}\|}(\|\boldsymbol{b}-\boldsymbol{a}\|-l) \\f_{b \rightarrow a} = - f_{ a \rightarrow b}</script><p>我们再引入内部损耗摩擦力以让该系统可以停下来：</p><script type="math/tex; mode=display">\boldsymbol{f}_{\boldsymbol{b}}=-k_{d} \ \left( \frac{\boldsymbol{b}-\boldsymbol{a}}{\|\boldsymbol{b}-\boldsymbol{a}\|} \cdot(\dot{\boldsymbol{b}}-\dot{\boldsymbol{a}}) \right)\  \frac{\boldsymbol{b}-\boldsymbol{a}}{\|\boldsymbol{b}-\boldsymbol{a}\|}</script><ul><li>质点弹簧系统组成的结构：<ul><li>Sheet / Block / …</li><li>下图为用质点弹簧系统对布料的模拟：</li></ul></li></ul><p><img src="https://s2.loli.net/2022/01/18/nKJWEFLij1BHOXz.png" alt="image-20220118112053335"></p><h3 id="粒子系统"><a href="#粒子系统" class="headerlink" title="粒子系统"></a>粒子系统</h3><p>把我们考虑的物体细分成粒子表示，然后在动画的每一帧中：</p><ul><li>(如果需要) 创建新粒子</li><li>计算每个粒子上的作用力</li><li>更新每个粒子的位置和速度</li><li>（如果需要）移除某些例子</li><li>渲染该帧</li></ul><h3 id="运动学"><a href="#运动学" class="headerlink" title="运动学"></a>运动学</h3><ul><li>正向运动学：通过定义各个部件之间的连接方式，给定参数（如 $l, \theta$），即可计算相应部件的位置</li><li>逆运动学：可以通过拖拽等方式改变最终目标部件的位置，中间的各个部件的情况自动计算得出</li></ul><blockquote><p>逆运动学的应用： Rigging</p><p>Rigging 是对于一个角色的控制，就像是提线木偶一样，改变角色的姿态或表情…</p><p>不同角色的 Rigging 是不同的…</p></blockquote><h3 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h3><ul><li><strong>Euler’s Method</strong>：简单的迭代法，十分不精确且不稳定</li></ul><script type="math/tex; mode=display">\begin{aligned}&\boldsymbol{x}^{t+\Delta t}=\boldsymbol{x}^{t}+\Delta t \dot{\boldsymbol{x}}^{t} \\&\dot{\boldsymbol{x}}^{t+\Delta t}=\dot{\boldsymbol{x}}^{t}+\Delta t \ddot{\boldsymbol{x}}^{t}\end{aligned}</script><p>用数值迭代的方法解 ODE 存在的问题：</p><ul><li>误差：随着迭代步数的增加，迭代结果和真实结果存在偏移</li><li>稳定性：原本收敛的结果<strong>发散</strong>，如螺旋速度场中粒子应该最终做匀速圆周运动，而实际模拟却会飞出该场</li></ul><p>于是，我们有若干方法解决这种不稳定性：</p><ul><li><strong>中点法 Midpoint Method</strong></li></ul><script type="math/tex; mode=display">\begin{aligned}x_{\mathrm{mid}} &=x(t)+\Delta t / 2 \cdot v(x(t), t) \\x(t+\Delta t) &=x(t)+\Delta t \cdot v\left(x_{\mathrm{mid}}, t\right)\end{aligned}\</script><ul><li><strong>Adaptive Step Size 自适应步长</strong></li></ul><p>按照误差项判断是否将 $\Delta t$​ 继续细分…</p><pre class="language-none"><code class="language-none">Repeat until error is below certain threshold epsilon:Compute x(T) one Euler step, size TCompute x(T&#x2F;2) two Euler steps, size T&#x2F;2Compute error &#x3D; || x(T) - x(T&#x2F;2) ||if (error &gt; threshold):T &lt;- reduced(T)else:break</code></pre><ul><li><strong>隐式欧拉方法</strong></li></ul><script type="math/tex; mode=display">\begin{aligned}\boldsymbol{x}^{t+\Delta t} &=\boldsymbol{x}^{t}+\Delta t \dot{\boldsymbol{x}}^{t+\Delta t} \\\dot{\boldsymbol{x}}^{t+\Delta t} &=\dot{\boldsymbol{x}}^{t}+\Delta t \ddot{\boldsymbol{x}}^{t+\Delta t}\end{aligned}</script><p>这种方法提供了更好的稳定性，下面我们就进行稳定性的定义：</p><ul><li>局部截断误差 Truncation Error</li><li>累积误差 Accumulated Error</li></ul><p>我们一般研究误差就是研究这两个误差和我们所取的 $\Delta t$ 的阶数的关系。</p><p>推导可以得出，隐式欧拉方法：</p><ul><li>Local Truncation Error: $O(h^2)$</li><li>Global Truncation Error: $O(h)$</li><li>$h$ is the step size, i.e. $\Delta t$​.</li></ul><p>误差是 $O(h)$ 的意思是说，如果我们将步长缩小到原来的一半，那么误差期望也缩小到原来的一半。</p><p>Runge-Kutta Families 中的 RK4 方法广泛得到运用，是一个 4 阶的方法。</p><ul><li><strong>Position-Based / Verlet Integration</strong>，一种不是基于物理的方法<ul><li>这种方法快速简单，但是可能不会遵守能量守恒等物理定律</li></ul></li></ul><p>下面举一个简单的 Position-Based 方法的例子，即渲染如下图片的例子。</p><p><img src="https://s2.loli.net/2022/01/18/Z21NyICghTidwWG.png" alt="image-20220118165158591"></p><p>关键想法如下：</p><ul><li>将水视为是很多小刚体球组成的</li><li>认为水的密度是不变的，即这些小刚体球是不可以被压缩的</li><li>也就是说，一旦某处水的密度改变了，就应该通过重新分布不同区域的刚体球的数量来“矫正”这个变化<ul><li>需要知道水的密度场的梯度！</li><li>这个水的密度场是由刚体球所在位置决定的…</li></ul></li><li>如何矫正？Gradient Descent!</li></ul><blockquote><p>模拟方法的总结：</p><ul><li>（质点法）拉格朗日方法，将物体细分成一个个质点</li><li>（网格法）欧拉方法，将整个空间分为不同的网格，考虑空间网格中存在的物体随着时间的变化</li></ul></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;GAMES 101 现代计算机图形学基础 笔记（下篇）.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;光线追踪（Whitted-style，求交算法，加速结构，辐射度量学，路径追踪）&lt;/li&gt;
&lt;li&gt;材质与外观&lt;/li&gt;
&lt;li&gt;动画与模拟&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="理论" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/"/>
    
    <category term="理论/计算机图形学" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/%E7%90%86%E8%AE%BA-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="图形学" scheme="https://www.c7w.tech/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Python Pandas 库使用指北</title>
    <link href="https://www.c7w.tech/python-pandas/"/>
    <id>https://www.c7w.tech/python-pandas/</id>
    <published>2022-01-11T12:26:30.000Z</published>
    <updated>2022-01-29T13:45:58.186Z</updated>
    
    <content type="html"><![CDATA[<p><code>Pandas</code> 是 Python 下的高性能的数据管理工具与数据分析工具。</p><p>本文中介绍了 <code>Pandas</code> 库中的一些常用类，然后记录了一些简单的筛选，切片等等用法。</p><a id="more"></a><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul><li>（主要数据结构）Pandas 的主要数据结构是 <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series">Series</a>（一维数据）与 <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame">DataFrame</a>（二维数据）。</li><li>（大小不变）Pandas 所有数据结构的值都是可变的，但数据结构的大小并非都是可变的，比如，Series 的长度不可改变，但 DataFrame 里就可以插入列。</li><li>（倾向于复制）Pandas 里，绝大多数方法都不改变原始的输入数据，而是复制数据，生成新的对象。 一般来说，原始输入数据<strong>不变</strong>更稳妥。</li></ul><h2 id="快速入门"><a href="#快速入门" class="headerlink" title="快速入门"></a>快速入门</h2><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</code></pre><h3 id="生成-Series-与-DataFrame"><a href="#生成-Series-与-DataFrame" class="headerlink" title="生成 Series 与 DataFrame"></a>生成 Series 与 DataFrame</h3><ul><li>Series 的生成：默认使用整数索引</li></ul><pre class="language-none"><code class="language-none">&gt;&gt;&gt; s &#x3D; pd.Series([1,3,5,np.nan,6,8])&gt;&gt;&gt; s0    1.01    3.02    5.03    NaN4    6.05    8.0dtype: float64</code></pre><ul><li>DataFrame 的生成：① 指定数据，索引，列名与是否为拷贝<ul><li><code>class pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=None)</code></li></ul></li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> dates <span class="token operator">=</span> pd<span class="token punctuation">.</span>date_range<span class="token punctuation">(</span><span class="token string">'20220101'</span><span class="token punctuation">,</span> periods<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> datesDatetimeIndex<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'2022-01-01'</span><span class="token punctuation">,</span> <span class="token string">'2022-01-02'</span><span class="token punctuation">,</span> <span class="token string">'2022-01-03'</span><span class="token punctuation">,</span> <span class="token string">'2022-01-04'</span><span class="token punctuation">,</span>               <span class="token string">'2022-01-05'</span><span class="token punctuation">,</span> <span class="token string">'2022-01-06'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              dtype<span class="token operator">=</span><span class="token string">'datetime64[ns]'</span><span class="token punctuation">,</span> freq<span class="token operator">=</span><span class="token string">'D'</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> index<span class="token operator">=</span>dates<span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token string">'ABCD'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> df                   A         B         C         D<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span> <span class="token operator">-</span><span class="token number">0.165424</span> <span class="token operator">-</span><span class="token number">0.095599</span>  <span class="token number">0.940562</span> <span class="token operator">-</span><span class="token number">0.629898</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">0.237563</span>  <span class="token number">0.252783</span>  <span class="token number">1.362851</span> <span class="token operator">-</span><span class="token number">1.525588</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">2.222287</span> <span class="token operator">-</span><span class="token number">0.591918</span> <span class="token operator">-</span><span class="token number">1.450194</span>  <span class="token number">0.860104</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span> <span class="token operator">-</span><span class="token number">0.560238</span>  <span class="token number">0.548346</span> <span class="token operator">-</span><span class="token number">0.691656</span> <span class="token operator">-</span><span class="token number">0.810484</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">1.600348</span>  <span class="token number">0.242665</span>  <span class="token number">0.836329</span>  <span class="token number">0.372371</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span> <span class="token operator">-</span><span class="token number">0.332250</span> <span class="token operator">-</span><span class="token number">0.941505</span>  <span class="token number">0.110009</span> <span class="token operator">-</span><span class="token number">1.478538</span><span class="token operator">>></span><span class="token operator">></span> a1 <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"A"</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">"B"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">"c"</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">&#125;</span><span class="token operator">>></span><span class="token operator">></span> a2 <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"A"</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">"B"</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">"C"</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">&#125;</span><span class="token operator">>></span><span class="token operator">></span> pd1 <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">[</span>a1<span class="token punctuation">,</span> a2<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> pd1   A  B    c    C<span class="token number">0</span>  <span class="token number">1</span>  <span class="token number">2</span>  <span class="token number">3.0</span>  NaN<span class="token number">1</span>  <span class="token number">1</span>  <span class="token number">3</span>  NaN  <span class="token number">5.0</span></code></pre><ul><li>DataFrame 的生成：② read_csv</li></ul><pre class="language-python" data-language="python"><code class="language-python">task <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'./Data/</span><span class="token interpolation"><span class="token punctuation">&#123;</span>camp_name<span class="token punctuation">&#125;</span></span><span class="token string">/task.csv'</span></span><span class="token punctuation">)</span>         tid     name   score<span class="token number">0</span>  <span class="token number">0001</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span>A   任务 <span class="token number">1</span><span class="token operator">-</span>A       <span class="token number">5</span><span class="token number">1</span>  <span class="token number">0001</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span>B   任务 <span class="token number">1</span><span class="token operator">-</span>B       <span class="token number">7</span><span class="token number">2</span>  <span class="token number">0001</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span>C   任务 <span class="token number">1</span><span class="token operator">-</span>C       <span class="token number">2</span><span class="token number">3</span>  <span class="token number">0001</span><span class="token operator">-</span><span class="token number">02</span><span class="token operator">-</span>A   任务 <span class="token number">2</span><span class="token operator">-</span>A       <span class="token number">5</span><span class="token number">4</span>  <span class="token number">0001</span><span class="token operator">-</span><span class="token number">02</span><span class="token operator">-</span>B   任务 <span class="token number">2</span><span class="token operator">-</span>B       <span class="token number">5</span><span class="token number">5</span>  <span class="token number">0001</span><span class="token operator">-</span><span class="token number">99</span><span class="token operator">-</span>A    Bonus       <span class="token number">1</span></code></pre><ul><li>DataFrame 的生成：③ data 中传入 Series，利用其所有的 index。如果不同列的 index 不 match，那么报错。</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># Example</span>df2 <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">'A'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>                     <span class="token string">'B'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Timestamp<span class="token punctuation">(</span><span class="token string">'20130102'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'C'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'D'</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'int32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'E'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Categorical<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">,</span> <span class="token string">"train"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">,</span> <span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'F'</span><span class="token punctuation">:</span> <span class="token string">'foo'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span> <span class="token operator">>></span><span class="token operator">></span> df2     A          B    C  D      E    F<span class="token number">0</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>   test  foo<span class="token number">1</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>  train  foo<span class="token number">2</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>   test  foo<span class="token number">3</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>  train  foo<span class="token comment"># Test</span>df3 <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">'A'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>                     <span class="token string">'B'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Timestamp<span class="token punctuation">(</span><span class="token string">'20130102'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'C'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'D'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'E'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Categorical<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">,</span> <span class="token string">"train"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">,</span> <span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'F'</span><span class="token punctuation">:</span> <span class="token string">'foo'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span><span class="token punctuation">:</span>  File <span class="token string">"&lt;stdin>"</span><span class="token punctuation">,</span> line <span class="token number">1</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>  File <span class="token string">"/home/c7w/.local/lib/python3.8/site-packages/pandas/core/frame.py"</span><span class="token punctuation">,</span> line <span class="token number">614</span><span class="token punctuation">,</span> <span class="token keyword">in</span> __init__    mgr <span class="token operator">=</span> dict_to_mgr<span class="token punctuation">(</span>data<span class="token punctuation">,</span> index<span class="token punctuation">,</span> columns<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span> copy<span class="token operator">=</span>copy<span class="token punctuation">,</span> typ<span class="token operator">=</span>manager<span class="token punctuation">)</span>  File <span class="token string">"/home/c7w/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py"</span><span class="token punctuation">,</span> line <span class="token number">464</span><span class="token punctuation">,</span> <span class="token keyword">in</span> dict_to_mgr    <span class="token keyword">return</span> arrays_to_mgr<span class="token punctuation">(</span>  File <span class="token string">"/home/c7w/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py"</span><span class="token punctuation">,</span> line <span class="token number">119</span><span class="token punctuation">,</span> <span class="token keyword">in</span> arrays_to_mgr    index <span class="token operator">=</span> _extract_index<span class="token punctuation">(</span>arrays<span class="token punctuation">)</span>  File <span class="token string">"/home/c7w/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py"</span><span class="token punctuation">,</span> line <span class="token number">649</span><span class="token punctuation">,</span> <span class="token keyword">in</span> _extract_index    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>msg<span class="token punctuation">)</span>ValueError<span class="token punctuation">:</span> array length <span class="token number">4</span> does <span class="token keyword">not</span> match index length <span class="token number">6</span>        <span class="token comment"># Another Test</span>df3 <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">'A'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>                     <span class="token string">'B'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Timestamp<span class="token punctuation">(</span><span class="token string">'20130102'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'C'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'D'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'E'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Categorical<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">,</span> <span class="token string">"train"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">,</span> <span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'F'</span><span class="token punctuation">:</span> <span class="token string">'foo'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span><span class="token punctuation">:</span>  File <span class="token string">"&lt;stdin>"</span><span class="token punctuation">,</span> line <span class="token number">1</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>  File <span class="token string">"/home/c7w/.local/lib/python3.8/site-packages/pandas/core/frame.py"</span><span class="token punctuation">,</span> line <span class="token number">614</span><span class="token punctuation">,</span> <span class="token keyword">in</span> __init__    mgr <span class="token operator">=</span> dict_to_mgr<span class="token punctuation">(</span>data<span class="token punctuation">,</span> index<span class="token punctuation">,</span> columns<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span> copy<span class="token operator">=</span>copy<span class="token punctuation">,</span> typ<span class="token operator">=</span>manager<span class="token punctuation">)</span>  File <span class="token string">"/home/c7w/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py"</span><span class="token punctuation">,</span> line <span class="token number">464</span><span class="token punctuation">,</span> <span class="token keyword">in</span> dict_to_mgr    <span class="token keyword">return</span> arrays_to_mgr<span class="token punctuation">(</span>  File <span class="token string">"/home/c7w/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py"</span><span class="token punctuation">,</span> line <span class="token number">119</span><span class="token punctuation">,</span> <span class="token keyword">in</span> arrays_to_mgr    index <span class="token operator">=</span> _extract_index<span class="token punctuation">(</span>arrays<span class="token punctuation">)</span>  File <span class="token string">"/home/c7w/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py"</span><span class="token punctuation">,</span> line <span class="token number">649</span><span class="token punctuation">,</span> <span class="token keyword">in</span> _extract_index    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>msg<span class="token punctuation">)</span>ValueError<span class="token punctuation">:</span> array length <span class="token number">4</span> does <span class="token keyword">not</span> match index length <span class="token number">7</span>                <span class="token comment"># Another Test</span>df3 <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">'A'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>                     <span class="token string">'B'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Timestamp<span class="token punctuation">(</span><span class="token string">'20130102'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'C'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'D'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'E'</span><span class="token punctuation">:</span> pd<span class="token punctuation">.</span>Categorical<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">,</span> <span class="token string">"train"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">,</span> <span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token string">'F'</span><span class="token punctuation">:</span> <span class="token string">'foo'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> df3     A          B    C     D      E    F<span class="token number">0</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">12.0</span>   test  foo<span class="token number">1</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">12.0</span>  train  foo<span class="token number">2</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">12.0</span>   test  foo<span class="token number">3</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">12.0</span>  train  foo</code></pre><h3 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h3><ul><li>列数据类型</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df2<span class="token punctuation">.</span>dtypesA           float64B    datetime64<span class="token punctuation">[</span>ns<span class="token punctuation">]</span>C           float32D             int32E          categoryF            <span class="token builtin">object</span>dtype<span class="token punctuation">:</span> <span class="token builtin">object</span></code></pre><ul><li>预览数据</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df2     A          B    C  D      E    F<span class="token number">0</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>   test  foo<span class="token number">1</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>  train  foo<span class="token number">2</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>   test  foo<span class="token number">3</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>  train  foo<span class="token operator">>></span><span class="token operator">></span> df2<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 默认最多显示 5 条数据</span>     A          B    C  D      E    F<span class="token number">0</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>   test  foo<span class="token number">1</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>  train  foo<span class="token number">2</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>   test  foo<span class="token number">3</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>  train  foo<span class="token operator">>></span><span class="token operator">></span> df2<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>     A          B    C  D      E    F<span class="token number">0</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>   test  foo<span class="token number">1</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>  train  foo<span class="token operator">>></span><span class="token operator">></span> df2<span class="token punctuation">.</span>tail<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>     A          B    C  D      E    F<span class="token number">2</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>   test  foo<span class="token number">3</span>  <span class="token number">1.0</span> <span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.0</span>  <span class="token number">3</span>  train  foo</code></pre><ul><li>显示索引与列</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df2<span class="token punctuation">.</span>indexInt64Index<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'int64'</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> df2<span class="token punctuation">.</span>columnsIndex<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">,</span> <span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token string">'D'</span><span class="token punctuation">,</span> <span class="token string">'E'</span><span class="token punctuation">,</span> <span class="token string">'F'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'object'</span><span class="token punctuation">)</span></code></pre><ul><li>转换成 numpy 对象</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> index<span class="token operator">=</span>dates<span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token string">'ABCD'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> df                   A         B         C         D<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span> <span class="token operator">-</span><span class="token number">0.451372</span>  <span class="token number">1.581206</span> <span class="token operator">-</span><span class="token number">0.499837</span> <span class="token operator">-</span><span class="token number">0.549320</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">0.508692</span> <span class="token operator">-</span><span class="token number">0.304325</span>  <span class="token number">1.995154</span> <span class="token operator">-</span><span class="token number">0.895727</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">0.681460</span>  <span class="token number">1.214341</span> <span class="token operator">-</span><span class="token number">0.608446</span> <span class="token operator">-</span><span class="token number">1.054553</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span> <span class="token operator">-</span><span class="token number">1.032206</span>  <span class="token number">0.237051</span>  <span class="token number">1.502665</span> <span class="token operator">-</span><span class="token number">0.048824</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">1.707183</span>  <span class="token number">0.382228</span>  <span class="token number">1.335121</span> <span class="token operator">-</span><span class="token number">1.099418</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>  <span class="token number">0.895205</span>  <span class="token number">0.982582</span>  <span class="token number">0.188397</span>  <span class="token number">0.023960</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>to_numpy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 纯 float 类型，转换速度较快</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.45137221</span><span class="token punctuation">,</span>  <span class="token number">1.58120564</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.49983697</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.54931982</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.50869221</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.30432474</span><span class="token punctuation">,</span>  <span class="token number">1.99515425</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.89572709</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.68146026</span><span class="token punctuation">,</span>  <span class="token number">1.21434138</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.60844611</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.05455281</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.03220563</span><span class="token punctuation">,</span>  <span class="token number">0.23705134</span><span class="token punctuation">,</span>  <span class="token number">1.50266499</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.04882351</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.70718305</span><span class="token punctuation">,</span>  <span class="token number">0.38222751</span><span class="token punctuation">,</span>  <span class="token number">1.33512092</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.09941788</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.89520526</span><span class="token punctuation">,</span>  <span class="token number">0.98258218</span><span class="token punctuation">,</span>  <span class="token number">0.18839673</span><span class="token punctuation">,</span>  <span class="token number">0.02396049</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> df2<span class="token punctuation">.</span>to_numpy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 复合数据类型，转换速度慢</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> Timestamp<span class="token punctuation">(</span><span class="token string">'2013-01-02 00:00:00'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> Timestamp<span class="token punctuation">(</span><span class="token string">'2013-01-02 00:00:00'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> Timestamp<span class="token punctuation">(</span><span class="token string">'2013-01-02 00:00:00'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> Timestamp<span class="token punctuation">(</span><span class="token string">'2013-01-02 00:00:00'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>      dtype<span class="token operator">=</span><span class="token builtin">object</span><span class="token punctuation">)</span></code></pre><ul><li>数据统计信息</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>describe<span class="token punctuation">(</span><span class="token punctuation">)</span>              A         B         C         Dcount  <span class="token number">6.000000</span>  <span class="token number">6.000000</span>  <span class="token number">6.000000</span>  <span class="token number">6.000000</span>mean   <span class="token number">0.384827</span>  <span class="token number">0.682181</span>  <span class="token number">0.652176</span> <span class="token operator">-</span><span class="token number">0.603980</span>std    <span class="token number">0.981800</span>  <span class="token number">0.698997</span>  <span class="token number">1.106773</span>  <span class="token number">0.497813</span><span class="token builtin">min</span>   <span class="token operator">-</span><span class="token number">1.032206</span> <span class="token operator">-</span><span class="token number">0.304325</span> <span class="token operator">-</span><span class="token number">0.608446</span> <span class="token operator">-</span><span class="token number">1.099418</span><span class="token number">25</span><span class="token operator">%</span>   <span class="token operator">-</span><span class="token number">0.211356</span>  <span class="token number">0.273345</span> <span class="token operator">-</span><span class="token number">0.327779</span> <span class="token operator">-</span><span class="token number">1.014846</span><span class="token number">50</span><span class="token operator">%</span>    <span class="token number">0.595076</span>  <span class="token number">0.682405</span>  <span class="token number">0.761759</span> <span class="token operator">-</span><span class="token number">0.722523</span><span class="token number">75</span><span class="token operator">%</span>    <span class="token number">0.841769</span>  <span class="token number">1.156402</span>  <span class="token number">1.460779</span> <span class="token operator">-</span><span class="token number">0.173948</span><span class="token builtin">max</span>    <span class="token number">1.707183</span>  <span class="token number">1.581206</span>  <span class="token number">1.995154</span>  <span class="token number">0.023960</span></code></pre><h3 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h3><ul><li>转置</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>T   <span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>  <span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>A   <span class="token operator">-</span><span class="token number">0.451372</span>    <span class="token number">0.508692</span>    <span class="token number">0.681460</span>   <span class="token operator">-</span><span class="token number">1.032206</span>    <span class="token number">1.707183</span>    <span class="token number">0.895205</span>B    <span class="token number">1.581206</span>   <span class="token operator">-</span><span class="token number">0.304325</span>    <span class="token number">1.214341</span>    <span class="token number">0.237051</span>    <span class="token number">0.382228</span>    <span class="token number">0.982582</span>C   <span class="token operator">-</span><span class="token number">0.499837</span>    <span class="token number">1.995154</span>   <span class="token operator">-</span><span class="token number">0.608446</span>    <span class="token number">1.502665</span>    <span class="token number">1.335121</span>    <span class="token number">0.188397</span>D   <span class="token operator">-</span><span class="token number">0.549320</span>   <span class="token operator">-</span><span class="token number">0.895727</span>   <span class="token operator">-</span><span class="token number">1.054553</span>   <span class="token operator">-</span><span class="token number">0.048824</span>   <span class="token operator">-</span><span class="token number">1.099418</span>    <span class="token number">0.023960</span></code></pre><ul><li>按索引排序<ul><li><code>DataFrame.sort_index(axis=0, level=None, ascending=True, inplace=False, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;, sort_remaining=True, ignore_index=False, key=None)</code></li><li>kind 可以取’mergesort’，以达到稳定的目的</li><li>axis 取 0 按行排序，取 1 按列排序</li></ul></li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df4 <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">,</span> <span class="token number">234</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                   columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> df4     A<span class="token number">100</span>  <span class="token number">1</span><span class="token number">29</span>   <span class="token number">2</span><span class="token number">234</span>  <span class="token number">3</span><span class="token number">1</span>    <span class="token number">4</span><span class="token number">150</span>  <span class="token number">5</span><span class="token operator">>></span><span class="token operator">></span> df4<span class="token punctuation">.</span>sort_index<span class="token punctuation">(</span><span class="token punctuation">)</span>     A<span class="token number">1</span>    <span class="token number">4</span><span class="token number">29</span>   <span class="token number">2</span><span class="token number">100</span>  <span class="token number">1</span><span class="token number">150</span>  <span class="token number">5</span><span class="token number">234</span>  <span class="token number">3</span><span class="token operator">>></span><span class="token operator">></span> df4 <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">,</span> <span class="token number">234</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">]</span><span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'B'</span><span class="token punctuation">,</span> <span class="token string">'A'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> df4     B   A<span class="token number">100</span>  <span class="token number">1</span>   <span class="token number">2</span><span class="token number">29</span>   <span class="token number">3</span>   <span class="token number">4</span><span class="token number">234</span>  <span class="token number">5</span>   <span class="token number">6</span><span class="token number">1</span>    <span class="token number">7</span>   <span class="token number">8</span><span class="token number">150</span>  <span class="token number">9</span>  <span class="token number">10</span><span class="token operator">>></span><span class="token operator">></span> df4<span class="token punctuation">.</span>sort_index<span class="token punctuation">(</span><span class="token punctuation">)</span>     B   A<span class="token number">1</span>    <span class="token number">7</span>   <span class="token number">8</span><span class="token number">29</span>   <span class="token number">3</span>   <span class="token number">4</span><span class="token number">100</span>  <span class="token number">1</span>   <span class="token number">2</span><span class="token number">150</span>  <span class="token number">9</span>  <span class="token number">10</span><span class="token number">234</span>  <span class="token number">5</span>   <span class="token number">6</span><span class="token operator">>></span><span class="token operator">></span> df4<span class="token punctuation">.</span>sort_index<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>      A  B<span class="token number">100</span>   <span class="token number">2</span>  <span class="token number">1</span><span class="token number">29</span>    <span class="token number">4</span>  <span class="token number">3</span><span class="token number">234</span>   <span class="token number">6</span>  <span class="token number">5</span><span class="token number">1</span>     <span class="token number">8</span>  <span class="token number">7</span><span class="token number">150</span>  <span class="token number">10</span>  <span class="token number">9</span></code></pre><ul><li>按某列排序<ul><li><code>DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;, ignore_index=False, key=None)</code></li><li>na_position 可以是 <code>first</code> 和 <code>last</code></li><li>如果 ignore_index 为真，那么结果的索引会从 0 标号至 n-1</li><li>key: 接受一个 Series 作为输出，返回一个 shape 相同的 Series，然后使用后者进行排序操作</li></ul></li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">'col1'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>nan<span class="token punctuation">,</span> <span class="token string">'D'</span><span class="token punctuation">,</span> <span class="token string">'C'</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">'col2'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">'col3'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">'col4'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'D'</span><span class="token punctuation">,</span> <span class="token string">'e'</span><span class="token punctuation">,</span> <span class="token string">'F'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> df  col1  col2  col3 col4<span class="token number">0</span>    A     <span class="token number">2</span>     <span class="token number">0</span>    a<span class="token number">1</span>    A     <span class="token number">1</span>     <span class="token number">1</span>    B<span class="token number">2</span>    B     <span class="token number">9</span>     <span class="token number">9</span>    c<span class="token number">3</span>  NaN     <span class="token number">8</span>     <span class="token number">4</span>    D<span class="token number">4</span>    D     <span class="token number">7</span>     <span class="token number">2</span>    e<span class="token number">5</span>    C     <span class="token number">4</span>     <span class="token number">3</span>    F<span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span>by<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'col1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  col1  col2  col3 col4<span class="token number">0</span>    A     <span class="token number">2</span>     <span class="token number">0</span>    a<span class="token number">1</span>    A     <span class="token number">1</span>     <span class="token number">1</span>    B<span class="token number">2</span>    B     <span class="token number">9</span>     <span class="token number">9</span>    c<span class="token number">5</span>    C     <span class="token number">4</span>     <span class="token number">3</span>    F<span class="token number">4</span>    D     <span class="token number">7</span>     <span class="token number">2</span>    e<span class="token number">3</span>  NaN     <span class="token number">8</span>     <span class="token number">4</span>    D<span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span>by<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'col1'</span><span class="token punctuation">,</span> <span class="token string">'col2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  col1  col2  col3 col4<span class="token number">1</span>    A     <span class="token number">1</span>     <span class="token number">1</span>    B<span class="token number">0</span>    A     <span class="token number">2</span>     <span class="token number">0</span>    a<span class="token number">2</span>    B     <span class="token number">9</span>     <span class="token number">9</span>    c<span class="token number">5</span>    C     <span class="token number">4</span>     <span class="token number">3</span>    F<span class="token number">4</span>    D     <span class="token number">7</span>     <span class="token number">2</span>    e<span class="token number">3</span>  NaN     <span class="token number">8</span>     <span class="token number">4</span>    Ddf<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span>by<span class="token operator">=</span><span class="token string">'col4'</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> col<span class="token punctuation">:</span> col<span class="token punctuation">.</span><span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  col1  col2  col3 col4<span class="token number">0</span>    A     <span class="token number">2</span>     <span class="token number">0</span>    a<span class="token number">1</span>    A     <span class="token number">1</span>     <span class="token number">1</span>    B<span class="token number">2</span>    B     <span class="token number">9</span>     <span class="token number">9</span>    c<span class="token number">3</span>  NaN     <span class="token number">8</span>     <span class="token number">4</span>    D<span class="token number">4</span>    D     <span class="token number">7</span>     <span class="token number">2</span>    e<span class="token number">5</span>    C     <span class="token number">4</span>     <span class="token number">3</span>    F</code></pre><h3 id="选择"><a href="#选择" class="headerlink" title="选择"></a>选择</h3><ul><li>获取单列：使用 <code>df.A</code> 或者 <code>df[&#39;A&#39;]</code></li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df                   A         B         C         D<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span> <span class="token operator">-</span><span class="token number">0.514649</span>  <span class="token number">2.198378</span> <span class="token operator">-</span><span class="token number">0.986735</span> <span class="token operator">-</span><span class="token number">0.368712</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span> <span class="token operator">-</span><span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span> <span class="token operator">-</span><span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span> <span class="token operator">-</span><span class="token number">0.167852</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.288924</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span> <span class="token operator">-</span><span class="token number">0.604422</span> <span class="token operator">-</span><span class="token number">0.483053</span>  <span class="token number">1.557318</span> <span class="token operator">-</span><span class="token number">0.158592</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>A<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>   <span class="token operator">-</span><span class="token number">0.514649</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>   <span class="token operator">-</span><span class="token number">2.059045</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>   <span class="token operator">-</span><span class="token number">1.398741</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>    <span class="token number">0.642856</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>    <span class="token number">0.288924</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>   <span class="token operator">-</span><span class="token number">0.604422</span>Freq<span class="token punctuation">:</span> D<span class="token punctuation">,</span> Name<span class="token punctuation">:</span> A<span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> float64            <span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">]</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>   <span class="token operator">-</span><span class="token number">0.514649</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>   <span class="token operator">-</span><span class="token number">2.059045</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>   <span class="token operator">-</span><span class="token number">1.398741</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>    <span class="token number">0.642856</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>    <span class="token number">0.288924</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>   <span class="token operator">-</span><span class="token number">0.604422</span>Freq<span class="token punctuation">:</span> D<span class="token punctuation">,</span> Name<span class="token punctuation">:</span> A<span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> float64</code></pre><ul><li>获取多行：使用 <code>[]</code> 做 Slice</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span>                   A         B         C         D<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span> <span class="token operator">-</span><span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span> <span class="token operator">-</span><span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span> <span class="token operator">-</span><span class="token number">0.167852</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">[</span><span class="token string">'20220102'</span><span class="token punctuation">:</span><span class="token punctuation">]</span>                   A         B         C         D<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span> <span class="token operator">-</span><span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span> <span class="token operator">-</span><span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span> <span class="token operator">-</span><span class="token number">0.167852</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.288924</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span> <span class="token operator">-</span><span class="token number">0.604422</span> <span class="token operator">-</span><span class="token number">0.483053</span>  <span class="token number">1.557318</span> <span class="token operator">-</span><span class="token number">0.158592</span></code></pre><ul><li>按标签索引：使用 <code>.loc[]</code></li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span> <span class="token punctuation">:</span> <span class="token punctuation">,</span> <span class="token punctuation">:</span> <span class="token punctuation">]</span>                   A         B         C         D<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span> <span class="token operator">-</span><span class="token number">0.514649</span>  <span class="token number">2.198378</span> <span class="token operator">-</span><span class="token number">0.986735</span> <span class="token operator">-</span><span class="token number">0.368712</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span> <span class="token operator">-</span><span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span> <span class="token operator">-</span><span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span> <span class="token operator">-</span><span class="token number">0.167852</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.288924</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span> <span class="token operator">-</span><span class="token number">0.604422</span> <span class="token operator">-</span><span class="token number">0.483053</span>  <span class="token number">1.557318</span> <span class="token operator">-</span><span class="token number">0.158592</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span> <span class="token string">'20220101'</span> <span class="token punctuation">,</span> <span class="token punctuation">:</span> <span class="token punctuation">]</span>A   <span class="token operator">-</span><span class="token number">0.514649</span>B    <span class="token number">2.198378</span>C   <span class="token operator">-</span><span class="token number">0.986735</span>D   <span class="token operator">-</span><span class="token number">0.368712</span>Name<span class="token punctuation">:</span> <span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span> <span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> float64<span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span> <span class="token string">'20220101'</span> <span class="token punctuation">,</span> <span class="token string">'C'</span> <span class="token punctuation">]</span><span class="token operator">-</span><span class="token number">0.9867347785391464</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span> <span class="token string">'20220101'</span> <span class="token punctuation">:</span> <span class="token string">'20220104'</span> <span class="token punctuation">,</span> <span class="token string">'C'</span> <span class="token punctuation">]</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>   <span class="token operator">-</span><span class="token number">0.986735</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>    <span class="token number">0.607552</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>    <span class="token number">1.459097</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>    <span class="token number">0.378368</span>Freq<span class="token punctuation">:</span> D<span class="token punctuation">,</span> Name<span class="token punctuation">:</span> C<span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> float64<span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span> <span class="token string">'20220101'</span> <span class="token punctuation">:</span> <span class="token string">'20220104'</span> <span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">,</span> <span class="token string">'D'</span><span class="token punctuation">]</span> <span class="token punctuation">]</span>                   C         B         B         D<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span> <span class="token operator">-</span><span class="token number">0.986735</span>  <span class="token number">2.198378</span>  <span class="token number">2.198378</span> <span class="token operator">-</span><span class="token number">0.368712</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">0.607552</span>  <span class="token number">1.715020</span>  <span class="token number">1.715020</span>  <span class="token number">1.145638</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">1.459097</span>  <span class="token number">1.538408</span>  <span class="token number">1.538408</span>  <span class="token number">0.491077</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.378368</span>  <span class="token number">0.670310</span>  <span class="token number">0.670310</span> <span class="token operator">-</span><span class="token number">0.167852</span></code></pre><ul><li>按整数索引</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span> <span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token punctuation">]</span>                   C         B         B         D<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">0.607552</span>  <span class="token number">1.715020</span>  <span class="token number">1.715020</span>  <span class="token number">1.145638</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">1.459097</span>  <span class="token number">1.538408</span>  <span class="token number">1.538408</span>  <span class="token number">0.491077</span></code></pre><ul><li>Bool 索引</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>B<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>    <span class="token number">2.198378</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>    <span class="token number">1.715020</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>    <span class="token number">1.538408</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>    <span class="token number">0.670310</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>    <span class="token number">1.131819</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>   <span class="token operator">-</span><span class="token number">0.483053</span>Freq<span class="token punctuation">:</span> D<span class="token punctuation">,</span> Name<span class="token punctuation">:</span> B<span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> float64            <span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>B <span class="token operator">></span> <span class="token number">1</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>     <span class="token boolean">True</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>     <span class="token boolean">True</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>     <span class="token boolean">True</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>    <span class="token boolean">False</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>     <span class="token boolean">True</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>    <span class="token boolean">False</span>Freq<span class="token punctuation">:</span> D<span class="token punctuation">,</span> Name<span class="token punctuation">:</span> B<span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> <span class="token builtin">bool</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>df<span class="token punctuation">.</span>B <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">]</span>                   A         B         C         D<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span> <span class="token operator">-</span><span class="token number">0.514649</span>  <span class="token number">2.198378</span> <span class="token operator">-</span><span class="token number">0.986735</span> <span class="token operator">-</span><span class="token number">0.368712</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span> <span class="token operator">-</span><span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span> <span class="token operator">-</span><span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.288924</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span></code></pre><ul><li>用 <code>isin()</code>  筛选</li></ul><pre class="language-python" data-language="python"><code class="language-python">In <span class="token punctuation">[</span><span class="token number">41</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df2 <span class="token operator">=</span> df<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>In <span class="token punctuation">[</span><span class="token number">42</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df2<span class="token punctuation">[</span><span class="token string">'E'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'one'</span><span class="token punctuation">,</span> <span class="token string">'one'</span><span class="token punctuation">,</span> <span class="token string">'two'</span><span class="token punctuation">,</span> <span class="token string">'three'</span><span class="token punctuation">,</span> <span class="token string">'four'</span><span class="token punctuation">,</span> <span class="token string">'three'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df2Out<span class="token punctuation">[</span><span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    A         B         C         D      E<span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>  <span class="token number">0.469112</span> <span class="token operator">-</span><span class="token number">0.282863</span> <span class="token operator">-</span><span class="token number">1.509059</span> <span class="token operator">-</span><span class="token number">1.135632</span>    one<span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">1.212112</span> <span class="token operator">-</span><span class="token number">0.173215</span>  <span class="token number">0.119209</span> <span class="token operator">-</span><span class="token number">1.044236</span>    one<span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span> <span class="token operator">-</span><span class="token number">0.861849</span> <span class="token operator">-</span><span class="token number">2.104569</span> <span class="token operator">-</span><span class="token number">0.494929</span>  <span class="token number">1.071804</span>    two<span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.721555</span> <span class="token operator">-</span><span class="token number">0.706771</span> <span class="token operator">-</span><span class="token number">1.039575</span>  <span class="token number">0.271860</span>  three<span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span> <span class="token operator">-</span><span class="token number">0.424972</span>  <span class="token number">0.567020</span>  <span class="token number">0.276232</span> <span class="token operator">-</span><span class="token number">1.087401</span>   four<span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span> <span class="token operator">-</span><span class="token number">0.673690</span>  <span class="token number">0.113648</span> <span class="token operator">-</span><span class="token number">1.478427</span>  <span class="token number">0.524988</span>  threeIn <span class="token punctuation">[</span><span class="token number">44</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df2<span class="token punctuation">[</span>df2<span class="token punctuation">[</span><span class="token string">'E'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isin<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'two'</span><span class="token punctuation">,</span> <span class="token string">'four'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">44</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    A         B         C         D     E<span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span> <span class="token operator">-</span><span class="token number">0.861849</span> <span class="token operator">-</span><span class="token number">2.104569</span> <span class="token operator">-</span><span class="token number">0.494929</span>  <span class="token number">1.071804</span>   two<span class="token number">2013</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span> <span class="token operator">-</span><span class="token number">0.424972</span>  <span class="token number">0.567020</span>  <span class="token number">0.276232</span> <span class="token operator">-</span><span class="token number">1.087401</span>  four</code></pre><ul><li>赋值</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">[</span><span class="token string">'E'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token operator">>></span><span class="token operator">></span> df                   A         B         C         D  E<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span> <span class="token operator">-</span><span class="token number">0.514649</span>  <span class="token number">2.198378</span> <span class="token operator">-</span><span class="token number">0.986735</span> <span class="token operator">-</span><span class="token number">0.368712</span>  <span class="token number">1</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span> <span class="token operator">-</span><span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span>  <span class="token number">2</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span> <span class="token operator">-</span><span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span> <span class="token operator">-</span><span class="token number">0.167852</span>  <span class="token number">4</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.288924</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span> <span class="token operator">-</span><span class="token number">0.604422</span> <span class="token operator">-</span><span class="token number">0.483053</span>  <span class="token number">1.557318</span> <span class="token operator">-</span><span class="token number">0.158592</span>  <span class="token number">4</span><span class="token operator">>></span><span class="token operator">></span> s <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">,</span> index<span class="token operator">=</span>pd<span class="token punctuation">.</span>date_range<span class="token punctuation">(</span><span class="token string">'20220103'</span><span class="token punctuation">,</span> periods<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> s<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>    <span class="token number">6</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>    <span class="token number">5</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>    <span class="token number">4</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>    <span class="token number">3</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">07</span>    <span class="token number">2</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">08</span>    <span class="token number">1</span>Freq<span class="token punctuation">:</span> D<span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> int64        <span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>F <span class="token operator">=</span> s<span class="token operator">>></span><span class="token operator">></span> df                   A         B         C         D  E<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span> <span class="token operator">-</span><span class="token number">0.514649</span>  <span class="token number">2.198378</span> <span class="token operator">-</span><span class="token number">0.986735</span> <span class="token operator">-</span><span class="token number">0.368712</span>  <span class="token number">1</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span> <span class="token operator">-</span><span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span>  <span class="token number">2</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span> <span class="token operator">-</span><span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span> <span class="token operator">-</span><span class="token number">0.167852</span>  <span class="token number">4</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.288924</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span> <span class="token operator">-</span><span class="token number">0.604422</span> <span class="token operator">-</span><span class="token number">0.483053</span>  <span class="token number">1.557318</span> <span class="token operator">-</span><span class="token number">0.158592</span>  <span class="token number">4</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">[</span><span class="token string">'F'</span><span class="token punctuation">]</span> <span class="token operator">=</span> s<span class="token operator">>></span><span class="token operator">></span> df                   A         B         C         D  E    F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span> <span class="token operator">-</span><span class="token number">0.514649</span>  <span class="token number">2.198378</span> <span class="token operator">-</span><span class="token number">0.986735</span> <span class="token operator">-</span><span class="token number">0.368712</span>  <span class="token number">1</span>  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span> <span class="token operator">-</span><span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span>  <span class="token number">2</span>  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span> <span class="token operator">-</span><span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span>  <span class="token number">6.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span> <span class="token operator">-</span><span class="token number">0.167852</span>  <span class="token number">4</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.288924</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span>  <span class="token number">4.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span> <span class="token operator">-</span><span class="token number">0.604422</span> <span class="token operator">-</span><span class="token number">0.483053</span>  <span class="token number">1.557318</span> <span class="token operator">-</span><span class="token number">0.158592</span>  <span class="token number">4</span>  <span class="token number">3.0</span></code></pre><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>at<span class="token punctuation">[</span><span class="token string">'20220105'</span><span class="token punctuation">,</span> <span class="token string">'A'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">114514</span><span class="token operator">>></span><span class="token operator">></span> df                        A         B         C         D  E    F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>      <span class="token operator">-</span><span class="token number">0.514649</span>  <span class="token number">2.198378</span> <span class="token operator">-</span><span class="token number">0.986735</span> <span class="token operator">-</span><span class="token number">0.368712</span>  <span class="token number">1</span>  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>      <span class="token operator">-</span><span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span>  <span class="token number">2</span>  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>      <span class="token operator">-</span><span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span>  <span class="token number">6.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>       <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span> <span class="token operator">-</span><span class="token number">0.167852</span>  <span class="token number">4</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">114514.000000</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span>  <span class="token number">4.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>      <span class="token operator">-</span><span class="token number">0.604422</span> <span class="token operator">-</span><span class="token number">0.483053</span>  <span class="token number">1.557318</span> <span class="token operator">-</span><span class="token number">0.158592</span>  <span class="token number">4</span>  <span class="token number">3.0</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>at<span class="token punctuation">[</span><span class="token string">'20220105'</span><span class="token punctuation">,</span> <span class="token string">'A'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">114514</span><span class="token operator">>></span><span class="token operator">></span> df                        A         B         C         D  E    F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>      <span class="token operator">-</span><span class="token number">0.514649</span>  <span class="token number">2.198378</span> <span class="token operator">-</span><span class="token number">0.986735</span> <span class="token operator">-</span><span class="token number">0.368712</span>  <span class="token number">1</span>  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>      <span class="token operator">-</span><span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span>  <span class="token number">2</span>  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>      <span class="token operator">-</span><span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span>  <span class="token number">6.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>       <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span> <span class="token operator">-</span><span class="token number">0.167852</span>  <span class="token number">4</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">114514.000000</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span>  <span class="token number">4.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>      <span class="token operator">-</span><span class="token number">0.604422</span> <span class="token operator">-</span><span class="token number">0.483053</span>  <span class="token number">1.557318</span> <span class="token operator">-</span><span class="token number">0.158592</span>  <span class="token number">4</span>  <span class="token number">3.0</span></code></pre><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df                   A         B         C         D  E    F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span> <span class="token operator">-</span><span class="token number">0.514649</span>  <span class="token number">2.198378</span> <span class="token operator">-</span><span class="token number">0.986735</span> <span class="token operator">-</span><span class="token number">0.368712</span>  <span class="token number">1</span>  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span> <span class="token operator">-</span><span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span>  <span class="token number">2</span>  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span> <span class="token operator">-</span><span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span>  <span class="token number">6.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span> <span class="token operator">-</span><span class="token number">0.167852</span>  <span class="token number">4</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span> <span class="token operator">-</span><span class="token number">0.012000</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span>  <span class="token number">4.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span> <span class="token operator">-</span><span class="token number">0.604422</span> <span class="token operator">-</span><span class="token number">0.483053</span>  <span class="token number">1.557318</span> <span class="token operator">-</span><span class="token number">0.158592</span>  <span class="token number">4</span>  <span class="token number">3.0</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">[</span>df <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">]</span>                   A         B         C         D   E   F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span> <span class="token operator">-</span><span class="token number">0.514649</span>       NaN <span class="token operator">-</span><span class="token number">0.986735</span> <span class="token operator">-</span><span class="token number">0.368712</span> NaN NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span> <span class="token operator">-</span><span class="token number">2.059045</span>       NaN       NaN       NaN NaN NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span> <span class="token operator">-</span><span class="token number">1.398741</span>       NaN       NaN       NaN NaN NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>       NaN       NaN       NaN <span class="token operator">-</span><span class="token number">0.167852</span> NaN NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span> <span class="token operator">-</span><span class="token number">0.012000</span>       NaN       NaN       NaN NaN NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span> <span class="token operator">-</span><span class="token number">0.604422</span> <span class="token operator">-</span><span class="token number">0.483053</span>       NaN <span class="token operator">-</span><span class="token number">0.158592</span> NaN NaN<span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">[</span>df <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span>df<span class="token operator">>></span><span class="token operator">></span> df                   A         B         C         D  E    F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>  <span class="token number">0.514649</span>  <span class="token number">2.198378</span>  <span class="token number">0.986735</span>  <span class="token number">0.368712</span>  <span class="token number">1</span>  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span>  <span class="token number">2</span>  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span>  <span class="token number">6.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span>  <span class="token number">0.167852</span>  <span class="token number">4</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.012000</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span>  <span class="token number">4.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>  <span class="token number">0.604422</span>  <span class="token number">0.483053</span>  <span class="token number">1.557318</span>  <span class="token number">0.158592</span>  <span class="token number">4</span>  <span class="token number">3.0</span></code></pre><h3 id="缺失值"><a href="#缺失值" class="headerlink" title="缺失值"></a>缺失值</h3><ul><li>删除带有缺省值的行</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df1 <span class="token operator">=</span> df<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> df1                   A         B         C         D  E    F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>  <span class="token number">0.514649</span>  <span class="token number">2.198378</span>  <span class="token number">0.986735</span>  <span class="token number">0.368712</span>  <span class="token number">1</span>  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span>  <span class="token number">2</span>  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span>  <span class="token number">6.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span>  <span class="token number">0.167852</span>  <span class="token number">4</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.012000</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span>  <span class="token number">4.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>  <span class="token number">0.604422</span>  <span class="token number">0.483053</span>  <span class="token number">1.557318</span>  <span class="token number">0.158592</span>  <span class="token number">4</span>  <span class="token number">3.0</span><span class="token operator">>></span><span class="token operator">></span> df1<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>how<span class="token operator">=</span><span class="token string">'any'</span><span class="token punctuation">)</span>                   A         B         C         D  E    F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span>  <span class="token number">6.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span>  <span class="token number">0.167852</span>  <span class="token number">4</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.012000</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span>  <span class="token number">4.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>  <span class="token number">0.604422</span>  <span class="token number">0.483053</span>  <span class="token number">1.557318</span>  <span class="token number">0.158592</span>  <span class="token number">4</span>  <span class="token number">3.0</span><span class="token operator">>></span><span class="token operator">></span> df1                   A         B         C         D  E    F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>  <span class="token number">0.514649</span>  <span class="token number">2.198378</span>  <span class="token number">0.986735</span>  <span class="token number">0.368712</span>  <span class="token number">1</span>  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span>  <span class="token number">2</span>  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span>  <span class="token number">6.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span>  <span class="token number">0.167852</span>  <span class="token number">4</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.012000</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span>  <span class="token number">4.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>  <span class="token number">0.604422</span>  <span class="token number">0.483053</span>  <span class="token number">1.557318</span>  <span class="token number">0.158592</span>  <span class="token number">4</span>  <span class="token number">3.0</span></code></pre><ul><li>填充缺省值</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df1<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>value<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>                   A         B         C         D  E    F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>  <span class="token number">0.514649</span>  <span class="token number">2.198378</span>  <span class="token number">0.986735</span>  <span class="token number">0.368712</span>  <span class="token number">1</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token number">2.059045</span>  <span class="token number">1.715020</span>  <span class="token number">0.607552</span>  <span class="token number">1.145638</span>  <span class="token number">2</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span>  <span class="token number">6.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span>  <span class="token number">0.167852</span>  <span class="token number">4</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.012000</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span>  <span class="token number">4.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>  <span class="token number">0.604422</span>  <span class="token number">0.483053</span>  <span class="token number">1.557318</span>  <span class="token number">0.158592</span>  <span class="token number">4</span>  <span class="token number">3.0</span></code></pre><ul><li>获取是否为 Nan</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> pd<span class="token punctuation">.</span>isna<span class="token punctuation">(</span>df1<span class="token punctuation">)</span>                A      B      C      D      E      F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>   <span class="token boolean">True</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>   <span class="token boolean">True</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span>  <span class="token boolean">False</span></code></pre><h3 id="运算"><a href="#运算" class="headerlink" title="运算"></a>运算</h3><p>Pandas 默认用 <code>np.nan</code> 表示缺失数据。下列计算时，默认不包含缺失值。</p><ul><li>求平均值</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df <span class="token operator">=</span> df1<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>how<span class="token operator">=</span><span class="token string">'any'</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> df                   A         B         C         D  E    F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span>  <span class="token number">6.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span>  <span class="token number">0.167852</span>  <span class="token number">4</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.012000</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span>  <span class="token number">4.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>  <span class="token number">0.604422</span>  <span class="token number">0.483053</span>  <span class="token number">1.557318</span>  <span class="token number">0.158592</span>  <span class="token number">4</span>  <span class="token number">3.0</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>A    <span class="token number">0.664505</span>B    <span class="token number">0.955897</span>C    <span class="token number">0.981879</span>D    <span class="token number">0.427724</span>E    <span class="token number">3.750000</span>F    <span class="token number">4.500000</span>dtype<span class="token punctuation">:</span> float64    <span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>    <span class="token number">2.314554</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>    <span class="token number">1.809898</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>    <span class="token number">1.761655</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>    <span class="token number">1.633897</span>Freq<span class="token punctuation">:</span> D<span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> float64</code></pre><ul><li>作差</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df                   A         B         C         D  E    F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span>  <span class="token number">6.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span>  <span class="token number">0.167852</span>  <span class="token number">4</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.012000</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span>  <span class="token number">4.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>  <span class="token number">0.604422</span>  <span class="token number">0.483053</span>  <span class="token number">1.557318</span>  <span class="token number">0.158592</span>  <span class="token number">4</span>  <span class="token number">3.0</span><span class="token operator">>></span><span class="token operator">></span> s<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>    <span class="token number">6</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>    <span class="token number">5</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>    <span class="token number">4</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>    <span class="token number">3</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">07</span>    <span class="token number">2</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">08</span>    <span class="token number">1</span>Freq<span class="token punctuation">:</span> D<span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> int64        <span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>s<span class="token punctuation">)</span>            <span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span> <span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span>  <span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span> <span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>   E   F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>                  NaN                  NaN  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> NaN NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>                  NaN                  NaN  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> NaN NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>                  NaN                  NaN  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> NaN NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>                  NaN                  NaN  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> NaN NaN<span class="token punctuation">[</span><span class="token number">4</span> rows x <span class="token number">12</span> columns<span class="token punctuation">]</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>s<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token string">'index'</span><span class="token punctuation">)</span>                   A         B         C         D    E    F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span> <span class="token operator">-</span><span class="token number">4.601259</span> <span class="token operator">-</span><span class="token number">4.461592</span> <span class="token operator">-</span><span class="token number">4.540903</span> <span class="token operator">-</span><span class="token number">5.508923</span> <span class="token operator">-</span><span class="token number">3.0</span>  <span class="token number">0.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span> <span class="token operator">-</span><span class="token number">4.357144</span> <span class="token operator">-</span><span class="token number">4.329690</span> <span class="token operator">-</span><span class="token number">4.621632</span> <span class="token operator">-</span><span class="token number">4.832148</span> <span class="token operator">-</span><span class="token number">1.0</span>  <span class="token number">0.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span> <span class="token operator">-</span><span class="token number">3.988000</span> <span class="token operator">-</span><span class="token number">2.868181</span> <span class="token operator">-</span><span class="token number">3.467266</span> <span class="token operator">-</span><span class="token number">3.106626</span>  <span class="token number">0.0</span>  <span class="token number">0.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span> <span class="token operator">-</span><span class="token number">2.395578</span> <span class="token operator">-</span><span class="token number">2.516947</span> <span class="token operator">-</span><span class="token number">1.442682</span> <span class="token operator">-</span><span class="token number">2.841408</span>  <span class="token number">1.0</span>  <span class="token number">0.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">07</span>       NaN       NaN       NaN       NaN  NaN  NaN<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">08</span>       NaN       NaN       NaN       NaN  NaN  NaN</code></pre><ul><li>Apply 函数</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df                   A         B         C         D  E    F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span>  <span class="token number">6.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span>  <span class="token number">0.167852</span>  <span class="token number">4</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.012000</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span>  <span class="token number">4.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>  <span class="token number">0.604422</span>  <span class="token number">0.483053</span>  <span class="token number">1.557318</span>  <span class="token number">0.158592</span>  <span class="token number">4</span>  <span class="token number">3.0</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>cumsum<span class="token punctuation">)</span>                   A         B         C         D   E     F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>   <span class="token number">3</span>   <span class="token number">6.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">2.041597</span>  <span class="token number">2.208717</span>  <span class="token number">1.837465</span>  <span class="token number">0.658930</span>   <span class="token number">7</span>  <span class="token number">11.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">2.053597</span>  <span class="token number">3.340537</span>  <span class="token number">2.370199</span>  <span class="token number">1.552304</span>  <span class="token number">11</span>  <span class="token number">15.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>  <span class="token number">2.658018</span>  <span class="token number">3.823590</span>  <span class="token number">3.927517</span>  <span class="token number">1.710896</span>  <span class="token number">15</span>  <span class="token number">18.0</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> x<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>A    <span class="token number">1.386741</span>B    <span class="token number">1.055355</span>C    <span class="token number">1.178950</span>D    <span class="token number">0.734782</span>E    <span class="token number">1.000000</span>F    <span class="token number">3.000000</span>dtype<span class="token punctuation">:</span> float64</code></pre><ul><li>Series 的频数统计</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df                   A         B         C         D  E    F<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>  <span class="token number">1.398741</span>  <span class="token number">1.538408</span>  <span class="token number">1.459097</span>  <span class="token number">0.491077</span>  <span class="token number">3</span>  <span class="token number">6.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>  <span class="token number">0.642856</span>  <span class="token number">0.670310</span>  <span class="token number">0.378368</span>  <span class="token number">0.167852</span>  <span class="token number">4</span>  <span class="token number">5.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>  <span class="token number">0.012000</span>  <span class="token number">1.131819</span>  <span class="token number">0.532734</span>  <span class="token number">0.893374</span>  <span class="token number">4</span>  <span class="token number">4.0</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>  <span class="token number">0.604422</span>  <span class="token number">0.483053</span>  <span class="token number">1.557318</span>  <span class="token number">0.158592</span>  <span class="token number">4</span>  <span class="token number">3.0</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>E<span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">03</span>    <span class="token number">3</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>    <span class="token number">4</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>    <span class="token number">4</span><span class="token number">2022</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">06</span>    <span class="token number">4</span>Freq<span class="token punctuation">:</span> D<span class="token punctuation">,</span> Name<span class="token punctuation">:</span> E<span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> int64            <span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>E<span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token number">4</span>    <span class="token number">3</span><span class="token number">3</span>    <span class="token number">1</span>Name<span class="token punctuation">:</span> E<span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> int64</code></pre><h3 id="合并-Merge"><a href="#合并-Merge" class="headerlink" title="合并 Merge"></a>合并 Merge</h3><h4 id="Concat"><a href="#Concat" class="headerlink" title="Concat"></a>Concat</h4><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> df1 <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token operator">>></span><span class="token operator">></span> df2 <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">>></span><span class="token operator">></span> df          <span class="token number">0</span>         <span class="token number">1</span>         <span class="token number">2</span>         <span class="token number">3</span><span class="token number">0</span> <span class="token operator">-</span><span class="token number">0.453289</span>  <span class="token number">0.892104</span>  <span class="token number">1.891981</span>  <span class="token number">0.485892</span><span class="token number">1</span> <span class="token operator">-</span><span class="token number">2.703414</span> <span class="token operator">-</span><span class="token number">0.685189</span> <span class="token operator">-</span><span class="token number">0.903685</span> <span class="token operator">-</span><span class="token number">0.137809</span><span class="token number">2</span>  <span class="token number">0.500884</span>  <span class="token number">0.831745</span> <span class="token operator">-</span><span class="token number">0.757333</span>  <span class="token number">1.997601</span><span class="token number">3</span>  <span class="token number">0.939272</span>  <span class="token number">1.907135</span> <span class="token operator">-</span><span class="token number">0.528942</span> <span class="token operator">-</span><span class="token number">0.724512</span><span class="token number">4</span>  <span class="token number">0.796412</span>  <span class="token number">0.958696</span>  <span class="token number">1.352733</span>  <span class="token number">1.805198</span><span class="token number">5</span> <span class="token operator">-</span><span class="token number">1.141725</span>  <span class="token number">1.591892</span> <span class="token operator">-</span><span class="token number">0.171487</span> <span class="token operator">-</span><span class="token number">0.289578</span><span class="token number">6</span>  <span class="token number">0.155887</span> <span class="token operator">-</span><span class="token number">0.646798</span>  <span class="token number">1.151169</span>  <span class="token number">1.051582</span><span class="token number">7</span> <span class="token operator">-</span><span class="token number">0.917709</span> <span class="token operator">-</span><span class="token number">0.156452</span>  <span class="token number">0.578088</span>  <span class="token number">0.639791</span><span class="token number">8</span>  <span class="token number">0.570383</span> <span class="token operator">-</span><span class="token number">0.513202</span>  <span class="token number">0.891358</span> <span class="token operator">-</span><span class="token number">0.567285</span><span class="token number">9</span>  <span class="token number">1.858860</span>  <span class="token number">1.628878</span> <span class="token operator">-</span><span class="token number">1.269917</span> <span class="token operator">-</span><span class="token number">0.396636</span><span class="token operator">>></span><span class="token operator">></span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df1<span class="token punctuation">,</span> df2<span class="token punctuation">]</span><span class="token punctuation">)</span>          <span class="token number">0</span>         <span class="token number">1</span>         <span class="token number">2</span>         <span class="token number">3</span><span class="token number">0</span> <span class="token operator">-</span><span class="token number">0.453289</span>  <span class="token number">0.892104</span>  <span class="token number">1.891981</span>  <span class="token number">0.485892</span><span class="token number">1</span> <span class="token operator">-</span><span class="token number">2.703414</span> <span class="token operator">-</span><span class="token number">0.685189</span> <span class="token operator">-</span><span class="token number">0.903685</span> <span class="token operator">-</span><span class="token number">0.137809</span><span class="token number">2</span>  <span class="token number">0.500884</span>  <span class="token number">0.831745</span> <span class="token operator">-</span><span class="token number">0.757333</span>  <span class="token number">1.997601</span><span class="token number">7</span> <span class="token operator">-</span><span class="token number">0.917709</span> <span class="token operator">-</span><span class="token number">0.156452</span>  <span class="token number">0.578088</span>  <span class="token number">0.639791</span><span class="token number">8</span>  <span class="token number">0.570383</span> <span class="token operator">-</span><span class="token number">0.513202</span>  <span class="token number">0.891358</span> <span class="token operator">-</span><span class="token number">0.567285</span><span class="token number">9</span>  <span class="token number">1.858860</span>  <span class="token number">1.628878</span> <span class="token operator">-</span><span class="token number">1.269917</span> <span class="token operator">-</span><span class="token number">0.396636</span></code></pre><h4 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h4><p>SQL 风格的合并。</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> left <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">'key'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'lval'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> right <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">'key'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'rval'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> left   key  lval<span class="token number">0</span>  foo     <span class="token number">1</span><span class="token number">1</span>  foo     <span class="token number">2</span><span class="token operator">>></span><span class="token operator">></span> right   key  rval<span class="token number">0</span>  foo     <span class="token number">4</span><span class="token number">1</span>  foo     <span class="token number">5</span><span class="token operator">>></span><span class="token operator">></span> pd<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>left<span class="token punctuation">,</span> right<span class="token punctuation">,</span> on<span class="token operator">=</span><span class="token string">'key'</span><span class="token punctuation">)</span>   key  lval  rval<span class="token number">0</span>  foo     <span class="token number">1</span>     <span class="token number">4</span><span class="token number">1</span>  foo     <span class="token number">1</span>     <span class="token number">5</span><span class="token number">2</span>  foo     <span class="token number">2</span>     <span class="token number">4</span><span class="token number">3</span>  foo     <span class="token number">2</span>     <span class="token number">5</span></code></pre><h4 id="追加-Append"><a href="#追加-Append" class="headerlink" title="追加 Append"></a>追加 Append</h4><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">,</span> <span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token string">'D'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> s <span class="token operator">=</span> df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token operator">>></span><span class="token operator">></span> df          A         B         C         D<span class="token number">0</span> <span class="token operator">-</span><span class="token number">0.019536</span>  <span class="token number">1.644399</span>  <span class="token number">1.250679</span>  <span class="token number">0.140385</span><span class="token number">1</span>  <span class="token number">0.770806</span>  <span class="token number">1.496631</span>  <span class="token number">0.216141</span>  <span class="token number">0.265806</span><span class="token number">2</span>  <span class="token number">1.166252</span>  <span class="token number">0.415610</span> <span class="token operator">-</span><span class="token number">1.166003</span>  <span class="token number">1.359695</span><span class="token number">3</span> <span class="token operator">-</span><span class="token number">0.360562</span>  <span class="token number">0.463504</span>  <span class="token number">0.507450</span> <span class="token operator">-</span><span class="token number">0.651677</span><span class="token number">4</span> <span class="token operator">-</span><span class="token number">0.459843</span> <span class="token operator">-</span><span class="token number">2.204788</span>  <span class="token number">1.381087</span> <span class="token operator">-</span><span class="token number">0.988501</span><span class="token number">5</span>  <span class="token number">0.505702</span> <span class="token operator">-</span><span class="token number">0.213073</span> <span class="token operator">-</span><span class="token number">1.264545</span>  <span class="token number">1.884786</span><span class="token number">6</span> <span class="token operator">-</span><span class="token number">0.955691</span>  <span class="token number">0.130868</span> <span class="token operator">-</span><span class="token number">0.722569</span> <span class="token operator">-</span><span class="token number">0.514278</span><span class="token number">7</span>  <span class="token number">0.768887</span>  <span class="token number">0.195819</span> <span class="token operator">-</span><span class="token number">0.997779</span> <span class="token operator">-</span><span class="token number">0.707758</span><span class="token operator">>></span><span class="token operator">></span> sA    <span class="token number">0.505702</span>B   <span class="token operator">-</span><span class="token number">0.213073</span>C   <span class="token operator">-</span><span class="token number">1.264545</span>D    <span class="token number">1.884786</span>Name<span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> float64        <span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>append<span class="token punctuation">(</span>s<span class="token punctuation">,</span> ignore_index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>          A         B         C         D<span class="token number">0</span> <span class="token operator">-</span><span class="token number">0.019536</span>  <span class="token number">1.644399</span>  <span class="token number">1.250679</span>  <span class="token number">0.140385</span><span class="token number">1</span>  <span class="token number">0.770806</span>  <span class="token number">1.496631</span>  <span class="token number">0.216141</span>  <span class="token number">0.265806</span><span class="token number">2</span>  <span class="token number">1.166252</span>  <span class="token number">0.415610</span> <span class="token operator">-</span><span class="token number">1.166003</span>  <span class="token number">1.359695</span><span class="token number">3</span> <span class="token operator">-</span><span class="token number">0.360562</span>  <span class="token number">0.463504</span>  <span class="token number">0.507450</span> <span class="token operator">-</span><span class="token number">0.651677</span><span class="token number">4</span> <span class="token operator">-</span><span class="token number">0.459843</span> <span class="token operator">-</span><span class="token number">2.204788</span>  <span class="token number">1.381087</span> <span class="token operator">-</span><span class="token number">0.988501</span><span class="token number">5</span>  <span class="token number">0.505702</span> <span class="token operator">-</span><span class="token number">0.213073</span> <span class="token operator">-</span><span class="token number">1.264545</span>  <span class="token number">1.884786</span><span class="token number">6</span> <span class="token operator">-</span><span class="token number">0.955691</span>  <span class="token number">0.130868</span> <span class="token operator">-</span><span class="token number">0.722569</span> <span class="token operator">-</span><span class="token number">0.514278</span><span class="token number">7</span>  <span class="token number">0.768887</span>  <span class="token number">0.195819</span> <span class="token operator">-</span><span class="token number">0.997779</span> <span class="token operator">-</span><span class="token number">0.707758</span><span class="token number">8</span>  <span class="token number">0.505702</span> <span class="token operator">-</span><span class="token number">0.213073</span> <span class="token operator">-</span><span class="token number">1.264545</span>  <span class="token number">1.884786</span></code></pre><h3 id="分组-Grouping"><a href="#分组-Grouping" class="headerlink" title="分组 Grouping"></a>分组 Grouping</h3><p>“group by” 指的是涵盖下列一项或多项步骤的处理流程：</p><ul><li><strong>分割</strong>：按条件把数据分割成多组；</li><li><strong>应用</strong>：为每组单独应用函数；</li><li><strong>组合</strong>：将处理结果组合成一个数据结构。</li></ul><pre class="language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> df          A         B         C         D  E<span class="token number">0</span> <span class="token operator">-</span><span class="token number">0.019536</span>  <span class="token number">1.644399</span>  <span class="token number">1.250679</span>  <span class="token number">0.140385</span>  <span class="token number">1</span><span class="token number">1</span>  <span class="token number">0.770806</span>  <span class="token number">1.496631</span>  <span class="token number">0.216141</span>  <span class="token number">0.265806</span>  <span class="token number">1</span><span class="token number">2</span>  <span class="token number">1.166252</span>  <span class="token number">0.415610</span> <span class="token operator">-</span><span class="token number">1.166003</span>  <span class="token number">1.359695</span>  <span class="token number">1</span><span class="token number">3</span> <span class="token operator">-</span><span class="token number">0.360562</span>  <span class="token number">0.463504</span>  <span class="token number">0.507450</span> <span class="token operator">-</span><span class="token number">0.651677</span>  <span class="token number">3</span><span class="token number">4</span> <span class="token operator">-</span><span class="token number">0.459843</span> <span class="token operator">-</span><span class="token number">2.204788</span>  <span class="token number">1.381087</span> <span class="token operator">-</span><span class="token number">0.988501</span>  <span class="token number">4</span><span class="token number">5</span>  <span class="token number">0.505702</span> <span class="token operator">-</span><span class="token number">0.213073</span> <span class="token operator">-</span><span class="token number">1.264545</span>  <span class="token number">1.884786</span>  <span class="token number">3</span><span class="token number">6</span> <span class="token operator">-</span><span class="token number">0.955691</span>  <span class="token number">0.130868</span> <span class="token operator">-</span><span class="token number">0.722569</span> <span class="token operator">-</span><span class="token number">0.514278</span>  <span class="token number">2</span><span class="token number">7</span>  <span class="token number">0.768887</span>  <span class="token number">0.195819</span> <span class="token operator">-</span><span class="token number">0.997779</span> <span class="token operator">-</span><span class="token number">0.707758</span>  <span class="token number">2</span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">'E'</span><span class="token punctuation">)</span><span class="token operator">&lt;</span>pandas<span class="token punctuation">.</span>core<span class="token punctuation">.</span>groupby<span class="token punctuation">.</span>generic<span class="token punctuation">.</span>DataFrameGroupBy <span class="token builtin">object</span> at <span class="token number">0x000001EE0AF69FD0</span><span class="token operator">></span><span class="token operator">>></span><span class="token operator">></span> df<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">'E'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>          A         B         C         DE<span class="token number">1</span>  <span class="token number">1.917522</span>  <span class="token number">3.556640</span>  <span class="token number">0.300816</span>  <span class="token number">1.765886</span><span class="token number">2</span> <span class="token operator">-</span><span class="token number">0.186804</span>  <span class="token number">0.326687</span> <span class="token operator">-</span><span class="token number">1.720349</span> <span class="token operator">-</span><span class="token number">1.222036</span><span class="token number">3</span>  <span class="token number">0.145139</span>  <span class="token number">0.250431</span> <span class="token operator">-</span><span class="token number">0.757095</span>  <span class="token number">1.233109</span><span class="token number">4</span> <span class="token operator">-</span><span class="token number">0.459843</span> <span class="token operator">-</span><span class="token number">2.204788</span>  <span class="token number">1.381087</span> <span class="token operator">-</span><span class="token number">0.988501</span></code></pre><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="http://www.pypandas.cn/docs/">http://www.pypandas.cn/docs/</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;Pandas&lt;/code&gt; 是 Python 下的高性能的数据管理工具与数据分析工具。&lt;/p&gt;
&lt;p&gt;本文中介绍了 &lt;code&gt;Pandas&lt;/code&gt; 库中的一些常用类，然后记录了一些简单的筛选，切片等等用法。&lt;/p&gt;</summary>
    
    
    
    <category term="技术" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="技术/Python应用" scheme="https://www.c7w.tech/categories/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF-Python%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="数据分析" scheme="https://www.c7w.tech/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>《数据结构》课程期末 CheatSheet</title>
    <link href="https://www.c7w.tech/dsa-cheatsheet/"/>
    <id>https://www.c7w.tech/dsa-cheatsheet/</id>
    <published>2022-01-09T16:00:06.000Z</published>
    <updated>2022-01-29T13:52:17.794Z</updated>
    
    <content type="html"><![CDATA[<p>期末考试可以自带的一张 CheatSheet Made by c7w.</p><p>仅供参考，对于任何可能影响您课程成绩的行为，请您后果自负！</p><a id="more"></a><p>会的不整 CheatSheet 还是会，不会的整上去还是不会w</p><p>反正是 Page Fault 了，带了这一整页判断题还是不会做 TaT</p><p><img src="https://s2.loli.net/2022/01/29/hxij9gYq1DuZ3ST.jpg" alt="cheatSheet"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;期末考试可以自带的一张 CheatSheet Made by c7w.&lt;/p&gt;
&lt;p&gt;仅供参考，对于任何可能影响您课程成绩的行为，请您后果自负！&lt;/p&gt;</summary>
    
    
    
    <category term="理论" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/"/>
    
    <category term="理论/数据结构" scheme="https://www.c7w.tech/categories/%E7%90%86%E8%AE%BA/%E7%90%86%E8%AE%BA-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="数据结构" scheme="https://www.c7w.tech/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>《数据结构》课程 Lab 报告</title>
    <link href="https://www.c7w.tech/dsa-lab/"/>
    <id>https://www.c7w.tech/dsa-lab/</id>
    <published>2022-01-09T16:00:05.000Z</published>
    <updated>2022-01-29T11:07:59.169Z</updated>
    
    <content type="html"><![CDATA[<p>内含以下题目的实验报告：</p><ul><li>CST2021F LAB1 Zuma</li><li>CST2021F LAB2 HashFun</li><li>CST2021F LAB3 BBST</li></ul><p>这里不提供任何解题代码，仅将解题的白盒报告归档处理。</p><p>本博文仅做参考使用，任何可能影响您查重结果的行为请您后果自负！</p><div class="table-container"><table><thead><tr><th style="text-align:center">Problem</th><th style="text-align:center">White Box (100%)</th><th style="text-align:center">Black Box (0%)</th></tr></thead><tbody><tr><td style="text-align:center">CST2021F LAB1 Zuma (100%)</td><td style="text-align:center">97</td><td style="text-align:center">[0]</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:center">Problem</th><th style="text-align:center">White Box (100%)</th><th style="text-align:center">Black Box (0%)</th></tr></thead><tbody><tr><td style="text-align:center">CST2021F LAB2 HashFun (100%)</td><td style="text-align:center">98</td><td style="text-align:center">[100]</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:center">Problem</th><th style="text-align:center">White Box (80%)</th><th style="text-align:center">Black Box (20%)</th></tr></thead><tbody><tr><td style="text-align:center">CST2021F LAB3 BBST (100%)</td><td style="text-align:center">100</td><td style="text-align:center">[100]</td></tr></tbody></table></div><a id="more"></a><h2 id="LAB1"><a href="#LAB1" class="headerlink" title="LAB1"></a>LAB1</h2><h3 id="01"><a href="#01" class="headerlink" title="01"></a>01</h3><ul><li>错误类型: Runtime Error</li><li>错误原因: 访问 <code>string a</code> 时可能发生越界访问</li><li>相应测例<pre class="language-none"><code class="language-none">XYZ30 X0 X0 X</code></pre></li><li>标准答案: <code>XYZ\n</code></li><li>构造思路<ul><li>在程序的 19 行 <code>play(left - 1);</code> 可能发生越界访问的情况(原因在于第 10 行 <code>char color = a.at(rank);</code> 直接对 <code>rank</code> 进行了访问).</li><li>我们只需构造输入让 <code>left</code> 的值 <code>0</code>，也就是构造在字符串 <code>a</code> 的最左边进行一次消除的情况即可.</li></ul></li></ul><h3 id="02"><a href="#02" class="headerlink" title="02"></a>02</h3><ul><li>错误类型: Runtime Error</li><li>错误原因: 访问 <code>string a</code> 时可能发生越界访问</li><li>相应测例<pre class="language-none"><code class="language-none">30 X0 X0 X</code></pre></li><li>标准答案: <code>\n</code></li><li>构造思路<ul><li>在程序的 23 行 <code>play(left - 1);</code> 可能发生越界访问的情况(原因在于第 10 行 <code>char color = a.at(rank);</code> 直接对 <code>rank</code> 进行了访问).</li><li>我们只需让程序的 18 行字符串 <code>a</code> 的值在 <code>erase()</code> 后为空，此时的 <code>next</code> 值便会变成 <code>0</code>.</li><li>在下次 <code>play</code> 时，便会尝试访问一个空串中的第 <code>0</code> 个元素.</li></ul></li></ul><h3 id="03"><a href="#03" class="headerlink" title="03"></a>03</h3><ul><li>错误类型: Time Limit Exceeded</li><li>错误原因: 算法效率过低</li><li>相应测例<pre class="language-none"><code class="language-none">[&quot;QWER&quot; x 65536 times]262144[&quot;0 X\n0 Y\n&quot; x 131072 times]</code></pre></li><li>标准答案: <code>YXYX...(Trash)...QWER...(Trash)...QWER\n</code></li><li>构造思路<ul><li>现算法时间复杂度为 $O(mn)$, 构造足够大的数据规模即可.</li></ul></li></ul><h3 id="04"><a href="#04" class="headerlink" title="04"></a>04</h3><ul><li>错误类型: Wrong Answer</li><li>错误原因: 在进行 <code>while</code> 寻找可消除元素串时对边界情况处理错误</li><li>相应测例<pre class="language-none"><code class="language-none">XYY11 Y</code></pre></li><li>标准答案: <code>X\n</code></li><li>构造思路<ul><li>在程序的 12 行 <code>while (left &gt; 0 &amp;&amp; a.at(left) == color) --left;</code> 中, 最终 <code>a.at(left)</code> 的值不一定为 <code>color</code>.</li><li>而最终却通过 <code>erase</code> 将该值删除.</li><li>构造含有消除的输入即可.</li></ul></li></ul><h3 id="05"><a href="#05" class="headerlink" title="05"></a>05</h3><ul><li>错误类型: Wrong Answer</li><li>错误原因: 没有考虑初始序列为空行的情况</li><li>相应测例<pre class="language-none"><code class="language-none">10 X</code></pre></li><li>标准答案: <code>X\n</code></li><li>构造思路<ul><li>构造初始序列为空行即可.</li></ul></li></ul><h3 id="06"><a href="#06" class="headerlink" title="06"></a>06</h3><ul><li>错误类型: Wrong Answer</li><li>错误原因: 没有考虑到插入分块数组时，块过长的情况</li><li>相应测例<pre class="language-none"><code class="language-none">XYXY[&quot;XY&quot; x 1020 times]XYM20500 Y0 X0 Y0 X[&quot;0 Y\n0 X\n&quot; x 1021 times]0 Y0 X0 Y0 X</code></pre></li><li>标准答案: 以 <code>M</code> 结尾</li><li>构造思路<ul><li>构造某个块过长，使得在 <code>memmove</code> 时覆盖掉后面数组中的 <code>M</code> 即可.</li></ul></li></ul><h3 id="07"><a href="#07" class="headerlink" title="07"></a>07</h3><ul><li>错误类型: Wrong Answer</li><li>错误原因: 在向左计算需要消除的区间时，对长度为 <code>0</code> 的分块未有效过滤</li><li>相应测例<pre class="language-none"><code class="language-none">QWER[&quot;QWER&quot; x 510 times]QWMXXYYX[&quot;XYYX&quot; x 510 times]XYYXXM23072 X2048 M</code></pre></li><li>标准答案: <code>QWERQWER...(Trash)...QW</code></li><li>构造思路<ul><li>构造需要将其中一个分块完全清除的连消输入.</li><li>输入为 $[QWER…QWERQWMX][XYYX…XYYX][XM]$<ul><li>在中间分块的中间位置首先执行一次连消，中间区块的长度被置为 <code>0</code>.</li><li>程序在之后插入 <code>M</code>，寻找可消除区块时，<code>l.first</code> 便无法成功查询到目标位置，导致答案错误的出现.</li></ul></li></ul></li></ul><h3 id="08"><a href="#08" class="headerlink" title="08"></a>08</h3><ul><li>错误类型: Wrong Answer</li><li>错误原因: 没有考虑连消</li><li>相应测例<pre class="language-none"><code class="language-none">XXYYZZYYXX14 Z</code></pre></li><li>标准答案: <code>\n</code></li><li>构造思路<ul><li>构造连消输入即可.</li></ul></li></ul><h3 id="09"><a href="#09" class="headerlink" title="09"></a>09</h3><ul><li>错误类型: Runtime Error</li><li>错误原因: 在执行消除时没有对 <code>l</code>, <code>r</code> 出现在同一个分块数组的情况进行特判而导致异常</li><li>相应测例<pre class="language-none"><code class="language-none">XYZXYZMMXYZXYZ16 M</code></pre></li><li>标准答案: <code>XYZXYZXYZXYZ\n</code></li><li>构造思路<ul><li>代码的 132 行，135 行对 <code>len</code> 的赋值，在<code>l</code>, <code>r</code> 出现在同一个分块数组的情况会出现负数.</li><li>构造执行消除时 <code>l</code>, <code>r</code> 出现在同一个分块数组的情况即可.</li></ul></li></ul><h3 id="10"><a href="#10" class="headerlink" title="10"></a>10</h3><ul><li>错误类型: Wrong Answer</li><li>错误原因: 在执行跨分块消除时，误将 <code>plen[l.first]</code> 设为 <code>0</code></li><li>相应测例<pre class="language-none"><code class="language-none">XY[&quot;XY&quot; x 1022 times]XYYM12048 Y</code></pre></li><li>标准答案: 以 <code>M</code> 结尾</li><li>构造思路<ul><li>代码消除连珠后，在对中间分块的区间长度置 <code>0</code> 时，<code>for (int i = l.first; i &lt; r.first; i++)</code> 会误将 <code>plen[l.first]</code> 设为 <code>0</code>.</li><li>构造跨分块消除的情况，注意构造 <code>M</code> 使得在 <code>p2a()</code> 拷贝时 <code>M</code> 覆盖掉 <code>a</code> 的首元素.<ul><li>输入为 $[XYXYXY…XYXY][YM]$.</li><li>连消后 <code>plen[0]</code> 被置 <code>0</code>，再发生 <code>p2a()</code> 拷贝时 <code>M</code> 便会覆盖掉 <code>a</code> 的首元素.</li></ul></li></ul></li></ul><h2 id="LAB2"><a href="#LAB2" class="headerlink" title="LAB2"></a>LAB2</h2><h3 id="Hashing-Strategies"><a href="#Hashing-Strategies" class="headerlink" title="Hashing Strategies"></a>Hashing Strategies</h3><h4 id="hashing-ascii"><a href="#hashing-ascii" class="headerlink" title="[hashing_ascii] "></a><strong>[hashing_ascii] </strong></h4><script type="math/tex; mode=display">(\sum_{every-32bit}BitRepresentation_i) \ \ \ \ \ \ \ \ (mod \ \ TableSize)</script><p>即字符串 <code>aaaabbbbcd</code> 会被分割为 <code>aaaa</code>, <code>bbbb</code>, <code>cd\0\0</code> 考虑，分别找出其 32bit 的表示后求和。（对 $TableSize$ 取模的意义下）</p><h4 id="hashing-utf8"><a href="#hashing-utf8" class="headerlink" title="[hashing_utf8]"></a><strong>[hashing_utf8]</strong></h4><script type="math/tex; mode=display">(\sum_{every-utf8-character}BitRepresentation_i) \mod TableSize</script><p>如 <code>哒a</code> 被考虑为 <code>哒\0</code> 和 <code>a\0\0\0</code>。即考虑字符串中的每个 utf-8 字符，将其延拓为 32bit 表示后求和。（对 $TableSize$ 取模的意义下）</p><h4 id="quad-probe"><a href="#quad-probe" class="headerlink" title="[quad_probe]"></a><strong>[quad_probe]</strong></h4><p><strong>quad_probe</strong> 有成员函数 <code>getOffset()</code> 建立 $(-1,0,1,2,3,4,5,6\cdots)$ 到 $(0,0,1,-1,4,-4,9,-9\cdots)$ 的映射，成员变量 <code>lastIndex</code> 记录当前的 offset-index，在 <code>init()</code> 类对象的时候将 <code>lastIndex</code> 置为 $-1$​​​，之后每次解决冲突都将 <code>lastIndex</code> 自增，在对 $TableSize$ 取模的意义下返回 <code>last_choice + getOffset(lastIndex) - getOffset(lastIndex-1)</code>。</p><h4 id="public-overflow"><a href="#public-overflow" class="headerlink" title="[public_overflow]"></a><strong>[public_overflow]</strong></h4><p>对 collision_strategy 增加虚函数 <code>get_max_hashing_volume</code> 获得非溢出区的长度，默认返回 $TableSize$，并修改 <code>*my_hashing</code> 调用时传入该函数的返回值。<strong>public_overflow</strong> 对该函数重写，返回最大表长的 $4/5$。</p><p>在解决 overflow 问题的时候，若 <code>last_choice</code> 不在缓冲区中，则返回缓冲区的第一个位置；不然返回下一个邻近的位置。</p><h3 id="Testing-Cases"><a href="#Testing-Cases" class="headerlink" title="Testing Cases"></a>Testing Cases</h3><div class="table-container"><table><thead><tr><th>测例名</th><th>数据来源</th><th>插入</th><th>查询</th><th>Collision Factor</th></tr></thead><tbody><tr><td>1-ascii-standard</td><td>poj</td><td>30k</td><td>90k</td><td>20</td></tr><tr><td>2-utf8-standard</td><td>hdu</td><td>30k</td><td>90k</td><td>20</td></tr><tr><td>3-ascii-collision</td><td>poj</td><td>30k</td><td>90k</td><td>100</td></tr><tr><td>4-utf8-collision</td><td>hdu</td><td>30k</td><td>90k</td><td>100</td></tr><tr><td>5-ascii-large</td><td>poj</td><td>100k</td><td>300k</td><td>20</td></tr><tr><td>6-utf8-large</td><td>hdu</td><td>100k</td><td>300k</td><td>20</td></tr></tbody></table></div><h4 id="测例构造方法"><a href="#测例构造方法" class="headerlink" title="测例构造方法"></a>测例构造方法</h4><p>首先将所有数据读入，并维护一个 hashTable 来进行 key 去重的操作。这个 hashTable 使用的 hash 策略根据数据来源，分别使用 hashing-ascii 和 hashing-utf8，这是为了保证可以构造高冲突率的样例。在将数据读入时，我们为每条数据赋予一个 uniqueId，计算公式为：</p><script type="math/tex; mode=display">uniqueId_i = hash(key) + randint(1, 100M)/CollisionFactor^2</script><p>这个计算公式可以保证，在 CollisionFactor 较小时，数据的 uniqueId 由随机值决定；而在冲突因子较大时，hash 值相近的数据最终 uniqueId 相近。最终我们按照 uniqueId 将读入的顺序进行排序。</p><p>然后我们均匀选择插入与查询操作，<strong>插入</strong>即将排序后的条目的最后一个移入待查询队列中；<strong>查询</strong>有 75% 的概率从待查询队列随机选取一个，25% 概率查询条目队列的最后一个并将其丢弃。</p><h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><ol><li>使用 hashing-ascii 处理 utf-8 字符串的性能比使用 hashing-utf8 的性能差。这是因为 hashing-ascii 没有充分考虑 utf-8 字符串的组成结构，导致散列后的关键码分布不均匀。</li><li>双向平方探测的性能显著优于线性试探，这是因为一旦发生散列冲突，前者可以快速跳离冲突区域。</li><li>闭散列在性能上更占优势。当冲突的元素个数 $k \le TableSize$ 时，不需要进行 $O(TableSize)$ 的试探链探测，只需要 $O(k)$ 的溢出区查找。</li><li><p>这可能会导致散列后的散列码分布并不均匀，因而可能导致局部的聚集性，进而造成散列表操作效率的下降。</p></li><li></li></ol><p><strong>[Input Data]</strong> <code>a-z0-9</code> 上长度为 5 的串的集合 $S$​。</p><p><strong>[Representation]</strong> $h :=(0,\cdots,9,a,\cdots,z) \rightarrow (0,\cdots,9,10,\cdots, 35)$​​​​​， $f(w) := \sum _{i=1}^n h(w_i)*36^{i-1}$​​​​。</p><p><strong>[Operation]</strong> 使用长度为 $O(|S|)$​ 的向量 $V$，$Rank(w)=f(w)$，$V_w = Rank(w)$。</p><h2 id="LAB3"><a href="#LAB3" class="headerlink" title="LAB3"></a>LAB3</h2><h3 id="Data-Structures"><a href="#Data-Structures" class="headerlink" title="Data Structures"></a>Data Structures</h3><p>实验中实现了<strong>AVL 树</strong>，<strong>Splay 树</strong>，<strong>红黑树</strong>三种数据结构，接下来做简单介绍与复杂度分析。数据结构的构思部分参考了《数据结构》课堂讲义第八章和第十章的内容。</p><h4 id="BBST"><a href="#BBST" class="headerlink" title="BBST"></a>BBST</h4><p>这是一个接口（抽象基类）。本实验用到的三种数据结构均由 BBST 派生。具体来说，它提供了以下虚方法：</p><ul><li><code>find(const T&amp; e)</code></li><li><code>insert(const T&amp; e)</code></li><li><code>remove(const T&amp; e)</code></li></ul><h4 id="AVL-树"><a href="#AVL-树" class="headerlink" title="AVL 树"></a>AVL 树</h4><p>AVL 树实现了一种渐进平衡，其定义一个结点的<strong>平衡因子</strong>为左孩子与右孩子的高度差。其渐进平衡的条件为每个结点的平衡因子绝对值不超过 1。可以证明，在这样的渐进平衡意义下，树高 $h=O(\log_2n)$。</p><p>AVL 树的查找调用了与标准 BST 类似的接口，不过增设了 <code>_find</code> 指针记录上一个结点 $T$ 的地址，其中结点 $T$ 满足 $data(T) \le e$ 的题设条件。最终的查找结果便是 <code>_find</code> 指针对应的结点。</p><p>AVL 树的插入和删除涉及到平衡因子被破坏后的恢复操作。具体来说，是对失衡结点 $g$，及其较高的孩子 $p$，以及较高的孩子的较高的孩子 $v$ 执行 3+4 重构，保持中序遍历单调增原则的不变性。对于插入操作可以证明这样的修正是一蹴而就的，修正后局部子树的高度恢复，平衡因子的改变影响无需上传至树根。而删除操作在修正后，产生的失衡影响可能继续上传，一直到树根。</p><p>也因此我们可以分析得出，一颗结点数为 $n$ 的 AVL 树的空间复杂度为 $O(n)$，时间复杂度分析如下：</p><p>单次查找时间复杂度为 $O(h) = O(\log n)$，插入删除操作最坏情况均为 $O(\log n)$。而单次插入操作引起的拓扑结构变化量为 $O(1)$，单次删除操作引起的拓扑结构变化量为 $O(\log n)$。</p><h4 id="Splay-树"><a href="#Splay-树" class="headerlink" title="Splay 树"></a>Splay 树</h4><p>伸展树使用双层伸展策略，思想主要是充分利用数据访问的局部性，具体来说：</p><ul><li>刚被访问过的结点，极有可能很快地再次被访问</li><li>下一次将要访问的结点，极有可能就在刚被访问过的结点的附近</li></ul><p>于是就模仿自适应链表的想法，一旦结点被访问，便通过旋转将其推送至树根。而这旋转是使用双层伸展策略，即每次旋转考察祖孙三代，对其做 3+4 重构。事实证明这有利于树高的减小。</p><p>Splay 树的查找调用了与标准 BST 类似的接口，不过增设了 <code>_find</code> 指针记录上一个结点 $T$ 的地址，其中结点 $T$ 满足 $data(T) \le e$ 的题设条件。最终的查找结果便是 <code>_find</code> 指针对应的结点。此外，在结点查找结束后，最终被查找到的结点会被旋转推送至根。</p><p>Splay 树的插入和删除依赖于其查找操作。不管是插入，还是删除，在此之前都会执行一次查找操作。对于插入操作来说，带插入节点的直接前驱/后继已经在这时推送至根，我们只需在根部做简单的拓扑结构改变便可将新结点接入。而对于删除操作来说，待删除结点已经在这时被推送至根。我们只需要在其其中一棵子树中寻找其直接后继，然后将其推送至该子树的根部，然后将两颗子树重新拼接起来即可。</p><p>于是我们可以分析得出，一颗结点数为 $n$ 的 Splay 树的空间复杂度为 $O(n)$，时间复杂度分析如下：</p><p>单次查找最坏时间复杂度为 $O(h) = O(n)$，而分摊复杂度为 $O(\log n)$；插入删除操作由于调用了查找接口，最坏情况均为 $O(n)$，但分摊复杂度均为 $O(\log n)$。单次插入删除操作引起的拓扑结构变化量均为 $O(\log n)$。而当我们进行连续的 $m$ 次查找，满足 $k \ll n \ll m$ 时，整体的时间复杂度仅为 $O(m\log k+n \log n)$。也就是说，针对局部性的数据访问，Splay 树有其独特的优势。</p><h4 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a>红黑树</h4><p>红黑树是一种适度平衡树，其满足以下条件：</p><ol><li>树根必为黑色。</li><li>外部结点必为黑色。</li><li>红结点只能有黑孩子和黑父亲。</li><li>外部结点的黑深度相等，或全树的黑深度相等。</li></ol><p>事实上，红黑树的性质与 (2,4)-B 树有密不可分的联系，在这里我们不多详细介绍。值得注意的是，适度平衡的红黑树虽然平衡条件没有 AVL 树严格，但是可以证明其高度 $h = O(\log n)$。</p><p>红黑树的查找调用了与标准 BST 类似的接口，不过增设了 <code>_find</code> 指针记录上一个结点 $T$ 的地址，其中结点 $T$ 满足 $data(T) \le e$ 的题设条件。最终的查找结果便是 <code>_find</code> 指针对应的结点。</p><p>红黑树的插入和删除需要处理插入时上溢（双红修正）和下溢（双黑修正）两种特殊情况。二者均可以类比 B 树中结点上溢和下溢的操作来处理，然后将 B 树的处理结果通过重染色和旋转两种方式体现回红黑树中。而不管是插入还是删除的哪种情况，针对拓扑结构改变而言，我们均最多做常数次旋转便可以将其恢复为符合红黑树规则的 BST。</p><p>也因此我们可以分析得出，一颗结点数为 $n$ 的红黑树的空间复杂度为 $O(n)$，时间复杂度分析如下：</p><p>单次查找时间复杂度为 $O(h) = O(\log n)$，插入删除操作最坏情况均为 $O(\log n)$。而单次插入和删除操作引起的拓扑结构变化量均为 $O(1)$。</p><h3 id="Test-Cases"><a href="#Test-Cases" class="headerlink" title="Test Cases"></a>Test Cases</h3><p>实验使用 Python 写了自动化的测试工程，只需使用 <code>python3 main.py</code> 即可运行输出测试结果。我们在报告的根目录留了一份 <code>result.log</code>，为使用 <code>Ubuntu-20.04 LTS, AMD Ryzen 5 4600H (3.00 GHz), 8GM RAM</code> 的运行结果。</p><p>项目目录解释如下：<br><pre class="language-none"><code class="language-none">|- main.py  测试程序主入口|- cases  测试样例生成器    |- case1_rand.py    |- case2_sorted.py    |- case3_query.py    |- case4_modification.py|- utils    |- judger.py  Judger|- testdata  样例生成器的生成结果 &#x2F;&#x2F; Very large. Maybe 600MB+!</code></pre></p><h4 id="Case-1-Random"><a href="#Case-1-Random" class="headerlink" title="Case 1: Random"></a>Case 1: Random</h4><p>实验的第一组为随机数据。数据量分为 $100K$，$1M$，$5M$，$10M$ 四种情况。</p><p>具体来说，测例生成的流程如下：</p><ul><li>随机在 $[1, 1M]$ 中均匀选择关键字 <code>key</code>；</li><li>如果 <code>key</code> 不在树中，执行插入操作；不然有 70% 的概率对 <code>key</code> 执行一次查找，30% 的概率执行一次删除。</li></ul><p>这样可以首先保证树中有足够多的数据，后续操作不至因树中结点规模 $n$ 过小而导致性能无法区分；此外可知  $p_{query}$，$p_{insertion}$，$p_{removal}$ 三者的极限均收敛，实证证明三者的比例分别约为 $0.5, 0.3, 0.2$。</p><h4 id="Case-2-Sorted"><a href="#Case-2-Sorted" class="headerlink" title="Case 2: Sorted"></a>Case 2: Sorted</h4><p>实验的第二组为顺序插入数据。数据量分为 $100K$，$1M$，$5M$，$10M$ 四种情况。</p><p>具体来说，测例生成的流程如下：</p><ul><li>对于 $[1, n]$ 之间的所有关键码 <code>key</code>，顺序插入 <code>key</code>。</li></ul><p>有序数据是现实中较为特殊的一种情况。同时，这样数据的插入也在一定程度上具有局部性，即每次要插入的结点都是上一次插入的结点的直接后继。此外，这组数据也可以反映出树的动态操作次数。</p><h4 id="Case-3-Query-with-locality"><a href="#Case-3-Query-with-locality" class="headerlink" title="Case 3: Query with locality"></a>Case 3: Query with locality</h4><p>实验的第三组为大量查询具有局部性特征的数据。数据量分为 $100K$，$1M$，$5M$，$10M$ 四种情况。</p><p>具体来说，测例生成的流程如下：</p><ul><li>向树中插入规模为 $n * 0.5\%$ 的随机结点；</li><li>剩下的次数均用于查询最后被插入的结点。</li></ul><p>这既能反映 AVL 树和红黑树面对大量查询时的表现性能，从而间接反映出树高的情况，同时由于查询带有局部性，可以更好地体现 Splay 树具有的局部性查询的特征。</p><h4 id="Case-4-Modification"><a href="#Case-4-Modification" class="headerlink" title="Case 4: Modification"></a>Case 4: Modification</h4><p>实验的第四组为大量插入和删除数据。数据量分为 $100K$，$1M$，$5M$，$10M$ 四种情况。</p><p>具体来说，测例生成的流程如下：</p><ul><li>随机在 $[1, 1M]$ 中均匀选择关键字 <code>key</code>；</li><li>如果 <code>key</code> 在树中，执行插入操作；不然执行删除操作。</li></ul><p>这样可以首先保证树中有足够多的数据，后续操作不至因树中结点规模 $n$ 过小而导致性能无法区分；此外这样可以测试数据结构在面对大量的增删操作时的运作性能。</p><h3 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h3><p>我们在计算机无其他任务运行时使用上述的配置共计运行了 5 次实验并取平均值。其中“运行时间”的定义为 Python 的 subprocess 开始运行与停止运行的时间，旋转次数定义为 <code>zig</code>, <code>zag</code>, 或是 3+4 重构总的调用次数。下面我们逐测例分析：</p><h4 id="Case-1"><a href="#Case-1" class="headerlink" title="Case 1"></a>Case 1</h4><div class="table-container"><table><thead><tr><th style="text-align:center">数据结构/运行时间(s)</th><th style="text-align:center">100 K</th><th style="text-align:center">1M</th><th style="text-align:center">5M</th><th style="text-align:center">10M</th></tr></thead><tbody><tr><td style="text-align:center">AVL</td><td style="text-align:center"><font color="limegreen">0.45</font></td><td style="text-align:center">1.14</td><td style="text-align:center">5.14</td><td style="text-align:center">10.50</td></tr><tr><td style="text-align:center">Splay</td><td style="text-align:center">0.47</td><td style="text-align:center">2.10</td><td style="text-align:center">11.00</td><td style="text-align:center"><span style="color: red"> &gt; 15.00</span></td></tr><tr><td style="text-align:center">RedBlack</td><td style="text-align:center">0.51</td><td style="text-align:center"><font color="limegreen">1.05</font></td><td style="text-align:center"><font color="limegreen">5.03</font></td><td style="text-align:center"><font color="limegreen">9.25</font></td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:center">数据结构/旋转次数</th><th style="text-align:center">100 K</th><th style="text-align:center">1M</th><th style="text-align:center">5M</th><th style="text-align:center">10M</th></tr></thead><tbody><tr><td style="text-align:center">AVL</td><td style="text-align:center">45K</td><td style="text-align:center">0.32M</td><td style="text-align:center">0.95M</td><td style="text-align:center">1.5M</td></tr><tr><td style="text-align:center">Splay</td><td style="text-align:center">1.2M</td><td style="text-align:center">15M</td><td style="text-align:center"><font color="red">79M</font></td><td style="text-align:center"><font color="red">- TLE -</font></td></tr><tr><td style="text-align:center">RedBlack</td><td style="text-align:center">39K</td><td style="text-align:center"><font color="limegreen">0.27M</font></td><td style="text-align:center"><font color="limegreen">0.8M</font></td><td style="text-align:center"><font color="limegreen">1.4M</font></td></tr></tbody></table></div><p>在随机数据上的表现红黑树最好，伸展树最差。伸展树由于其单次插入，删除和查询都需要将目标结点通过旋转推送至根，而我们的数据输入十分具有随机性，因此平均每次增删查都需要 $O(\log n)$ 的时间将目标结点推送至根，因此在时间复杂度上逊于另外两者。而 AVL 树与红黑树二者的表现不相伯仲，但红黑树的动态操作数明显小于 AVL 树，这是由于其动态操作拓扑结构的变化量都是常数级别的。</p><h4 id="Case-2"><a href="#Case-2" class="headerlink" title="Case 2"></a>Case 2</h4><div class="table-container"><table><thead><tr><th style="text-align:center">数据结构/运行时间(s)</th><th style="text-align:center">100 K</th><th style="text-align:center">1M</th><th style="text-align:center">5M</th><th style="text-align:center">10M</th></tr></thead><tbody><tr><td style="text-align:center">AVL</td><td style="text-align:center">0.49</td><td style="text-align:center">0.62</td><td style="text-align:center">1.30</td><td style="text-align:center">2.16</td></tr><tr><td style="text-align:center">Splay</td><td style="text-align:center">0.50</td><td style="text-align:center"><font color="limegreen">0.54</font></td><td style="text-align:center"><font color="limegreen">0.98</font></td><td style="text-align:center"><font color="limegreen">1.72</font></td></tr><tr><td style="text-align:center">RedBlack</td><td style="text-align:center">0.50</td><td style="text-align:center">0.66</td><td style="text-align:center">1.50</td><td style="text-align:center">2.66</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:center">数据结构/旋转次数</th><th style="text-align:center">100 K</th><th style="text-align:center">1M</th><th style="text-align:center">5M</th><th style="text-align:center">10M</th></tr></thead><tbody><tr><td style="text-align:center">AVL</td><td style="text-align:center">100K</td><td style="text-align:center">1M</td><td style="text-align:center">5M</td><td style="text-align:center">10M</td></tr><tr><td style="text-align:center">Splay</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">RedBlack</td><td style="text-align:center">100K</td><td style="text-align:center">1M</td><td style="text-align:center">5M</td><td style="text-align:center">10M</td></tr></tbody></table></div><p>Splay 树在这组数据上表现的最好，这是因为插入的数据具有局部性，每次插入的数据的直接前驱是上一次插入的数据，这样可以让 Splay 树仅仅在根部做嫁接即可，无需旋转操作，单次操作也只需要常数级别。而 AVL 树在这组数据上的动态操作表现与红黑树近似，这是因为只有插入操作，二者均可在 $O(1)$ 的动态操作次数内完成。</p><h4 id="Case-3"><a href="#Case-3" class="headerlink" title="Case 3"></a>Case 3</h4><div class="table-container"><table><thead><tr><th style="text-align:center">数据结构/运行时间(s)</th><th style="text-align:center">100 K</th><th style="text-align:center">1M</th><th style="text-align:center">5M</th><th style="text-align:center">10M</th></tr></thead><tbody><tr><td style="text-align:center">AVL</td><td style="text-align:center">0.52</td><td style="text-align:center">0.67</td><td style="text-align:center">1.40</td><td style="text-align:center"><font color="limegreen">2.00</font></td></tr><tr><td style="text-align:center">Splay</td><td style="text-align:center">0.50</td><td style="text-align:center"><font color="limegreen">0.66</font></td><td style="text-align:center"><font color="limegreen">1.39</font></td><td style="text-align:center">3.12</td></tr><tr><td style="text-align:center">RedBlack</td><td style="text-align:center">0.51</td><td style="text-align:center">0.67</td><td style="text-align:center">1.44</td><td style="text-align:center">3.20</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:center">数据结构/旋转次数</th><th style="text-align:center">100 K</th><th style="text-align:center">1M</th><th style="text-align:center">5M</th><th style="text-align:center">10M</th></tr></thead><tbody><tr><td style="text-align:center">AVL</td><td style="text-align:center">0.2K</td><td style="text-align:center">2.3K</td><td style="text-align:center">11K</td><td style="text-align:center">23K</td></tr><tr><td style="text-align:center">Splay</td><td style="text-align:center">3K</td><td style="text-align:center">44K</td><td style="text-align:center">280K</td><td style="text-align:center"><font color="red">610K</font></td></tr><tr><td style="text-align:center">RedBlack</td><td style="text-align:center">0.2K</td><td style="text-align:center">1.9K</td><td style="text-align:center">9.7K</td><td style="text-align:center">19K</td></tr></tbody></table></div><p>在小批量插入随机数据，大批量查询局部数据的过程中我们可以得出结论：</p><ul><li>Splay 树针对局部数据的查询有其独到之处，具体来说，在 1M 和 5M 的实验中，即使其有十分缓慢的插入速度，其综合性能仍然优于其他两者；而在 10 M 的实验中，其查询带来的性能提升终究没有低过随机插入带来的严重性能浪费（这点由其动态操作的次数便可看出）。</li><li>而同时值得我们注意的是，AVL 树和红黑树在面对大规模的数据查询时所表现出的不同。AVL 树面对大规模的数据查询时性能明显优于红黑树，这是由于其较为严格的平衡条件保证了其在结点规模相等的情况下，树高低于红黑树，因而查找的平均长度低。</li></ul><h4 id="Case-4"><a href="#Case-4" class="headerlink" title="Case 4"></a>Case 4</h4><div class="table-container"><table><thead><tr><th style="text-align:center">数据结构/运行时间(s)</th><th style="text-align:center">100 K</th><th style="text-align:center">1M</th><th style="text-align:center">5M</th><th style="text-align:center">10M</th></tr></thead><tbody><tr><td style="text-align:center">AVL</td><td style="text-align:center">0.54</td><td style="text-align:center">1.28</td><td style="text-align:center">5.30</td><td style="text-align:center">10.45</td></tr><tr><td style="text-align:center">Splay</td><td style="text-align:center">0.53</td><td style="text-align:center">2.02</td><td style="text-align:center"><font color="red">10.30</font></td><td style="text-align:center"><span style="color: red"> &gt; 15.00</span></td></tr><tr><td style="text-align:center">RedBlack</td><td style="text-align:center">0.51</td><td style="text-align:center"><font color="limegreen">1.16</font></td><td style="text-align:center"><font color="limegreen">4.89</font></td><td style="text-align:center"><font color="limegreen">9.89</font></td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:center">数据结构/旋转次数</th><th style="text-align:center">100 K</th><th style="text-align:center">1M</th><th style="text-align:center">5M</th><th style="text-align:center">10M</th></tr></thead><tbody><tr><td style="text-align:center">AVL</td><td style="text-align:center">44K</td><td style="text-align:center">375K</td><td style="text-align:center">1.6M</td><td style="text-align:center">3.1M</td></tr><tr><td style="text-align:center">Splay</td><td style="text-align:center">1.3M</td><td style="text-align:center">16.4M</td><td style="text-align:center">88M</td><td style="text-align:center"><font color="red">- TLE -</font></td></tr><tr><td style="text-align:center">RedBlack</td><td style="text-align:center">37K</td><td style="text-align:center"><font color="limegreen">326K</font></td><td style="text-align:center"><font color="limegreen">1.4M</font></td><td style="text-align:center"><font color="limegreen">2.8M</font></td></tr></tbody></table></div><p>在涉及到大规模的数据插入与删除的时候，因为每次插入和删除都要大批量旋转的伸展树自然是喜提 TLE。而我们得到的结论是，红黑树在大规模的增删操作是优于 AVL 树的，这恰恰也是因为红黑树对于渐进平衡的要求并没有 AVL 树严格，同时红黑树删除操作所涉及的动态操作数目少于 AVL 树的缘故。</p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><ol><li>在进行大规模<strong>查找</strong>时，<strong>AVL 树</strong>比红黑树更优。因为它的平衡条件更严格，平均树高更低，也因此适用于数据库等需要快速查找的场合。</li><li><strong>红黑树</strong>的大规模<strong>插入与删除</strong>操作优于 AVL 树，既可以有效减少拓扑结构的更改次数，且分摊时间成本也较低。红黑树也因此被广泛用于各种编程语言提供的标准数据结构中。</li><li>当问题访问的数据具有<strong>局部性</strong>时，<strong>Splay 树</strong>的可以大大提升性能，甚至在某些情况下会超过 AVL 树和红黑树的性能。因此当要处理的问题数据具有明显的局部性特征，应选用 Splay 树。</li></ol><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] Pfaff B. Performance analysis of BSTs in system software[J]. ACM SIGMETRICS Performance Evaluation Review, 2004, 32(1): 410-411.</p><p>[2] Štrbac-Savić S, Tomašević M. Comparative performance evaluation of the AVL and red-black trees[C]//Proceedings of the Fifth Balkan Conference in Informatics. 2012: 14-19.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;内含以下题目的实验报告：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CST2021F LAB1 Zuma&lt;/li&gt;
&lt;li&gt;CST2021F LAB2 HashFun&lt;/li&gt;
&lt;li&gt;CST2021F LAB3 BBST&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里不提供任何解题代码，仅将解题的白盒报告归档处理。&lt;/p&gt;
&lt;p&gt;本博文仅做参考使用，任何可能影响您查重结果的行为请您后果自负！&lt;/p&gt;
&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Problem&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;White Box (100%)&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Black Box (0%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F LAB1 Zuma (100%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;97&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[0]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Problem&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;White Box (100%)&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Black Box (0%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F LAB2 HashFun (100%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;98&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[100]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Problem&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;White Box (80%)&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Black Box (20%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F LAB3 BBST (100%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;100&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[100]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;</summary>
    
    
    
    <category term="程设" scheme="https://www.c7w.tech/categories/%E7%A8%8B%E8%AE%BE/"/>
    
    <category term="程设/数据结构" scheme="https://www.c7w.tech/categories/%E7%A8%8B%E8%AE%BE/%E7%A8%8B%E8%AE%BE-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="数据结构" scheme="https://www.c7w.tech/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>《数据结构》课程 PA3 报告</title>
    <link href="https://www.c7w.tech/dsa-pa3/"/>
    <id>https://www.c7w.tech/dsa-pa3/</id>
    <published>2022-01-09T16:00:03.000Z</published>
    <updated>2022-01-29T11:16:06.703Z</updated>
    
    <content type="html"><![CDATA[<p>内含以下题目的实验报告：</p><ul><li>CST2021F 3-1 Circuit</li><li>CST2021F 3-3 kth</li><li>CST2021F 3-5 Prefix</li><li>CST2021F 3-7 Sort</li></ul><p>这里不提供任何解题代码，仅将解题的白盒报告归档处理。</p><p>本博文仅做参考使用，任何可能影响您查重结果的行为请您后果自负！</p><div class="table-container"><table><thead><tr><th style="text-align:center">Problem</th><th style="text-align:center">White Box (20%)</th><th style="text-align:center">Black Box (80%)</th></tr></thead><tbody><tr><td style="text-align:center">CST2021F 3-1 Circuit (25%)</td><td style="text-align:center">100</td><td style="text-align:center">[100] -1</td></tr><tr><td style="text-align:center">CST2021F 3-3 kth (25%)</td><td style="text-align:center">100</td><td style="text-align:center">[100] -1</td></tr><tr><td style="text-align:center">CST2021F 3-5 Prefix (25%)</td><td style="text-align:center">100</td><td style="text-align:center">[100] -1</td></tr><tr><td style="text-align:center">CST2021F 3-7 Sort (25%)</td><td style="text-align:center">100</td><td style="text-align:center">[100] -1</td></tr></tbody></table></div><a id="more"></a><h1 id="CST2021F-3-1-Circuit"><a href="#CST2021F-3-1-Circuit" class="headerlink" title="CST2021F 3-1 Circuit"></a>CST2021F 3-1 Circuit</h1><p>​    <strong>[关键词] Trie 树</strong></p><h2 id="方案设计"><a href="#方案设计" class="headerlink" title="方案设计"></a>方案设计</h2><p>$\forall i \in [0, n)$，需要一种支持以下操作的数据结构：</p><p>(1) 持有 $[\max(i-k-1, 0), \min(i+k+1, n-1)]$ 中所有的元件的输出信息；</p><p>(2) 可以查询这些信息中满足与 $data[i]$ 异或值最大的 $data[j]$ 的 $j$，其中 $i \ne j$。</p><p>(3) 在考虑 $i$ 结束，转向考虑 $i+1$ 的时候，可以快速地删除 $data[i-k-1]$ 的信息，加入 $data[(i+1)+k+1]$ 的信息。</p><p>而字典树，恰恰就能满足我们上述的需求，下面对其进行详细介绍。</p><h3 id="字典树：规则"><a href="#字典树：规则" class="headerlink" title="字典树：规则"></a>字典树：规则</h3><p>字典树的结点分<strong>非叶结点</strong>和<strong>叶结点</strong>两种。事实上，我们可以用考虑有限转移自动机（DFA）的方式来考虑字典树。</p><p><strong>非叶结点</strong>记录了所有终态经过它的串的个数，以及通过输入一个字符 $a\in\Sigma$​，可以转移到的下一个非叶结点或叶结点的位置。</p><p><strong>叶结点</strong>记录了所有以它为终态的串的个数，同时维护了一个列表来按次序记录所有以该叶结点为终态的串的 ID。</p><p>我们定义，一个结点输入一个字符 $a\in \Sigma$​​ 后对应的结点<strong>存在</strong>，当且仅当该结点是非叶结点，同时该非叶结点可以通过字符 $a$ 转移到位置 $t$，且结点 $t$ 接受的终态经过 $t$ 或是以 $t$ 为终态的串的个数非零。</p><h3 id="字典树：初始化"><a href="#字典树：初始化" class="headerlink" title="字典树：初始化"></a>字典树：初始化</h3><p>从这小节的讨论开始，我们只讨论 $\Sigma=\{0, 1\}$ 的情况。</p><p>字典树默认只有一个根节点，接受空串 $\epsilon$​，终态经过它的串的个数为 $0$​​，这里我们不将该根节点视为叶结点。</p><p>$\Sigma = \{0,1\}$​​ 的字典树的非叶结点只需记录其经过 $0$ 转移和 $1$ 转移后的到达结点，这里我们使用二叉树的记号，分别记作其左孩子和右孩子。</p><h3 id="字典树：插入"><a href="#字典树：插入" class="headerlink" title="字典树：插入"></a>字典树：插入</h3><p>考虑我们将插入 $64$ 位整数 $data[i]$。</p><p>我们从根节点出发，逐一考虑去接受该串的字符，遇 $0$ 则转向其左孩子，遇 $1$ 则转向其右孩子，若对应的孩子的<strong>位置不存在</strong>（注意这里与上述结点的<strong>存在</strong>不同，结点存在需要位置存在，且该位置的记录串数非零）则创建。同时我们将沿途所有的非叶结点的“终态经过它的串的个数”自增，终态叶结点的“以它为终态的串的个数”自增。最后，我们在终态叶结点的串列表中将该串的 ID $i$ 插入。在本题中由于我们考虑的窗口永远是从左向右滑动，我们可以保证插入的 ID $i$​ 一定是在列表的末尾，故我们只需插入到列表末尾即可。</p><h3 id="字典树：删除"><a href="#字典树：删除" class="headerlink" title="字典树：删除"></a>字典树：删除</h3><p>考虑我们将删除 $64$ 位整数 $data[i]$，同时我们断言 $data[i]$ 在此前一定被插入到树中。</p><p>我们从根节点出发，逐一考虑去接受该串的字符，遇 $0$ 则转向其左孩子，遇 $1$ 则转向其右孩子。我们将沿途所有的非叶结点的“终态经过它的串的个数”自减，终态叶结点的“以它为终态的串的个数”自减。最后，我们在终态叶结点的串列表中将该串的 ID $i$ 移除。在本题中由于我们考虑的窗口永远是从左向右滑动，我们可以保证删除的 ID $i$​ 一定是在列表的首位，故我们只需删除列表首位即可。</p><h3 id="字典树：查询"><a href="#字典树：查询" class="headerlink" title="　字典树：查询"></a>　字典树：查询</h3><p>考虑我们将查询 $j$，使得 $i \ne j$ 且 $data[j]$ 与 $64$ 位整数 $data[i]$ 的异或值最大，其中 $j \in [\max(i-k-1, 0), \min(i+k+1, n-1)]$。</p><p>由贪心策略，如果我们每步均朝向异或值最大的方向走，即遇 $0$ 走 $1$，遇 $1$ 走 $0$（如果可能的话，这种可能性由对应的<strong>结点存在</strong>蕴含），我们最终得到的异或值便一定是最大的。</p><p>也就是说，我们的查询过程可以概述如下：</p><p>从根节点出发，逐一去考虑接受该串的字符，遇 $0$ 若右孩子存在则转向右孩子，不然转向左孩子；遇 $1$ 若左孩子存在则转向左孩子，不然转向右孩子。这样不断进行下去势必会达到一个终态，而这个我们要做的便是输出这个终态叶结点的接受串 ID 列表中第一个 $id$（满足 $id \ne i$​）。</p><h2 id="过程记录"><a href="#过程记录" class="headerlink" title="过程记录"></a>过程记录</h2><p>输入有毒。输入有毒。输入有毒。最初一版使用 <code>getchar()</code> 读取 $64$ 位字符串，结果满满的是 WA，一个点都不给过。初步推断可能是输入文件以 <code>\r\n</code> 结尾而程序只考虑了以 <code>\n</code> 结尾的情况。换用 <code>scanf()</code> 后便解决了问题，<s>而这个问题竟然喜提 PA3 中 Debug 时间最久的问题</s>。</p><p>解决过程大致是首先为了控制变量，排除算法实现过程的具体问题，做了以下两个操作：</p><p>(1) 撰写了对拍器 check.py（见附 1），但是本地的数据怎么测都是 AC。</p><p>(2) 撰写了 Trivial.cpp（见附 2），读入部分没变（事实上，最初我认为是后续字典树处理写出了问题，于是想写个最简单的版本交上去看下测试数据的规模），使用最平凡的 $O(nk)$ 的算法处理问题，最终发现还是爆零。目光转向读入部分，改用 <code>scanf</code> 后 Trivial 算法拿到了 40/50（自然会喜提 TLE），然后是将新的读入复制回 <code>main.cpp</code>，前后两次拿到了 50/50, 90/90, <s>完结撒花</s>。</p><h2 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h2><p>从时间上来看，每个结点最多被插入一次，查询一次，删除一次，这些操作的时间复杂度均是正比于树高 $h=O(64)=O(1)$，而对于 $n$ 个结点，我们有时间复杂度是 $O(n)$。</p><p>字典树的每个结点可能对应 $64$​​ 位整数的位表示中的一个字符。也就是说，最多有 $O(64n)=O(n)$​​ 量级的结点个数。而这些结点有小部分是可以复用的。具体来说，根据鸽巢原理，我们设读入 $k$​​ 个字符后，才会出现 $2^k&gt;n$​​，解得 $k\ge19$​​。也就是说，我们可以考虑一种极端的情况，树深度 $depth \le 19$​​ 时为满树，而树深度 $depth \ge 20$​​ 时为单链，这种情况下最多的结点个数为 $\sum_{i=0}^{19}2^i+(64-19)<em>n\approx 2.4</em>10^7=24M$​​​。</p><p>我们的叶结点共有 $O(n)$​ 个，同时每个叶节点都需要维护 1 个列表，因此列表的个数也是 $O(n)$​​ 个，列表的元素的总个数也是 $O(n)$。综上，空间复杂度为 $O(n)$。</p><p>而这题还是有卡常的嫌疑的，也就是说虽然是 $O(n)$​ 量级，但是空间复杂度还是可能有可能会超限，具体分析如下：（$n=5*10^5$）</p><ul><li>非叶结点，24M * 12Byte = 288M.</li><li>列表条目，0.5M * 12Byte = 6M.</li><li>叶结点，0.5M * 20Byte = 10M.</li><li>$64$ 位整数的数据，0.5M * 8Byte = 4M.</li><li>合计 308M &lt; 512M.</li></ul><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="附-1-check-py"><a href="#附-1-check-py" class="headerlink" title="附 1: check.py"></a>附 1: check.py</h3><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> io<span class="token keyword">import</span> time<span class="token keyword">import</span> datetime<span class="token keyword">import</span> random<span class="token keyword">import</span> subprocess<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npIN <span class="token operator">=</span> <span class="token string">''</span>OUT <span class="token operator">=</span> <span class="token string">''</span><span class="token keyword">class</span> <span class="token class-name">Judger</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">generateInputData</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">global</span> IN<span class="token punctuation">,</span> OUT        IN <span class="token operator">=</span> <span class="token string">''</span>        OUT <span class="token operator">=</span> <span class="token string">''</span>        n <span class="token operator">=</span> <span class="token number">10</span>        k <span class="token operator">=</span> <span class="token number">2</span>        IN <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>n<span class="token punctuation">&#125;</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">&#123;</span>k<span class="token punctuation">&#125;</span></span><span class="token string">\n'</span></span>                dataList <span class="token operator">=</span> <span class="token punctuation">[</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token operator">**</span><span class="token number">64</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">]</span>        rawList <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">bin</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>zfill<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span> <span class="token keyword">for</span> data <span class="token keyword">in</span> dataList<span class="token punctuation">]</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>dataList<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>rawList<span class="token punctuation">)</span>        <span class="token keyword">for</span> raw <span class="token keyword">in</span> rawList<span class="token punctuation">:</span>            IN <span class="token operator">+=</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>raw<span class="token punctuation">&#125;</span></span><span class="token string">\n'</span></span>                <span class="token keyword">for</span> index<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataList<span class="token punctuation">)</span><span class="token punctuation">:</span>            left <span class="token operator">=</span> index <span class="token operator">-</span> k <span class="token operator">-</span> <span class="token number">1</span>            <span class="token keyword">if</span> left <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">:</span>                left <span class="token operator">=</span> <span class="token number">0</span>            right <span class="token operator">=</span> index <span class="token operator">+</span> k <span class="token operator">+</span> <span class="token number">1</span>            <span class="token keyword">if</span> right <span class="token operator">></span> n<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>                right <span class="token operator">=</span> n<span class="token operator">-</span><span class="token number">1</span>                        currMaxIndex <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">999</span>            currMaxValue <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">999</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>left<span class="token punctuation">,</span> right<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">==</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>                    <span class="token keyword">continue</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span>dataList<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">^</span> data<span class="token punctuation">)</span> <span class="token operator">></span> currMaxValue<span class="token punctuation">:</span>                    currMaxIndex <span class="token operator">=</span> i                    currMaxValue <span class="token operator">=</span> <span class="token punctuation">(</span>dataList<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">^</span> data<span class="token punctuation">)</span>            OUT <span class="token operator">+=</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>currMaxIndex<span class="token punctuation">&#125;</span></span><span class="token string">\n'</span></span>                <span class="token keyword">return</span> IN    <span class="token keyword">def</span> <span class="token function">getAnswer</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">global</span> OUT        <span class="token keyword">return</span> OUT<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">judge</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> judgeAns<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n\nCompiling...'</span><span class="token punctuation">)</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            subprocess<span class="token punctuation">.</span>check_output<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'g++'</span><span class="token punctuation">,</span> <span class="token string">'-O2'</span><span class="token punctuation">,</span> <span class="token string">'-std=c++14'</span><span class="token punctuation">,</span> <span class="token string">'-w'</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>name<span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> <span class="token string">'-o'</span><span class="token punctuation">,</span> <span class="token string">'main'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">except</span> subprocess<span class="token punctuation">.</span>CalledProcessError <span class="token keyword">as</span> e<span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token string">'CE'</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Generating testing data...'</span><span class="token punctuation">)</span>        data <span class="token operator">=</span> self<span class="token punctuation">.</span>generateInputData<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Running...'</span><span class="token punctuation">)</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            time1 <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>            cppout <span class="token operator">=</span> subprocess<span class="token punctuation">.</span>check_output<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'./main'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token operator">=</span><span class="token builtin">bytes</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> timeout<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">)</span>            cppout <span class="token operator">=</span> cppout<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>            time2 <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">except</span> subprocess<span class="token punctuation">.</span>TimeoutExpired<span class="token punctuation">:</span>            f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'check-</span><span class="token interpolation"><span class="token punctuation">&#123;</span>datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">"%Y-%m-%d-%H-%M-%S"</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">.log'</span></span><span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Time Limit Exceeded\n"</span></span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"-------------IN--------------\n"</span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>data <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f'Time Limit Exceeded (2.000s)'</span></span>        <span class="token keyword">except</span> subprocess<span class="token punctuation">.</span>CalledProcessError <span class="token keyword">as</span> e<span class="token punctuation">:</span>            f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'check-</span><span class="token interpolation"><span class="token punctuation">&#123;</span>datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">"%Y-%m-%d-%H-%M-%S"</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">.log'</span></span><span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Runtime Error (signal </span><span class="token interpolation"><span class="token punctuation">&#123;</span>e<span class="token punctuation">.</span>returncode<span class="token punctuation">&#125;</span></span><span class="token string">)\n"</span></span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"-------------IN--------------\n"</span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>data <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f'Runtime Error (Signal </span><span class="token interpolation"><span class="token punctuation">&#123;</span>e<span class="token punctuation">.</span>returncode<span class="token punctuation">&#125;</span></span><span class="token string">)'</span></span>        <span class="token keyword">if</span> judgeAns<span class="token punctuation">:</span>            <span class="token comment"># print(cppout)</span>            <span class="token comment"># print("↑ cppout ↓ ans")</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Generating testing answer...'</span><span class="token punctuation">)</span>            ans <span class="token operator">=</span> self<span class="token punctuation">.</span>getAnswer<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># print(ans)</span>                        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Judging...'</span><span class="token punctuation">)</span>            <span class="token keyword">try</span><span class="token punctuation">:</span>                cppout_ <span class="token operator">=</span> cppout<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>                ans_ <span class="token operator">=</span> ans<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>cppout_<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>ans_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    <span class="token keyword">raise</span> BaseException<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>                <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>cppout_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    <span class="token keyword">if</span> <span class="token punctuation">(</span>cppout_<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> ans_<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                        <span class="token keyword">raise</span> BaseException<span class="token punctuation">(</span>i<span class="token punctuation">)</span>            <span class="token keyword">except</span> BaseException <span class="token keyword">as</span> e<span class="token punctuation">:</span>                f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'check-</span><span class="token interpolation"><span class="token punctuation">&#123;</span>datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">"%Y-%m-%d-%H-%M-%S"</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">.log'</span></span><span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Wrong Answer on line </span><span class="token interpolation"><span class="token punctuation">&#123;</span>e<span class="token punctuation">&#125;</span></span><span class="token string">\n"</span></span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"-------------IN--------------\n"</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>data <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"-------------CPPOUT--------------\n"</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>cppout <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"-------------ANS--------------\n"</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>ans <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">return</span> <span class="token string">'Wrong Answer'</span>            <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f'Accepted (</span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">round</span><span class="token punctuation">(</span>time2 <span class="token operator">-</span> time1<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">s)'</span></span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f'Program exited successfully (</span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">round</span><span class="token punctuation">(</span>time2 <span class="token operator">-</span> time1<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">s)'</span></span>        j <span class="token operator">=</span> Judger<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>j<span class="token punctuation">.</span>judge<span class="token punctuation">(</span><span class="token string">'trivial.cpp'</span><span class="token punctuation">,</span> judgeAns<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="附-2-Trivial-cpp"><a href="#附-2-Trivial-cpp" class="headerlink" title="附 2: Trivial.cpp"></a>附 2: Trivial.cpp</h3><pre class="language-cpp" data-language="cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">ull</span> <span class="token expression"><span class="token keyword">unsigned</span> <span class="token keyword">long</span> <span class="token keyword">long</span></span></span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;cstdio></span></span><span class="token keyword">int</span> n<span class="token punctuation">,</span> k<span class="token punctuation">;</span>ull data<span class="token punctuation">[</span><span class="token number">500001</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token number">0</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    <span class="token function">scanf</span><span class="token punctuation">(</span><span class="token string">"%d %d\n"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>n<span class="token punctuation">,</span> <span class="token operator">&amp;</span>k<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> i <span class="token operator">&lt;=</span> n<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token keyword">char</span> c <span class="token operator">=</span> <span class="token function">getchar</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>c <span class="token operator">==</span> <span class="token string">'0'</span> <span class="token operator">||</span> c <span class="token operator">==</span> <span class="token string">'1'</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>            data<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;&lt;=</span> <span class="token number">1</span><span class="token punctuation">;</span>            data<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+=</span> c <span class="token operator">-</span> <span class="token string">'0'</span><span class="token punctuation">;</span>            c <span class="token operator">=</span> <span class="token function">getchar</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">&#125;</span>    <span class="token punctuation">&#125;</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> i <span class="token operator">&lt;=</span> n<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>                <span class="token keyword">int</span> l <span class="token operator">=</span> i<span class="token operator">-</span>k<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>l <span class="token operator">&lt;</span> <span class="token number">1</span><span class="token punctuation">)</span> l <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> r <span class="token operator">=</span> i <span class="token operator">+</span> k <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>r <span class="token operator">></span> n<span class="token punctuation">)</span> r <span class="token operator">=</span> n<span class="token punctuation">;</span>                ull currMax <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        ull currMaxIndex <span class="token operator">=</span> l <span class="token operator">!=</span> i <span class="token operator">?</span> l <span class="token operator">:</span> <span class="token punctuation">(</span>l <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> T <span class="token operator">=</span> l<span class="token punctuation">;</span> T <span class="token operator">&lt;=</span> r<span class="token punctuation">;</span> <span class="token operator">++</span>T<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>T <span class="token operator">==</span> i<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span><span class="token keyword">continue</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>data<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token operator">^</span>data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">></span>currMax<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>                currMax <span class="token operator">=</span> data<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">^</span> data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>                currMaxIndex <span class="token operator">=</span> T<span class="token punctuation">;</span>            <span class="token punctuation">&#125;</span>        <span class="token punctuation">&#125;</span>        <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"%d"</span><span class="token punctuation">,</span> currMaxIndex<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>i <span class="token operator">!=</span> n<span class="token punctuation">)</span> <span class="token function">puts</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span></code></pre><h1 id="CST2021F-3-3-kth"><a href="#CST2021F-3-3-kth" class="headerlink" title="CST2021F 3-3 kth"></a>CST2021F 3-3 kth</h1><p>​    <strong>[关键词] 堆，偏序关系，归并排序</strong></p><h2 id="方案设计-1"><a href="#方案设计-1" class="headerlink" title="方案设计"></a>方案设计</h2><h3 id="偏序关系"><a href="#偏序关系" class="headerlink" title="偏序关系"></a>偏序关系</h3><p>首先我们可以回忆出针对一维数组寻找第 $k$​ 大元素问题的解决方案。我们可以将原数组直接建小顶堆后，第 $k$​ 次 pop 出的元素即为所求，时间复杂度为 $O(n+k*\log n)$​​。而稍微再仔细考虑我们的建堆过程，实际上我们是将这一维数组中的所有元素之间建立起一种偏序关系。没错，偏序关系，这也是接下来我们讨论的重点。</p><h3 id="二维情况"><a href="#二维情况" class="headerlink" title="二维情况"></a>二维情况</h3><p>再来考虑针对两个数组的情况。首先我们可以固定某个 $X$ 元素，将 $Y$ 元素的顺序排序；然后固定某个 $Y$ 元素，将 $X$ 元素进行排序。这里排序的意思是说，找到一个序列 $(new_1, new_2, \cdots, new_n)$，使得 $X_{new_i} = sorted(X)[i]$。之后我们便可以记 $X[i]:=X_{new_i}=sorted(X)[i]$.</p><p>针对两个数组的情况，我们记 $(i,j)$ 表示值 $X[i]+Y[j]$。可以对于 $(i_1, j_1)$ 与 $(i_2, j_2)$，我们有：</p><ul><li>$(i_1,j_1) \le (i_2, j_2)$, if $i_1 \le i_2$ and $j_1 \le j_2$.</li></ul><p>由于我们的内存有限，我们能放在堆中的元素是有限的。所以我们要想出一种组织这些元素的方式，使得每个元素能且仅能出现在小顶堆中一次，也就是说，我们要建立一种新的偏序关系 $M$​​，使得 $\forall (i,j)$, 集合 $\{(x,y)\ |\ (x,y) \le_M (i,j) \ \and\ (x,y)\ne(i,j) \}$ 有最大元 $(m,n)$，即当且仅当 $(m,n)$ 出堆，$(i,j)$ 才能入堆，且这种偏序关系满足如果 $(x,y) \le_M(i,j)$，那么 $(x,y) \le (i,j)$​​​​。</p><p>对于数组有两个维度的情况，我们可以构造偏序关系 $M$ 如下图：</p><p><img src="https://i.loli.net/2021/11/30/ebFOURVMwqcm56J.png" alt="image-20211130004938307.png"></p><p>对于某个顶点 $(i,j)$，可以验证从比它小的元素指向它的边的入度均为 $1$（根节点除外），此即保证了每个元素都能入堆（当在新的偏序关系下，比它小的元素的极大值出堆，即当与它直接相连但比它小的那个顶点出堆，注意这里的“小”均为在新的偏序关系下），且每个元素仅能入堆一次。</p><p>于是我们便可以首先将 $(1,1)$ 推入小顶堆中，然后每 pop 一次，将其出边对应的结点推入堆中。这样 pop $k$ 次后得到的 $(x,y)$​ 即为所求。</p><h3 id="三维情况"><a href="#三维情况" class="headerlink" title="三维情况"></a>三维情况</h3><p>在三个数组的情况，我们采用与上述类似的记号，而建立的偏序关系如下图：</p><p><img src="https://i.loli.net/2021/11/30/nq3Vba9K1WA4P8J.png" alt="image-20211130005405726.png"></p><p>于是我们便可以首先将 $(1,1,1)$​​ 推入小顶堆中，然后每 pop 一次，将其出边对应的结点推入堆中。这样 pop $k$​​ 次后得到的 $(x,y,z)$​​ 即为所求。</p><h2 id="过程记录-1"><a href="#过程记录-1" class="headerlink" title="过程记录"></a>过程记录</h2><ul><li><p>首先对原有的 X，Y，Z 数组进行归并排序，具体来说是找到上述的 $X$​</p></li><li><p>编写 <code>Index</code> 类模拟上述定义的索引 tuple。可以简单地通过重载运算符来实现两个 <code>Index</code> 之间的比较（调用交互库函数）。</p></li><li>注意按照上述拓扑关系建立 <code>Index</code> 之间的新偏序关系，以保证所有顶点能且仅能被推入堆中一次。</li></ul><h2 id="复杂度分析-1"><a href="#复杂度分析-1" class="headerlink" title="复杂度分析"></a>复杂度分析</h2><p>从时间上来说，归并排序所需时间复杂度为 $O(n \log n)$​。注意到上述所有结点最多有 3 条出边，即运行 $k$​ 次上述操作后，可以保证堆中的结点数不超过 $3*k=O(k)$​。对于这样的堆，运行 $k$​ 次 pop，$O(3k)$​ 次 insert，我们有时间复杂度为 $O(k \log k)$​​​。​于是总体时间复杂度为 $O(n \log n + k \log k)$。</p><p>对原数组进行排序的归并排序数组辅助空间为 $O(n)$​，堆开辟的空间大小为 $O(3k)=O(k)$​。总空间复杂度为 $O(n+k)$。</p><h1 id="CST2021F-3-5-Prefix"><a href="#CST2021F-3-5-Prefix" class="headerlink" title="CST2021F 3-5 Prefix"></a>CST2021F 3-5 Prefix</h1><p>​    <strong>[关键词] KMP next[] 表，动态规划</strong></p><h2 id="方案设计-2"><a href="#方案设计-2" class="headerlink" title="方案设计"></a>方案设计</h2><h3 id="关键概念定义"><a href="#关键概念定义" class="headerlink" title="关键概念定义"></a>关键概念定义</h3><p>这里我们采用一种与题目和课堂讲义上不同的字符串及 <code>next[]</code> 表表示方式，具体介绍如下：</p><ul><li>对于长度为 $n$ 的串 $S$，记之为 $S[1…n]$​. (Index starts from 1)</li><li>记 $next[j]$​ 表示 <strong>$S[1…j]$​​ 中最大自匹配的真前缀和真后缀的串长</strong>，也就是说，与讲义中偏重 Pattern String 下一次移动到的位置不同，我们更加侧重的是这个长度值。举个例子：</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">i</th><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th></tr></thead><tbody><tr><td style="text-align:center">raw[i]</td><td>*</td><td>a</td><td>a</td><td>b</td><td>a</td><td>a</td><td>b</td></tr><tr><td style="text-align:center">next[i]</td><td>-1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>2</td><td>3</td></tr></tbody></table></div><p>可以证明，这种 next[] 表与讲义上的 next[] 表只偏差了一个 offset。</p><h3 id="next-表的构建"><a href="#next-表的构建" class="headerlink" title="next[] 表的构建"></a>next[] 表的构建</h3><p>根据我们的定义，$next[j]$​​ 代表 $S[1…j]$​​ 中<strong>最大自匹配的真前缀和真后缀的串长</strong>，而这个真前缀便是 $S[1…next[j]]$​。</p><p>于是，在我们采用递推的方式计算 $next[j+1]$​ 时，我们要寻找的是 $S[1…j+1]$​ 中最大自匹配的真前缀和真后缀的串长。</p><p>我们已知 $S[1…t]$​ 与 $S[j-t+1… j]$​ 是匹配的，这里 <strong>$t \in \{next[j], next[next[j]], next[next[next[j]]] \cdots\} =: T_j$​</strong>。</p><p>于是，我们便可以逐个考虑序列 $T_j$ 中的元素：</p><ul><li>如果 $S[j+1]$​​ 与 $S[t+1]$​​ 相等，我们便找到了 $S[1…j+1]$​​ 的一个最大的自匹配的真前缀与真后缀，此即 $next[j+1] \leftarrow t+1$.</li><li>不然，我们转而考虑这个序列的下一个元素。</li></ul><p>由于这个序列最后必然收敛于通配符 <code>*</code>，算法必定终止。</p><h3 id="动态规划求前缀出现次数"><a href="#动态规划求前缀出现次数" class="headerlink" title="动态规划求前缀出现次数"></a>动态规划求前缀出现次数</h3><p>考虑串 <code>aabaabaab</code>，定义 $dp[j]$ 表示 $S[1…j]$ 的所有真前缀与真后缀相匹配的次数。可得下表：</p><div class="table-container"><table><thead><tr><th>i</th><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th></tr></thead><tbody><tr><td>raw[i]</td><td>*</td><td>a</td><td>a</td><td>b</td><td>a</td><td>a</td><td>b</td><td>a</td><td>a</td><td>b</td></tr><tr><td>next[i]</td><td>-1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td></tr><tr><td>dp[i]</td><td>-</td><td>0</td><td>1</td><td>0</td><td>1</td><td>2</td><td>1</td><td>2</td><td>3</td><td>2</td></tr></tbody></table></div><p>归纳可证明：</p><script type="math/tex; mode=display">dp[i] =\begin{cases}0, & next[i] = 0, \\dp[next[i]]+1, & next[i] \gt 0.\end{cases}</script><p>最后我们的答案还需要考虑整个子串自匹配的情况，即 $S[1…j]$ 在 $S[1…n]$ 中出现过一次，$\forall j \in [1, n]$.</p><p>于是答案便是 $n + \sum_{i=1}^ndp[i]$.</p><h2 id="过程记录-2"><a href="#过程记录-2" class="headerlink" title="过程记录"></a>过程记录</h2><ul><li>通过引入通配符 <code>*</code> 这个哨兵结点，可以有效地进行递推。</li><li>需要用 <code>long long</code> 来存储答案数值。</li><li>同时记录 $raw, next, dp$ 会导致内存溢出，因为 $(1+4+8)*20M = 260M &gt; 256M.$<ul><li>首先想到的解决方案是，由于答案的大小不会超过 $(20M)^2=4e14$，而 $\log_2(4*10^{14})=2+\frac {14} {\lg2} \approx 49$，使用 $56$ 个 bit 便可以将其储存。<ul><li>于是我们可以撰写自己的 <code>int56</code> 类，在 get 与 set 对应整数的时候将 <code>long long</code> 通过位运算拆成 <code>char</code>, <code>short</code>, <code>int</code> 三部分（7 Byte）。</li><li>经过此种优化之后，内存用量为 $240M$，便有了通过的可能。</li></ul></li><li><s>但是转而一想，数据结构并不是汇编程序设计。</s><ul><li>事实上我们按照上述解题思路不难得出，我们是先算出了 $next$ 数组中的所有值，然后根据 $next$ 数组的值去递推 $dp$ 数组。</li><li>事实上，我们可以考虑只建立一个 $next$​ 数组，为 <code>long long</code> 类型，首先在其中算出所有 $next_j$，然后根据这个 $next_j$ 计算 $dp_i$，实行就地覆盖的方法，并不会影响答案的结果。</li></ul></li></ul></li></ul><h2 id="复杂度分析-2"><a href="#复杂度分析-2" class="headerlink" title="复杂度分析"></a>复杂度分析</h2><p>KMP 的 next[] 表构建过程时间复杂度为 $O(n)$，之后根据 $next$ 递推 $dp$ 与累加求和的复杂度均为 $O(n)$。于是时间复杂度为 $O(n)$。</p><p>空间上，使用 $raw$​ 与 $next$​ 数组均为 $O(n)$​ 大小，最大内存使用量为 $20M*9=180M&lt;256M$。</p><h1 id="CST2021F-3-7-Sort"><a href="#CST2021F-3-7-Sort" class="headerlink" title="CST2021F 3-7 Sort"></a>CST2021F 3-7 Sort</h1><p>​    <strong>[关键词] 归并排序， 四路归并</strong></p><h2 id="方案设计-3"><a href="#方案设计-3" class="headerlink" title="方案设计"></a>方案设计</h2><p>首先由题目测试数据给出的 $n$ 和 $k$ 的大小关系我们可以果断摒弃掉最坏情况为 $O(n^2)$ 的冒泡排序，选择排序等等算法。这些算法即使在一次能比较的数的个数上进行了优化，这也只是常数级别的，并不能撼动其数量级的地位。</p><p>目光自然转向了复杂度为 $O(n \log n)$ 的快速排序和归并排序上。我们要做的，便是利用比较器一次可以比较三个数的性质，对这些复杂度已经达到理论下界的算法进行常数级别的优化。</p><p>这里由于归并排序的稳定性，所以首选的是归并排序。首先我们自然可以想到的是，模仿二路归并的具体实现，如果比较器一次可以比较三个数，那么我们可以尝试实现三路归并，这样需要求解的递推方程为 $Cmp(n) = 3*Cmp(\frac n 3) + n$​，这是基于每经过一次比较，我们就可以确定三路中的最小元素，并将其从三路中取出，放置于数组的对应位置​。</p><p>但是如果我们代入 $n=3^k$​​ 对该方程求解，我们得出 $a_k=(k+1)<em>3^k$​​，其中 $a_k=Cmp(3^k)$​​，此即 $Cmp(n) \sim n</em>\log_3n$​​。代入 $n=10^6$ 我们有 $Cmp(n) \approx 7.6*10^7$。不能满足我们对 $limit$ 的要求。</p><p>于是想法转移到能否更加 exploit 比较器返回的结果中包含的信息。具体来说，在三路归并中，每次比较都能返回 $a&lt;b&lt;c$，我们只运用到了 $a&lt;b$, $a&lt;c$ 这两个部分，并没有利用到 $c$​ 是三者的最大值这么一个条件。而一旦 $c$ 是最大值，由于有 $b&lt;c$，可以保证在下次的比较过程中，$c$ 一定不是三者中的最小值。这竟然退化成了 $b,c,d$ 比较，实际上我们用比较器只比较了 $b, d$ 的二路归并的情况。</p><p>于是再进一步，我们考虑可以使用四路归并，便可以尽力 exploit 比较器的返回信息。具体来说，和上述想法相似，对于待合并数组 $a,b,c,d$，一旦我们在 $a,b,c$ 中比较得到 $a&lt;b&lt;c$，在下一次比较选择最小值时，我们便可以忽略掉 $c$，只比较 $next(a), b,d$，其正确性由 $b&lt;c$，即 $c$ 一定不是最小值保证。</p><p>这样需要求解的递推方程为 $Cmp(n) = 4<em>Cmp(\frac n 4) + n$​，此即 $Cmp(n) \sim n</em>\log_4n$​。代入 $n=10^6$​ 我们有 $Cmp(n) \approx 9.97*10^6&lt;limit_n$​。</p><h2 id="过程记录-3"><a href="#过程记录-3" class="headerlink" title="过程记录"></a>过程记录</h2><p>四路归并的具体实现过程中，递归过程与二路归并类似，而重点在于四路合并的过程。具体来说，我们可以先在 $a,b,c,d$ 四个数组中选取前三个数组 $a,b,c$ 做一次比较，将三者中的最大值的数组信息记录在一个全局变量 <code>nextBypass</code> 中。</p><p>然后我们便可以进入循环，每次比较除了该全局变量 <code>nextBypass</code> 记录的数组的剩下三个数组的首元素的相对大小信息，然后将三者中的最大值所在的数组信息更新给全局变量 <code>nextBypass</code>，而将最小值写入最终的合并后数组中，直到四路中某个数组耗竭，退化成上述平凡的三路归并的情况，进而退化成更加平凡的二路归并的情况，进而退化成更加更加平凡的数组拷贝的情况。</p><h2 id="复杂度分析-3"><a href="#复杂度分析-3" class="headerlink" title="复杂度分析"></a>复杂度分析</h2><p>四路归并中，时间复杂度方程与 $Cmp(n) = 4*Cmp(\frac n 4) + n$ 同构，即 $T(n) = O(n \log_4 n)$。而我们在上文也证明了比较次数 $Cmp(n) = O(n \log_4 n)$。</p><p>在空间上，主要开辟的是 $a,b,c,d$ 四个数组的辅助空间，空间复杂度为 $O(n)$。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;内含以下题目的实验报告：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CST2021F 3-1 Circuit&lt;/li&gt;
&lt;li&gt;CST2021F 3-3 kth&lt;/li&gt;
&lt;li&gt;CST2021F 3-5 Prefix&lt;/li&gt;
&lt;li&gt;CST2021F 3-7 Sort&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里不提供任何解题代码，仅将解题的白盒报告归档处理。&lt;/p&gt;
&lt;p&gt;本博文仅做参考使用，任何可能影响您查重结果的行为请您后果自负！&lt;/p&gt;
&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Problem&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;White Box (20%)&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Black Box (80%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F 3-1 Circuit (25%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;100&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[100] -1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F 3-3 kth (25%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;100&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[100] -1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F 3-5 Prefix (25%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;100&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[100] -1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F 3-7 Sort (25%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;100&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[100] -1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;</summary>
    
    
    
    <category term="程设" scheme="https://www.c7w.tech/categories/%E7%A8%8B%E8%AE%BE/"/>
    
    <category term="程设/数据结构" scheme="https://www.c7w.tech/categories/%E7%A8%8B%E8%AE%BE/%E7%A8%8B%E8%AE%BE-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="数据结构" scheme="https://www.c7w.tech/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>《数据结构》课程 PA2 报告</title>
    <link href="https://www.c7w.tech/dsa-pa2/"/>
    <id>https://www.c7w.tech/dsa-pa2/</id>
    <published>2022-01-09T16:00:02.000Z</published>
    <updated>2022-01-29T11:13:02.642Z</updated>
    
    <content type="html"><![CDATA[<p>内含以下题目的实验报告：</p><ul><li>CST2021F 2-1 Build</li><li>CST2021F 2-2 Not Found</li><li>CST2021F 2-4-2 Kidd</li><li>CST2021F 2-6 Hacker</li></ul><p>这里不提供任何解题代码，仅将解题的白盒报告归档处理。</p><p>本博文仅做参考使用，任何可能影响您查重结果的行为请您后果自负！</p><div class="table-container"><table><thead><tr><th style="text-align:center">Problem</th><th style="text-align:center">White Box (20%)</th><th style="text-align:center">Black Box (80%)</th></tr></thead><tbody><tr><td style="text-align:center">CST2021F 2-1 Build (25%)</td><td style="text-align:center">100</td><td style="text-align:center">[100] -1</td></tr><tr><td style="text-align:center">CST2021F 2-2 Not Found (25%)</td><td style="text-align:center">95</td><td style="text-align:center">[100] -1</td></tr><tr><td style="text-align:center">CST2021F 2-4-2 Kidd (25%)</td><td style="text-align:center">95</td><td style="text-align:center">[100] -1</td></tr><tr><td style="text-align:center">CST2021F 2-6 Hacker (25%)</td><td style="text-align:center">100</td><td style="text-align:center">[100] -2</td></tr></tbody></table></div><a id="more"></a><h2 id="CST2021F-2-1-NotFound"><a href="#CST2021F-2-1-NotFound" class="headerlink" title="CST2021F 2-1 NotFound"></a>CST2021F 2-1 NotFound</h2><p>​    <strong>[关键词] 父亲-长子-兄弟法的多叉树表示，List</strong></p><h3 id="方案设计"><a href="#方案设计" class="headerlink" title="方案设计"></a>方案设计</h3><h4 id="结点"><a href="#结点" class="headerlink" title="结点"></a>结点</h4><p>每个结点需要维护以下信息。</p><ul><li><code>parent</code>，指向父亲的指针</li><li><code>firstChild</code>，指向长子的指针</li><li><code>nextSibling</code>，指向下一个兄弟的指针</li><li><code>prevSibling</code>，指向前一个兄弟的指针</li><li><code>height</code>，子树高度</li><li><code>size</code>，子树规模</li><li><code>suffixMaxHeight</code>，以自己为基点，自己及自己之后的兄弟的高度的最大值</li><li><code>childLength</code>，孩子个数</li><li><code>childPushed</code>，在建树时用到的临时变量</li></ul><p>其中 <code>suffixMaxHeight</code> 的维护是基于复杂度分析的考量。每次更新时我们需保证复杂度不大于 $O(cost)$，$cost$ 中包含了结点的 $Rank$、也就是说，为了避免遍历所有孩子结点，我们可以考虑维护后续高度的最大值，然后只更新<strong>长子</strong>到<strong>本结点</strong>这些兄弟的高度最大值即可。父亲的高度自然是长子的 <code>suffixMaxHeight</code> + 1。这样就保证了单步更新高度复杂度在 $O(Rank)$，进而整体更新高度 $O(cost)$​ 范围内。</p><h4 id="建树"><a href="#建树" class="headerlink" title="建树"></a>建树</h4><p>我们在遍历初始树的时候按照以下原则，效力从上到下递减：</p><ul><li>如果一个结点的 <code>childPushed</code> 为 <code>false</code>，那么将其该字段设为 <code>true</code>，并将其压入栈中，将其所有孩子按照长子到末子的顺序压入栈中。</li><li>如果一个结点是叶节点，那么直接将其预处理。<ul><li>$height \leftarrow 0$​</li><li>$size \leftarrow 1$</li><li>$suffixMaxHeight \leftarrow \max(suffixMaxHeight_{nextSibling?}, height)$​​</li><li>$parent?.height \leftarrow parent?.height+1 $</li></ul></li><li>不然我们得出该结点一定有长子，且其所有孩子一定先于其被预处理。<ul><li>$height \leftarrow firstChild.suffixMaxHeight +1$</li><li>$size \leftarrow size + 1$​</li><li>$suffixMaxHeight \leftarrow \max(suffixMaxHeight_{nextSibling?}, height)$</li><li>$parent?.height \leftarrow parent?.height+1 $</li></ul></li><li>其中 $?$ 表示对其不存在的情况做特判。</li></ul><h4 id="删除子树"><a href="#删除子树" class="headerlink" title="删除子树"></a>删除子树</h4><p>分待删除子树是不是长子两种情况考虑。</p><ul><li>改变子树局部的拓扑结构</li><li>沿“祖父”链更新子树规模</li><li>沿“结点$\rightarrow$长子$\rightarrow$父亲$\rightarrow\cdots$”链更新 <code>height</code> 与 <code>suffixMaxHeight</code></li></ul><h4 id="插入子树"><a href="#插入子树" class="headerlink" title="插入子树"></a>插入子树</h4><p>分待插入子树是不是长子两种情况考虑。</p><ul><li>改变子树局部的拓扑结构</li><li>沿“祖父”链更新子树规模</li><li>沿“结点$\rightarrow$长子$\rightarrow$父亲$\rightarrow\cdots$”链更新 <code>height</code> 与 <code>suffixMaxHeight</code></li></ul><h4 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h4><p>根据我们维护的 <code>size</code> 和 <code>height</code>，找到对应节点输出相应数据即可。</p><h3 id="过程记录"><a href="#过程记录" class="headerlink" title="过程记录"></a>过程记录</h3><blockquote><p>目的位置的节点表示为移除源子树后的节点表示。</p></blockquote><p>题没读完就下手，对拍写的都是错的，痛苦 Debug 一天，然后不及 5min 读一遍题有效。</p><p>具体来说，提交记录交了 5 页，assert 出某个测试数据要在某个我认为的“叶节点”的第 1 个位置插入元素。猜测拓扑结构的查询或是更新出了问题，但小数据可以 AC，感觉大部分移动都是没问题的。于是感觉有种特殊情况处理的不对。大不解，重新读题…</p><p>事实上理解题意之后也直接可以手写一组小数据 Hack 掉自己的程序。</p><p>本题唯一有思想价值的是 <code>suffixMaxHeight</code> 的维护。既然不能在更新子树时遍历所有孩子，而复杂度要求我们可以在 $Rank$ 内完成子树的维护，于是我们就想到这样一种类似于区间最值的维护手段，每次更新只更新 $[0, Rank]$​ 的数据即可。</p><h3 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p>在建树时每个结点至多被压入栈中两次，预处理可以视为 $O(1)$ 时间，因而建树的时间复杂度为 $O(n)$。</p><p>按照上面对 <code>suffixMaxHeight</code> 维护的分析，所有单步操作 $i$ 的复杂度被 $O(cost_i)$ 所控制，因而整体 $m$ 次操作的复杂度被 $O(cost)$ 所控制。</p><p>总体来看时间复杂度为 $O(n+cost)$。</p><p>空间复杂度方面，只有结点列表和预处理栈大规模使用了空间，复杂度为 $O(n)$。</p><h2 id="CST2021F-2-2-NotFound"><a href="#CST2021F-2-2-NotFound" class="headerlink" title="CST2021F 2-2 NotFound"></a>CST2021F 2-2 NotFound</h2><blockquote><p>归档时注：该方法极有可能在优化不足的情况下被卡常，网络学堂已有人提交对应测例，本人并未对其进行测试。</p></blockquote><p>​    <strong>[关键词] Bitmap, BitMask</strong></p><h3 id="方案设计-1"><a href="#方案设计-1" class="headerlink" title="方案设计"></a>方案设计</h3><h4 id="存储数据"><a href="#存储数据" class="headerlink" title="存储数据"></a>存储数据</h4><p>考虑使用类似于 Bitmap 的结构，来逐位进行存储数据。</p><p>一个 unsigned char 为 8 个 Bit，将长度为 $2^{24}$​ 长的 0/1 串存储需要 $2^{24}/8=2^{21}$​ 个，内存占用 $2$ MB。 </p><h4 id="答案长度"><a href="#答案长度" class="headerlink" title="答案长度"></a>答案长度</h4><p>我们考虑答案长度的上界 $M$，即假设至多需要 $k$​​ 的长度才能得出答案。</p><p>那么字符串中所有长度为 $k$ 的连续字串共有 $n-k+1$ 个。</p><p>而 $k$ 的长度的所有可能情况有 $2^k$ 种。</p><p>于是我们令 $n-k+1<2^k$，即 $2^k+k>n+1$ 时，即可充分地保证答案存在，于是我们得出 $k \ge log_2 n$ 即可。</p><p>事实上，我们证明了答案的最大长度不超过 $log_2 n$​，因此我们不妨取 $M=24$​.</p><p>于是我们可以考虑枚举答案，最多不超过 $\sum_{k=1}^{24} 2^{k}$ 种可能情况。</p><h4 id="判断答案"><a href="#判断答案" class="headerlink" title="判断答案"></a>判断答案</h4><p>对输入字符串进行枚举一次，得出所有不满足答案要求的定长子串的时间为 $O(n)$​。而我们知道，针对不同的答案长度 $k\in[1, M]$​，封顶估计我们只需要枚举字符串 $Mn = 24n$​​​​ 次，便可以得到所有子串的情况。而我们只需要反选出所有可能的答案序列中，最早的一个即可。</p><p>而想要实现反选的效果，我们用 Ans 数组（unsigned char, $2^{21}$​）来记录某种情况是否已经出现。比如在枚举答案长度为 3，输入子串为 101 时，便将 Ans 数组的第 5 个 Bit 置为 1，表示该种情况存在。最终我们只需要输出第一个为 0 的 Bit 的 index 的二进制表示即可。</p><p>同时，一旦我们检测到某个答案长度下的<strong>输入数据的子串数目</strong>与<strong>可能的最多子串数目</strong>相等，便可以剪枝优化。</p><h4 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h4><p><strong>具体来说，我们考虑下面一个例子。</strong></p><p>对样例数据 $10100011$，我们考虑：</p><p>[AnsLen = 1]</p><div class="table-container"><table><thead><tr><th>输入数据的一个小 Window</th><th>Ans 数组</th><th>输入数据在本长度下的子串数目</th></tr></thead><tbody><tr><td>1</td><td>01</td><td>1</td></tr><tr><td>0</td><td>11</td><td>2</td></tr></tbody></table></div><p>[AnsLen = 2]</p><div class="table-container"><table><thead><tr><th>输入数据的一个小 Window</th><th>Ans 数组</th><th>输入数据在本长度下的子串数目</th></tr></thead><tbody><tr><td>10</td><td>0010</td><td>1</td></tr><tr><td>01</td><td>0110</td><td>2</td></tr><tr><td>10</td><td>0110</td><td>2</td></tr><tr><td>00</td><td>1110</td><td>3</td></tr><tr><td>00</td><td>1110</td><td>3</td></tr><tr><td>01</td><td>1110</td><td>3</td></tr><tr><td>11</td><td>1111</td><td>4</td></tr></tbody></table></div><p>[AnsLen = 3]</p><div class="table-container"><table><thead><tr><th>输入数据的一个小 Window</th><th>Ans 数组</th><th>输入数据在本长度下的子串数目</th></tr></thead><tbody><tr><td>101</td><td>00000100</td><td>1</td></tr><tr><td>010</td><td>00100100</td><td>2</td></tr><tr><td>100</td><td>00101100</td><td>3</td></tr><tr><td>000</td><td>10101100</td><td>4</td></tr><tr><td>001</td><td>11101100</td><td>5</td></tr><tr><td>011</td><td>11111100</td><td>6</td></tr></tbody></table></div><p>我们最终判断得到 $6 \ne 2^{3} = 8$​，于是在此时寻找第一个为 0 的元素 $6$ 并输出其在长度为 3 意义下的二进制表示 $110$，即为答案。</p><h3 id="过程记录-1"><a href="#过程记录-1" class="headerlink" title="过程记录"></a>过程记录</h3><p>我们使用“对拍”验证程序的运行时间，具体来说我们生成长度为 $2^{24}$ 的随机测试数据，然后让程序多次实验取最坏情况。</p><p><s>经测试，在随机数据上程序运行的最坏时间为 $0.57s$​​​​。</s></p><p>事实上打开了 O2 优化开关之后运行的平均最坏时间为 $0.2s$。 </p><p>在报告的最后会附上对拍代码。</p><h3 id="复杂度分析-1"><a href="#复杂度分析-1" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p>在空间上，使用了两个大小为 $2^{21}$ 的 unsigned char 数组，不超过 $4$ M。</p><p>在时间上，复杂度主要为对输入子串做连续子串截取与最终的反向寻找答案，二者最坏情况为 $O(n)$，都最多进行 $M$ 次，故最终复杂度为 $O(Mn)=O(n\log n)$​。</p><p>附：Judger 代码</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># Judger by c7w</span><span class="token keyword">import</span> io<span class="token keyword">import</span> time<span class="token keyword">import</span> datetime<span class="token keyword">import</span> random<span class="token keyword">import</span> subprocess<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">class</span> <span class="token class-name">Judger</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">generateInputData</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        IN <span class="token operator">=</span> <span class="token string">''</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">**</span><span class="token number">24</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            IN <span class="token operator">+=</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span>        IN <span class="token operator">+=</span> <span class="token string">'\n'</span>        <span class="token keyword">return</span> IN    <span class="token keyword">def</span> <span class="token function">getAnswer</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        OUT <span class="token operator">=</span> <span class="token string">''</span>        <span class="token keyword">return</span> OUT<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">judge</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> judgeAns<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n\nCompiling...'</span><span class="token punctuation">)</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            subprocess<span class="token punctuation">.</span>check_output<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'g++'</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>name<span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> <span class="token string">'-o'</span><span class="token punctuation">,</span> <span class="token string">'main'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">except</span> subprocess<span class="token punctuation">.</span>CalledProcessError <span class="token keyword">as</span> e<span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token string">'CE'</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Generating testing data...'</span><span class="token punctuation">)</span>        data <span class="token operator">=</span> self<span class="token punctuation">.</span>generateInputData<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Running...'</span><span class="token punctuation">)</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            time1 <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>            cppout <span class="token operator">=</span> subprocess<span class="token punctuation">.</span>check_output<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'./main'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token operator">=</span><span class="token builtin">bytes</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> timeout<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">)</span>            cppout <span class="token operator">=</span> cppout<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>            time2 <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">except</span> subprocess<span class="token punctuation">.</span>TimeoutExpired<span class="token punctuation">:</span>            f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'check-</span><span class="token interpolation"><span class="token punctuation">&#123;</span>datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">"%Y-%m-%d-%H-%M-%S"</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">.log'</span></span><span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Time Limit Exceeded\n"</span></span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"-------------IN--------------\n"</span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>data <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f'Time Limit Exceeded (2.000s)'</span></span>        <span class="token keyword">except</span> subprocess<span class="token punctuation">.</span>CalledProcessError <span class="token keyword">as</span> e<span class="token punctuation">:</span>            f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'check-</span><span class="token interpolation"><span class="token punctuation">&#123;</span>datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">"%Y-%m-%d-%H-%M-%S"</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">.log'</span></span><span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Runtime Error (signal </span><span class="token interpolation"><span class="token punctuation">&#123;</span>e<span class="token punctuation">.</span>returncode<span class="token punctuation">&#125;</span></span><span class="token string">)\n"</span></span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"-------------IN--------------\n"</span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>data <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>            f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f'Runtime Error (Signal </span><span class="token interpolation"><span class="token punctuation">&#123;</span>e<span class="token punctuation">.</span>returncode<span class="token punctuation">&#125;</span></span><span class="token string">)'</span></span>                <span class="token keyword">if</span> judgeAns<span class="token punctuation">:</span>            <span class="token comment"># print(cppout)</span>            <span class="token comment"># print("↑ cppout ↓ ans")</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Generating testing answer...'</span><span class="token punctuation">)</span>            ans <span class="token operator">=</span> self<span class="token punctuation">.</span>getAnswer<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># print(ans)</span>                        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Judging...'</span><span class="token punctuation">)</span>            <span class="token keyword">try</span><span class="token punctuation">:</span>                cppout_ <span class="token operator">=</span> cppout<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>                ans_ <span class="token operator">=</span> ans<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>cppout_<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>ans_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    <span class="token keyword">raise</span> BaseException<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>                <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>cppout_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    <span class="token keyword">if</span> <span class="token punctuation">(</span>cppout_<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> ans_<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                        <span class="token keyword">raise</span> BaseException<span class="token punctuation">(</span>i<span class="token punctuation">)</span>            <span class="token keyword">except</span> BaseException <span class="token keyword">as</span> e<span class="token punctuation">:</span>                f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'check-</span><span class="token interpolation"><span class="token punctuation">&#123;</span>datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">"%Y-%m-%d-%H-%M-%S"</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">.log'</span></span><span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Wrong Answer on line </span><span class="token interpolation"><span class="token punctuation">&#123;</span>e<span class="token punctuation">&#125;</span></span><span class="token string">\n"</span></span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"-------------IN--------------\n"</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>data <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"-------------CPPOUT--------------\n"</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>cppout <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"-------------ANS--------------\n"</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>ans <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>                f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">return</span> <span class="token string">'Wrong Answer'</span>            <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f'Accepted (</span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">round</span><span class="token punctuation">(</span>time2 <span class="token operator">-</span> time1<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">s)'</span></span>                <span class="token keyword">else</span><span class="token punctuation">:</span> <span class="token comment"># Do not judge answer</span>            <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f'Program exited (</span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">round</span><span class="token punctuation">(</span>time2 <span class="token operator">-</span> time1<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">s)'</span></span>        j <span class="token operator">=</span> Judger<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>j<span class="token punctuation">.</span>judge<span class="token punctuation">(</span><span class="token string">'main.cpp'</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h2 id="CST2021F-2-4-2-Kidd"><a href="#CST2021F-2-4-2-Kidd" class="headerlink" title="CST2021F 2-4-2 Kidd"></a>CST2021F 2-4-2 Kidd</h2><p>​    <strong>[关键词] Segment Tree</strong></p><h3 id="方案设计-2"><a href="#方案设计-2" class="headerlink" title="方案设计"></a>方案设计</h3><h4 id="建树-1"><a href="#建树-1" class="headerlink" title="建树"></a>建树</h4><p>首先读入数据，将所有操作预存储。</p><p>将所有 $[i, j]$​ 区间考虑为 $(i-1, j]$​ 的形式，并且将所有的 $(p_i, p_j]$​ 区间合并端点后，排序去重得到分点集合 $\{sep_0, sep_1, sep_2, \cdots, sep_{pos}\}$​​。</p><p>这样，我们便可以将 $(sep_{i-1}, sep_{i}]$​​​​​ 中所有的点在接下来的考虑中等而视之，我们不妨将其<strong>翻转次数和</strong>记作 $a_{i+1}$​。同时我们计算 $(sep_{i-1}, sep_{i}]$​​​​ 中所含有点的个数，来作为最终更新<strong>翻转次数和</strong>的时候该区间对应的权重 $weight$​。</p><p>我们维护两个数组 $sum$ 与 $lazy$​ 表示对应的区间的<strong>翻转总次数和</strong>以及<strong>没有下放的翻转次数</strong>。</p><p><img src="https://i.loli.net/2021/10/25/cwCBoszY5lZEpdm.png" alt="image-20211025173503713"></p><p>图为一颗普通的线段树的样子，其中绿色标记为其在数组中对应的存储下标。</p><p>然后我们就可以用这种数据结构去维护<strong>翻转次数和</strong>以及<strong>懒惰标记</strong>了，更新和查询操作如下。</p><h4 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h4><p><img src="https://i.loli.net/2021/10/25/6hcbXIyVQtr7OZE.png" alt="image-20211025173608364"></p><p>首先，我们要把待更新区间通过在有序分点集合中二分查找，找到其对应的最左区间 $a_l$ 和最右区间 $a_r$。</p><p>现在问题转化成我们要更新 $[a_l, a_r]$​ 中的所有元素。通过分治的方法我们可以将待更新区间分割成如图所示的若干个极大区间 $[a_{i_0}, a_{i_1}], \cdots, [a_{i_k}, a_{i_{k+1}}]$​，然后对其做一次“更新”操作，其中“更新”操作定义如下：</p><ul><li>将自身和自身的所有祖先的 $sum$ 加上自己的权值，表示对应区间翻转次数增加这个权值。</li><li>将自身的“懒惰”标记 $lazy$ 增加 1，表示有一次翻转并没有通知自己的子节点。</li></ul><h4 id="查询-1"><a href="#查询-1" class="headerlink" title="查询"></a>查询</h4><p><img src="https://i.loli.net/2021/10/25/EsUpMG86bPRTlwi.png" alt="image-20211025174102147"></p><p>首先，我们要把待查询区间通过在有序分点集合中二分查找，找到其对应的最左区间 $a_l$ 和最右区间 $a_r$​。</p><p>现在问题转化成我们要查找 $[a_l, a_r]$​ 中的所有元素。通过分治的方法我们可以将待查找区间分割成如图所示的若干个极大区间 $[a_{i_0}, a_{i_1}], \cdots, [a_{i_k}, a_{i_{k+1}}]$​，然后对其做一次“查找”操作，其中“查找”操作定义如下：</p><ul><li>在“分割”成极大子区间的过程中，如果一个含有懒惰标记的区间 $a_i$​​ 被分割，那么将该懒惰标记释放，同时其两个子区间 $a_j, a_k$​​ 要更新其 $sum$​​ 值和 $lazy$ 值：<ul><li>$sum_j \leftarrow sum_j + weight_j*lazy_i$​</li><li>$sum_k \leftarrow sum_k + weight_k*lazy_i$​</li><li>$lazy_j \leftarrow lazy_j + lazy_i$</li><li>$lazy_k \leftarrow lazy_k + lazy_i$</li><li>事实上，这是对之前更新时并未更新子区间的翻转次数和的“延时效应”的激活。</li></ul></li><li>返回各个极大子区间的 $sum$ 值之和。</li></ul><h3 id="过程记录-2"><a href="#过程记录-2" class="headerlink" title="过程记录"></a>过程记录</h3><p>理清思路是很重要的。</p><p>在首次划分区间的时候，并没有考虑 $(0, sep_0]$ 和 $(sep_{pos-1}, n]$ 这两个区段，导致算法运行时出现错误。</p><p>经过考虑不妨补充上这两个区间，即使 $sep_0 = 0$ 或是 $sep_{pos-1} = n$​，将其作为哨兵结点即可，在有序分点集合的二分查找中也不会命中它们。</p><h3 id="复杂度分析-2"><a href="#复杂度分析-2" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p>设分点总数为 $M$​​，可知 $M \le 2m$​​​，即 $M = O(m)$。</p><p>建树时排序 $O(Mlog M)$​，去重 $O(M)$​。在求权重时调用了递归方程对每个区间都求了权重，$T(M) = 2T(\frac M 2) +O(1)$，解递归方程复杂度 $O(M)$​。</p><p>更新时，首先在有序分点集合进行二分查找，复杂度 $O(logM)$​。因为有了懒惰标记，所以更新 $sum$​ 值的节点的个数被树高控制，即更新时复杂度为 $O(logM)$​。于是单次更新的复杂度为 $O((logM)^2)$​。</p><p>而在查询时，首先在有序分点集合进行二分查找，复杂度 $O(logM)$。因为极大区间存储了其对应子区间的 $sum$ 值总和，所以我们不需要遍历每一个子节点，与查询相关的极大子区间个数也被树高控制。于是单次查询的复杂度为 $O((logM)^2)$​。</p><p>由此我们可以得出，本算法的时间复杂度为 $O(MlogMlogM)$​​，即 $O(m\log m\log m)$.</p><p>而在空间上，我们使用的分点集合大小为 $M$​​​​，线段树对应的每个 $sum$​​​, $lazy$​​​, $weight$​​​ 的元素个数为 $O(m)$，于是我们得出空间复杂度为 $O(m)$​​​.</p><h2 id="CST2021F-2-6-Hacker"><a href="#CST2021F-2-6-Hacker" class="headerlink" title="CST2021F 2-6 Hacker"></a>CST2021F 2-6 Hacker</h2><p>​    <strong>[关键词] Hash, CRC32, Bitmask</strong></p><h3 id="方案设计-3"><a href="#方案设计-3" class="headerlink" title="方案设计"></a>方案设计</h3><h4 id="密码表示"><a href="#密码表示" class="headerlink" title="密码表示"></a>密码表示</h4><p>首先我们建立密码可能存在的字符与整数的对应关系。</p><ul><li>‘0’ ~ ‘9’ 映射至 0 ~ 9</li><li>‘t’, ‘s’, ‘i’, ‘n’, ‘g’, ‘h’, ‘u’, ‘a’ 映射至 10 ~ 17</li></ul><p>用字符数组来存储不方便我们进行管理，由于每个密码长度不超过八位，我们做以下规定：</p><ul><li>使用 <code>long long</code> ($64$ Bit) 来表示一个密码</li><li>密码的后 $4$ 个 Bit 表示密码长度.</li><li>密码的后 $[5k+4, 5k+9)$​ 个 Bit 表示倒数第 $k$ 个字符。</li></ul><p>比如，密码 <code>222</code> 可以表示为 $0b0000200002000020011$ </p><p>我们可以通过方便的移位操作和与操作来取出对应位数的字符。</p><p>将密码组织成密码结点的形式，存储其 salted(CRC32) 值，当前密码以及下一个同样 key 的密码结点的地址。</p><p>特别的，如果一个 CRC32 值已冲突，我们将密码记为 -1，即 $11111 \cdots 1111$。​</p><h4 id="散列表"><a href="#散列表" class="headerlink" title="散列表"></a>散列表</h4><p>我们的取模值 M 取为 5999993.</p><p>我们的 HashTable 取长度为 M，待插入其中的元素 key 为 $salted(CRC32) \mod M$​​，值为对应的密码结点地址。</p><h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><p>首先我们需要把 $\bigcup_{i=1}^{5} \Sigma^i$​​ 的所有字符串加入 HashTable 中。</p><p>根据 <code>CRC32</code> 函数的流拼接性质，我们使用队列来实现类似广度优先搜索的操作。</p><p>具体来说，首先向散列表插入 $\Sigma$ 中的所有元素，并将其入队。如果队列中还有剩余元素，那么首先向散列表插入将其与 $\Sigma$ 中所有元素拼接的结果，如果这些结果长度小于 5，那么继续将其入队。</p><h4 id="散列表的动态操作"><a href="#散列表的动态操作" class="headerlink" title="散列表的动态操作"></a>散列表的动态操作</h4><h5 id="查询-2"><a href="#查询-2" class="headerlink" title="查询"></a>查询</h5><p>首先将对应的 CRC32 值加盐，称为 salted(CRC32)。</p><p>查询 salted(CRC32) % M 单元，返回第一个 CRC32 值为 salted(CRC32) 的密码结点。</p><p>如果没查询到返回 nullptr。</p><h5 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h5><p>首先将 CRC32 值加盐，称之为 salted(CRC32)。</p><p>对散列表查询 CRC32 % M 单元，如果返回 nullptr 直接插入到该单元。</p><p>如果发现了一个 salted(CRC32)，那么直接将其 pass 设置为 -1.</p><h4 id="历史记录维护"><a href="#历史记录维护" class="headerlink" title="历史记录维护"></a>历史记录维护</h4><p>历史记录使用一维长度为 8 的滚动数组维护，需要存储其累积至今的 CRC32 值和 pass 值。</p><p>根据 CRC32 的流性质在有新的成功记录时直接拼接即可。</p><h3 id="过程记录-3"><a href="#过程记录-3" class="headerlink" title="过程记录"></a>过程记录</h3><p><img src="https://i.loli.net/2021/10/29/S8ZgtnEvzKwhGFX.png" alt="image-20211029213744001"></p><center>《当你看代码逻辑三小时而不知出什么问题.jpeg》</center><ul><li>初版代码忘了在历史记录插入 HashTable 时加盐（样例都跑不过 本地解决）</li><li>第一次九成测内存空间没算对。密码结点最多数目为 $2M$（Init）+ $3M$​（历史记录插入）</li></ul><h3 id="复杂度分析-3"><a href="#复杂度分析-3" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p>首先我们分析 HashTable 的查询与插入过程。</p><p>查询 HashTable，由于 HashTable 的长度大于实际最终可能的密码结点总数，因此分摊而言查询复杂度为 $O(1)$。</p><p>插入 HashTable 包含了一个查询过程和插入过程。因此时间也是 $O(1)$。</p><p>初始处理 1 ~ 5 位的初始字符串集合需要处理 $18 + 18^2 + 18^3 + 18^4 + 18^5 = 2<em>10^6$ 的数据，因此需要 $O(T)$​ 的时间，这里 $T=2</em>10^6$。</p><p>而后续处理的过程中，对于每个 CRC32 值，我们均需查询，如果成功还需维护历史记录，但是这些操作均在 $O(1)$ 时间内能够完成，因此整体来看时间复杂度为 $O(n)$。</p><p>于是整体的时间复杂度为 $O(T+n)$，其中 $T=2*10^6$，为初始遍历序列的势。</p><p>空间复杂度而言，我们每个密码结点需要 24 Byte（考虑到对齐要求），$24<em>5M=120M$​。而 HashTable 只需要储存密码结点的地址，$8</em>6M=48M$。遍历初始序列的队列大小为 $0.1M$，可以忽略。这样我们就整体在 $O(n)$​ 的空间复杂度内，且常数符合题目要求的情况下，完成了题目。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;内含以下题目的实验报告：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CST2021F 2-1 Build&lt;/li&gt;
&lt;li&gt;CST2021F 2-2 Not Found&lt;/li&gt;
&lt;li&gt;CST2021F 2-4-2 Kidd&lt;/li&gt;
&lt;li&gt;CST2021F 2-6 Hacker&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里不提供任何解题代码，仅将解题的白盒报告归档处理。&lt;/p&gt;
&lt;p&gt;本博文仅做参考使用，任何可能影响您查重结果的行为请您后果自负！&lt;/p&gt;
&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Problem&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;White Box (20%)&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Black Box (80%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F 2-1 Build (25%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;100&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[100] -1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F 2-2 Not Found (25%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;95&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[100] -1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F 2-4-2 Kidd (25%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;95&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[100] -1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F 2-6 Hacker (25%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;100&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[100] -2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;</summary>
    
    
    
    <category term="程设" scheme="https://www.c7w.tech/categories/%E7%A8%8B%E8%AE%BE/"/>
    
    <category term="程设/数据结构" scheme="https://www.c7w.tech/categories/%E7%A8%8B%E8%AE%BE/%E7%A8%8B%E8%AE%BE-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="数据结构" scheme="https://www.c7w.tech/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>《数据结构》课程 PA1 报告</title>
    <link href="https://www.c7w.tech/dsa-pa1/"/>
    <id>https://www.c7w.tech/dsa-pa1/</id>
    <published>2022-01-09T16:00:00.000Z</published>
    <updated>2022-01-29T11:06:43.942Z</updated>
    
    <content type="html"><![CDATA[<p>内含以下题目的实验报告：</p><ul><li>CST2021F 1-1 A+B Problem</li><li>CST2021F 1-2 Graphics</li><li>CST2021F 1-3 Filename</li><li>CST2021F 1-4 Risk</li></ul><p>这里不提供任何解题代码，仅将解题的白盒报告归档处理。</p><p>本博文仅做参考使用，任何可能影响您查重结果的行为请您后果自负！</p><div class="table-container"><table><thead><tr><th style="text-align:center">Problem</th><th style="text-align:center">White Box (20%)</th><th style="text-align:center">Black Box (80%)</th></tr></thead><tbody><tr><td style="text-align:center">CST2021F 1-1 A+B problem (25%)</td><td style="text-align:center">100</td><td style="text-align:center">[100] -1</td></tr><tr><td style="text-align:center">CST2021F 1-2 Graphics (25%)</td><td style="text-align:center">100</td><td style="text-align:center">[100] -1</td></tr><tr><td style="text-align:center">CST2021F 1-3 filename (25%)</td><td style="text-align:center">100</td><td style="text-align:center">[100] -2</td></tr><tr><td style="text-align:center">CST2021F 1-4 Risk (25%)</td><td style="text-align:center">100</td><td style="text-align:center">[100] -1</td></tr></tbody></table></div><a id="more"></a><h2 id="CST2021F-1-1-A-B-Problem"><a href="#CST2021F-1-1-A-B-Problem" class="headerlink" title="CST2021F 1-1 A+B Problem"></a>CST2021F 1-1 A+B Problem</h2><p>​    <strong>[关键词] 模拟，压位</strong></p><h3 id="方案设计"><a href="#方案设计" class="headerlink" title="方案设计"></a>方案设计</h3><h4 id="思路来源"><a href="#思路来源" class="headerlink" title="思路来源"></a>思路来源</h4><p>​    先来考虑小学二年级学过的十进制乘法。</p><p>​    如 $73 * 27$，我们的运算实际上是进行了…</p><script type="math/tex; mode=display">\begin{align}73*27 = & (7*10+3*1)*(2*10+7*1)\\= & (7*2)*100 + (7*7+3*2)*10 + (3*7)*1 \\= & (1*10+4) * 100+(5*10+5)*10 + (2*10+1)*1 \\= & (1*10+4)*100+(5*10+7)*10+1*1\\= & (1*10+9)*100+7*10+1*1 \\= & 1*1000 + 9*100 + 7*10 + 1*1\\= & 1971\end {align}</script><p>​    而我们再考虑导致现有的高精度加法模板 TLE 的原因，$O(n|a||b|)$ 的算法对于 $n=500, |a|=|b|=5000$ 的最坏情况，与 $1s$ 内允许进行的运算次数，只差了一个常数级别.</p><p>​    因此我们的优化可以有两个思考方向，其一是进行<strong>常数级别的复杂度优化</strong>，另一是<strong>寻找更为高效的算法</strong>。这里斟酌考虑后选择了前者，而关于后者的相关实现留作报告中的【后续的优化方向】部分呈现。</p><p>​    而怎么去<strong>优化</strong>这个<strong>常数</strong>呢？我们可以考虑通过<strong>增加数据的存储与运算进制</strong>，来减少 $O(n|a||b|)$ 中 $|a|, |b|$ 的值，最终达到时间上的优化效果。举个例子，如果我们以 $10^4$ 为进制，那么复杂度在某种程度上就变成了 $O(n\frac{|a|}{4} \frac{|b|}{4})$。（虽然常系数可能有所增长）</p><p>​    同时还注意到，类似于位运算，加法，乘法等这种操作是较为节省时间的，而进行除法，取模的操作较为费时。因此我们尽可能<strong>避免每进行一次循环就进行进位处理</strong>的实现方式，因为处理进位可能需要大量的求余和求商运算。</p><h4 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h4><p>​    使用 <code>BigInteger</code> 类对大整数进行封装。其中的数据采用 <code>__uint128_t</code> 类型来进行存储，单个 <code>data</code> 可以储存上限为 $2^{128}-1$ 大小的值. 而最终数据存储和乘法运算采用的进制为 $10^{16}$.</p><p><strong>读取数据</strong></p><p>​    大整数的读取按照以下方式进行。</p><ol><li><p><strong>预读取阶段</strong>：将一个大整数的所有位读到一个栈结构中.</p></li><li><p><strong>处理阶段</strong></p><p>每次出栈最多 $16$ 位大整数，并从整数的逻辑最左端到逻辑最右端不断进行 $s_i \leftarrow (s_i&lt;&lt;3)+(s_i&lt;&lt;1); s_i \leftarrow s_i+val;$ 的操作。</p><p>然后将每 $16$ 位处理的结果 $s_i$ 按照逻辑倒序排列成一个数组。</p></li></ol><p><strong>数据相乘</strong></p><p>​    大整数的相乘主要是进行对十进制乘法的模拟。</p><ol><li><p><strong>结果计算</strong></p><p>我们记 $r$​ 为计算后的结果，我们可以得到：</p><script type="math/tex; mode=display">for \ i \ in \ [0,|a|) \ and \ j \ in \ [0, |b|):\\r_{i+j} \leftarrow r_{i+j}+a_i*b_j</script></li><li><p><strong>取模进位</strong></p><script type="math/tex; mode=display">for \ i \ in \ [0, |a+b|]:\\r_{i+1} \leftarrow r_{i+1} + r_i \ / \ e\\r_i \leftarrow r_i \ \%\  e</script><p>其中 $e$ 代表进制数，即 $10^{16}$.</p></li></ol><h4 id="正确性证明"><a href="#正确性证明" class="headerlink" title="正确性证明"></a>正确性证明</h4><p><strong>[证明]</strong> 在结果计算时，<code>__uint128_t</code> 不会发生溢出.</p><p>考虑 $r_i$​，设单个数据在计算过程中所记录的最大数据的上界为 $M$.</p><script type="math/tex; mode=display">M=e*e*(|i|+|j|)\le 10^{32}*10^4 = 10^{36} \lt 10^{38.53} \approx 2^{128}-1</script><p>于是数据不会发生溢出，先计算再取模来优化计算效率是安全的.</p><h3 id="过程记录"><a href="#过程记录" class="headerlink" title="过程记录"></a>过程记录</h3><p><strong>问题调试</strong></p><pre class="language-cpp" data-language="cpp"><code class="language-cpp"><span class="token comment">// First version: reading a big integer</span>data<span class="token punctuation">[</span>size<span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">[</span>size<span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> <span class="token number">1</span> <span class="token operator">+</span> data<span class="token punctuation">[</span>size<span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> <span class="token number">3</span><span class="token punctuation">;</span> <span class="token comment">// *= 10</span>data<span class="token punctuation">[</span>size<span class="token punctuation">]</span> <span class="token operator">+=</span> currVal<span class="token punctuation">;</span></code></pre><p>进行逐行调试与中间变量逐 Bit 输出后发现运算符优先级出了问题.</p><p><strong>对拍验证</strong></p><p>为了测试边界数据的运行情况，撰写了数据生成程序.</p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> randomf <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'data.in'</span><span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>g <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'answer.out'</span><span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">)</span><span class="token builtin">len</span> <span class="token operator">=</span> <span class="token number">500</span>f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    a <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">10</span><span class="token operator">**</span><span class="token number">2</span><span class="token operator">-</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token operator">**</span><span class="token number">5000</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    b <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">10</span><span class="token operator">**</span><span class="token number">2</span><span class="token operator">-</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token operator">**</span><span class="token number">5000</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' '</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>    g<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>a<span class="token operator">*</span>b<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>g<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>然后就可以通过在控制台进行…</p><pre class="language-bash" data-language="bash"><code class="language-bash">g++ main.cpp -o mainpython3 datagen.py<span class="token function">time</span> ./main <span class="token operator">&lt;</span> data.in <span class="token operator">></span> data.out<span class="token function">diff</span> data.out answer.out<span class="token comment"># 输出</span>./main <span class="token operator">&lt;</span> data.in <span class="token operator">></span> data.out  <span class="token number">0</span>.33s user <span class="token number">0</span>.04s system <span class="token number">53</span>% cpu <span class="token number">0.683</span> total</code></pre><p>来进行程序运行时间和正确性的检测.</p><h3 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p><strong>时间复杂度</strong></p><p>我们记字符串 $a, b$ 的长度分别为 $|a|,|b|$. </p><p>进行压位本质上是对于 $O(n|a||b|)$​ 的时间复杂度进行常数上的优化，时间复杂度还是由乘法运算的双重循环所决定的 $O(n|a||b|)$​​​.</p><p><strong>空间复杂度</strong></p><p>程序使用的空间主要用来存储 $a,b,result$ 三个 <code>BigInteger</code> 类的对象.</p><p>而 $a,b,r$ 三个变量可以被循环利用.</p><p>因此空间复杂度可以近似地看作为 $O(|a|+|b|+|a||b|)$​. (考虑到 $|a| \equiv 0$​ 的情况)</p><h2 id="CST2021F-1-2-Graphics"><a href="#CST2021F-1-2-Graphics" class="headerlink" title="CST2021F 1-2 Graphics"></a>CST2021F 1-2 Graphics</h2><p>​    <strong>[关键词] 平面解析几何，快速排序，二分查找</strong></p><h3 id="方案设计-1"><a href="#方案设计-1" class="headerlink" title="方案设计"></a>方案设计</h3><h4 id="思路分析"><a href="#思路分析" class="headerlink" title="思路分析"></a>思路分析</h4><p><strong>唯一的连接方式</strong></p><p>[证明] 对于 $x, y$ 轴上的点列 $X=\{ x_1, \cdots, x_n \}$ 与 $Y=\{y_1, \cdots, y_n\}$，满足如果 $i \lt j$，那么 $x_i&lt;x_j, y_i \lt y_j$，那么将它们按题述方式连接的方式唯一。</p><p>​    (1) 假设存在 $i \lt j$​，满足 $x_i$​ 与 $y_j$​​ 相连.</p><p>​        由 $|Y| \lt + \infin$​ 我们可以得出，$\exist u,v \in[1,n], \ u \lt v$​，$y_u$​ 与​ $x_v$​ 相连。</p><p>​        考虑 $\frac{x}{x_i} + \frac{y}{y_j} = 1$​ 与 $\frac{x}{x_v} + \frac{y}{y_u} = 1$ 两条直线，可知它们在第一象限有交点.</p><p>​    (2) 假设存在 $i \lt j$​，满足 $x_v$​ 与 $y_u$​ 相连. 同 (1) 我们也可知不成立.</p><p>​    于是我们得出结论，唯一的连接方式为 $x_i$ 与 $y_i$​ 相连，而验证可知这种情况下，两条直线在第一象限确实没有交点。</p><p><strong>判断点与直线的位置关系</strong></p><p>​    我们接下来考虑点 $(x_0, y_0)$​​ 与直线 $\frac{x}{a} + \frac{y}{b} = 1$​ 的位置关系. ($x_0, y_0, a,b \gt0$)</p><p>​    联立$\begin{cases} \frac{x}{a} + \frac{y}{b} = 1 \\ y=\frac{y_0}{x_0}x\end{cases}$​，我们可以解得交点的横坐标为 $x_{intersection}=\frac{abx_0}{ay_0+bx_0}$​.</p><p>​    (1) 如果点 $(x_0, y_0)$​​​ 在直线左侧，即 $x_0<x_{intersection}$​​​​​，由上述公式我们可知 $\Delta:=-x_0y_0+(x_0-a)(y_0-b) >0$​​​.</p><p>​    (2) 如果点 $(x_0, y_0)$ 在直线上，同理可知 $\Delta = 0$.</p><p>​    (3) 如果点 $(x_0, y_0)$ 在直线右侧，同理可知 $\Delta &lt; 0$.</p><p>​    综上，如果我们对直线按照 $x_i$ 升序的次序排序，可知对应的 $\Delta$ 值先负后正.</p><p>​    而我们可以通过二分查找第一个大于 $0$ 的值所在的位置，确定有有多少条直线在给定点的左方或在直线上。</p><h4 id="具体实现-1"><a href="#具体实现-1" class="headerlink" title="具体实现"></a>具体实现</h4><ul><li>给定没有单调性的点列后，如何找到线段的连接关系？<strong>快速排序</strong>！</li><li>找到连接关系后如何判断给定点与直线的相互位置？<strong>使用$\Delta$判据</strong>！</li><li>如何找到有多少条直线在给定点的左方或在直线上？<strong>二分查找</strong>！</li></ul><h3 id="过程记录-1"><a href="#过程记录-1" class="headerlink" title="过程记录"></a>过程记录</h3><p>​    本题是对《程序设计基础》课程中传统的排序和查找算法的有效复习。</p><h3 id="复杂度估算"><a href="#复杂度估算" class="headerlink" title="复杂度估算"></a>复杂度估算</h3><p><strong>时间复杂度</strong></p><p>快速排序的平均时间复杂度为 $O(nlgn)$，但是在最坏情况下可能会有 $O(n^2)$ 的特例。</p><p>单次二分查找的时间复杂度为 $O(lgn)$，而总共进行了 $m$ 次，即查找的时间复杂度近似为 $O(mlgn)$。</p><p>因此，程序的时间复杂度约为 $O(nlgn+mlgn)$。</p><p><strong>空间复杂度</strong></p><p>程序的存储主要是用来存储 $X,Y$ 两个点列，而快速排序是原地排序算法，这里不需考虑其占用的可能空间。因此空间复杂度为 $O(n)$。</p><h2 id="CST2021F-1-3-Filename"><a href="#CST2021F-1-3-Filename" class="headerlink" title="CST2021F 1-3 Filename"></a>CST2021F 1-3 Filename</h2><p>​    <strong>[关键词] 动态规划，滚动数组</strong></p><h3 id="方案设计-2"><a href="#方案设计-2" class="headerlink" title="方案设计"></a>方案设计</h3><h4 id="思路分析-1"><a href="#思路分析-1" class="headerlink" title="思路分析"></a>思路分析</h4><h5 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h5><p>​    把字符串 $A$ 变成字符串 $B$ 所需的修改次数，很容易就能想到【最长公共子序列】这道模板题。记 $|S|$ 为字符串 $S$ 的长度，那么 把字符串 $A$ 变成字符串 $B$ 所需的修改次数 $e$ 满足 $e = |A|-|LCS|+|B|-|LCS| = |A|+|B|-2|LCS|$​.</p><p>​    但是再一看，最长公共子序列的常用的 $O(n^2)$ 的算法和优化后的 $O(nlgn)$ 自然是不可能满足题目中 $n,m$ 的数据范围的。而如果我们仔细将这道题与模板题加以对比就能发现，我们多获得的条件就是所允许的最大修改代价 $k$. 而<strong>添加的条件，自然是作为我们优化算法效率的突破口</strong>。</p><p>​    我们还是沿用 $LCS$​ 问题中定义的状态，设 $f[i][j]$​ 代表<strong>目标字符串的前 $i$​ 个字符 $B[1, i]$​ 与待修改字符串的前 $j$​ 个字符 $A[1, j]$​ 所含有的公共子序列的长度</strong>。我们的<strong>状态转移方程</strong>为：</p><script type="math/tex; mode=display">f[i][j] =\begin{cases}max(f[i-1][j], f[i][j-1]), & A[j] \ne B[i],\\f[i-1][j-1], & A[j]=B[i].\end{cases}</script><p>​    但是我们需要考虑 $k$​ 的作用。我们断言，如果存在 $i,j$ 使得 $f[i][j]$ 对应的修改次数大于 $k$，那么由 $f[i][j]$ 递推来的答案一定不符合题目最大修改次数的要求。这是因为如果两个字串序列的修改代价就已经大于 $k$，两个整串之间的修改代价一定是随着 $i, j$ 而单调递增，也必不可能不大于 $k$.</p><p>​    于是我们在递推的时候就可以尝试更改我们的策略。我们可以直接将递推边界设置为 $max((i-k)-1, 1)$ 与 $min(n, (i+k)+1)$。这是因为在递推边界外的 $f$ 值，至少对我们关心的答案没有影响。为了不影响递推公式的通用性，我们可以将递推边界上的值置为 $0$.</p><h5 id="滚动数组"><a href="#滚动数组" class="headerlink" title="滚动数组"></a>滚动数组</h5><p>​    但是我们接下来又会遇到一个问题，就是经过计算，$mn$​ 大小的状态记录数组显然会超过内存限制。这时我们可以使用动态规划时常见的操作，也就是<strong>滚动数组</strong>。由于我们的状态记录数组在每次状态转移时只涉及到两行间的关系，于是我们完全可以将数组开成 $2*n$ 的大小。然后在每次需要读取或写入 $f[i][j]$ 的值时，我们即寻找 $f[i\&amp;1][j]$，其中 $i\&amp;1$ 代表 $i\%2$.</p><h4 id="样例分析"><a href="#样例分析" class="headerlink" title="样例分析"></a>样例分析</h4><p><img src="https://i.loli.net/2021/09/20/msOAJyKkHUuFz5o.png" alt="image-20210920112305557"></p><p style="text-align: center">(图为模拟运行 LCS 后的结果)</p><h3 id="过程记录-2"><a href="#过程记录-2" class="headerlink" title="过程记录"></a>过程记录</h3><h4 id="对拍验证"><a href="#对拍验证" class="headerlink" title="对拍验证"></a>对拍验证</h4><p>​    因为最后忘了特判 $|A|+|B|-2|LCS| &gt;k$ 将结果置为 $-1$​ 导致九成测爆了 Wrong Answer. 于是写了对拍程序验证。对拍程序使用最平凡的递归算法。<s>但是竟然能想起来特判，写题的时候却不起来。</s></p><pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> random<span class="token keyword">import</span> os<span class="token keyword">import</span> subprocess<span class="token keyword">def</span> <span class="token function">solve</span><span class="token punctuation">(</span>ori<span class="token punctuation">,</span> des<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>ori <span class="token operator">==</span> <span class="token string">''</span> <span class="token keyword">or</span> des <span class="token operator">==</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">0</span>    n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>ori<span class="token punctuation">)</span>    m <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>des<span class="token punctuation">)</span>    <span class="token keyword">if</span> ori<span class="token punctuation">[</span>n<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> des<span class="token punctuation">[</span>m<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> solve<span class="token punctuation">(</span>ori<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>n<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> des<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>m<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">max</span><span class="token punctuation">(</span>solve<span class="token punctuation">(</span>ori<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>n<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> des<span class="token punctuation">)</span><span class="token punctuation">,</span> solve<span class="token punctuation">(</span>ori<span class="token punctuation">,</span> des<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>m<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 1000 Test cases</span>    charList <span class="token operator">=</span><span class="token string">"ab"</span>        n <span class="token operator">=</span> <span class="token number">20</span>    m <span class="token operator">=</span> <span class="token number">20</span>    k <span class="token operator">=</span> <span class="token number">18</span>    ori <span class="token operator">=</span> <span class="token punctuation">[</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>charList<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">]</span>    ori <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>ori<span class="token punctuation">)</span>    des <span class="token operator">=</span> <span class="token punctuation">[</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>charList<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">]</span>    des <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>des<span class="token punctuation">)</span>    g <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'testdata.in'</span><span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">)</span>    g<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' '</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' '</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>    g<span class="token punctuation">.</span>write<span class="token punctuation">(</span>ori <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>    g<span class="token punctuation">.</span>write<span class="token punctuation">(</span>des<span class="token punctuation">)</span>    g<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>        a <span class="token operator">=</span> subprocess<span class="token punctuation">.</span>check_output<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"./main &lt; testdata.in"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shell<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    answer <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span> <span class="token comment">#cpp</span>        l <span class="token operator">=</span> solve<span class="token punctuation">(</span>ori<span class="token punctuation">,</span> des<span class="token punctuation">)</span>    l <span class="token operator">=</span> n<span class="token operator">+</span>m<span class="token operator">-</span><span class="token number">2</span><span class="token operator">*</span>l    <span class="token keyword">if</span> l <span class="token operator">></span> k<span class="token punctuation">:</span>        l <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"[Answer </span><span class="token interpolation"><span class="token punctuation">&#123;</span>answer<span class="token punctuation">&#125;</span></span><span class="token string"> L </span><span class="token interpolation"><span class="token punctuation">&#123;</span>l<span class="token punctuation">&#125;</span></span><span class="token string">]"</span></span><span class="token punctuation">)</span>    <span class="token keyword">assert</span><span class="token punctuation">(</span>answer <span class="token operator">==</span> l<span class="token punctuation">)</span></code></pre><p>​    跑了一次就能拿到 <code>AssertionError</code>，然后发现了程序中的错误<s>并后悔自己浪费了一次九成测</s>。以下是程序修改后对拍程序的运行效果截图。</p><p><img src="https://i.loli.net/2021/09/20/kzcqpPVEb6aGdvt.png" alt="image-20210920115702668"></p><h3 id="复杂度分析-1"><a href="#复杂度分析-1" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p><strong>时间复杂度</strong></p><p>由 $k$ 的限制和字符串长度的关系，我们得出时间复杂度为 $O(mk)$.</p><p><strong>空间复杂度</strong></p><p>新开辟的空间主要用来存储两个字符串，以及字符串对应的状态。因此空间复杂度为 $O(n+m)$.</p><h2 id="CST2021F-1-4-Risk"><a href="#CST2021F-1-4-Risk" class="headerlink" title="CST2021F 1-4 Risk"></a>CST2021F 1-4 Risk</h2><p>​    <strong>[关键词] 单调队列，归并排序，二分查找</strong></p><h3 id="方案设计-3"><a href="#方案设计-3" class="headerlink" title="方案设计"></a>方案设计</h3><h4 id="思路分析-2"><a href="#思路分析-2" class="headerlink" title="思路分析"></a>思路分析</h4><p>​    分析题目后，我们的需求是需要多次查询 $Cases$ 数组中位于 $[L_i, R_i]$ 的最大值，其中保证 $L_i$ 单调递增，$R_i=i-1$​​​。而我们可以根据<strong>单调队列</strong>这种数据结构来实现这种需求，将在下面介绍。在计算好每一天对应的风险评估值，也就是对应区间 $Cases$ 的最大值之后，我们对风险评估值数组进行排序，然后使用二分查找就能找到对于任意的 $e = p,q$，数组中小于 $e$ 的元素个数.</p><p><strong>单调队列</strong></p><p style="text-align:center; color:red">声明：本节内容根据题目提示，在复习参考<a href="https://oi-wiki.org/ds/monotonous-queue/">单调队列</a>相关知识后写成。<br/>提交的 main.cpp 中代码均为原创，不存在任何复制粘贴抄袭的行为</p><p>​    我们应实现具有以下功能的<strong>单调递减队列</strong>.</p><p>​    比如，对于测试 $Cases$ 输入 <code>&#123;0, 1000, 1000, 800, 900&#125;</code>.</p><div class="table-container"><table><thead><tr><th>Index</th><th>区间</th><th>对应 Queap 的值</th></tr></thead><tbody><tr><td>0: Enqueue</td><td>[0]</td><td>{0}</td></tr><tr><td>1: Enqueue</td><td>[0 1000]</td><td>{1000}</td></tr><tr><td>2: Enqueue</td><td>[0 1000 1000]</td><td>{1000, 1000}</td></tr><tr><td>3: Enqueue</td><td>[0 1000 1000 800]</td><td>{1000, 1000, 800}</td></tr><tr><td>4: Enqueue</td><td>[0 1000 1000 800 900]</td><td>{1000, 1000, 900}</td></tr><tr><td>5: Dequeue</td><td>[1000 1000 800 900]</td><td>{1000, 1000, 900}</td></tr><tr><td>6: Dequeue</td><td>[1000 800 900]</td><td>{1000, 900}</td></tr><tr><td>7: Dequeue</td><td>[800 900]</td><td>{900}</td></tr></tbody></table></div><p>​    记 $q$ 为<strong>单调递减队列</strong>，即对于所有 $[Leftbound, rightbound)$ 中的位置 $i,j$，命题 $(i&lt;j) \rightarrow (q[i] \ge q[j])$ 成立.</p><ol><li><strong>Enqueue</strong></li></ol><p>​    在将 $e$ 插入队列时…</p><ul><li>使用 $[Leftbound, rightbound)$​ 内二分查找找到位置 $i$​​​<ul><li>使得 $i = \inf\{i \ |\  q[i]&lt;e\} \ (Leftbound \le i \le Rightbound)$​​​​</li></ul></li><li>$q[i] \leftarrow e$​, $Rightbound \leftarrow i+1$</li></ul><ol><li><strong>Dequeue</strong></li></ol><p>​    在考虑将 $e$ 移出队列时…</p><ul><li>如果 $e$​ 是区间最大值，那么必有 $e=q[Leftbound]$​ ，只需 $Leftbound \leftarrow Leftbound+1$​;</li><li>如果 $e$​ 不是区间最大值，那么在后续的序列中，一定存在大于 $e$​ 的元素，$e$​ 一定在之前被覆盖.</li></ul><ol><li><p><strong>Get</strong></p><p>考虑获取当前区间的最大值，只需要返回队列中最大的元素，也就是 $q[Leftbound]$​.</p></li></ol><h4 id="具体实现-2"><a href="#具体实现-2" class="headerlink" title="具体实现"></a>具体实现</h4><p>​    单调队列使用一个线性结构实现，并保证长度上限为 $n$.</p><p>​    归并排序与二分查找手打模板即可.</p><h3 id="过程记录-3"><a href="#过程记录-3" class="headerlink" title="过程记录"></a>过程记录</h3><h4 id="对拍测试"><a href="#对拍测试" class="headerlink" title="对拍测试"></a>对拍测试</h4><p>使用规模最大的测例进行测试。</p><pre class="language-python" data-language="python"><code class="language-python">f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'data.in'</span><span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>ans <span class="token operator">=</span> <span class="token string">''</span>leng <span class="token operator">=</span> <span class="token number">1000000</span>f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>leng<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>leng<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' '</span><span class="token punctuation">)</span>f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> leng<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' '</span><span class="token punctuation">)</span>f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>T <span class="token operator">=</span> <span class="token number">100000</span>f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>T<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>T<span class="token punctuation">)</span><span class="token punctuation">:</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'0 10000000000000\n'</span><span class="token punctuation">)</span>    ans <span class="token operator">+=</span> <span class="token string">'0 1000000\n'</span>g <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'answer.out'</span><span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">)</span>g<span class="token punctuation">.</span>write<span class="token punctuation">(</span>ans<span class="token punctuation">)</span>g<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre class="language-bash" data-language="bash"><code class="language-bash">c7w@cc7w /mnt/e/Project/Homework/DSA/PA1/4-Risk <span class="token builtin class-name">:</span> python3 check.pyc7w@cc7w /mnt/e/Project/Homework/DSA/PA1/4-Risk <span class="token builtin class-name">:</span> <span class="token function">time</span> ./main <span class="token operator">&lt;</span> data.in <span class="token operator">></span> cpp.outc7w@cc7w /mnt/e/Project/Homework/DSA/PA1/4-Risk <span class="token builtin class-name">:</span> <span class="token function">diff</span> cpp.out answer.out./main <span class="token operator">&lt;</span> data.in <span class="token operator">></span> cpp.out  <span class="token number">0</span>.36s user <span class="token number">0</span>.11s system <span class="token number">43</span>% cpu <span class="token number">1.091</span> total</code></pre><h3 id="复杂度分析-2"><a href="#复杂度分析-2" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p><strong>时间复杂度</strong></p><p>设单调队列的长度为 $s$，则 Enqueue 过程的时间复杂度为 $O(lgs)$，Dequeue 过程的时间复杂度为 $O(1)$.</p><p>在最坏的情况下，将 $Cases$ 数组中的所有元素都入队，复杂度约为 $O(nlgn)$.</p><p>将风险评估值数组 $Measure$ 中的所有元素排序，复杂度 $O(nlgn)$.</p><p>之后执行 $2T$ 次二分查找，复杂度为 $O(Tlgn)$.</p><p>综上，时间复杂度为 $O(nlgn+Tlgn)$.</p><p><strong>空间复杂度</strong></p><p>程序所用的空间主要是单调队列的 $O(n)$，$Cases, \ Measure$ 以及归并排序的缓冲数组 $Buffer$ 数组的 $O(n)$，因此总体的空间复杂度为 $O(n)$.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;内含以下题目的实验报告：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CST2021F 1-1 A+B Problem&lt;/li&gt;
&lt;li&gt;CST2021F 1-2 Graphics&lt;/li&gt;
&lt;li&gt;CST2021F 1-3 Filename&lt;/li&gt;
&lt;li&gt;CST2021F 1-4 Risk&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里不提供任何解题代码，仅将解题的白盒报告归档处理。&lt;/p&gt;
&lt;p&gt;本博文仅做参考使用，任何可能影响您查重结果的行为请您后果自负！&lt;/p&gt;
&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Problem&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;White Box (20%)&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Black Box (80%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F 1-1 A+B problem (25%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;100&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[100] -1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F 1-2 Graphics (25%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;100&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[100] -1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F 1-3 filename (25%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;100&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[100] -2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;CST2021F 1-4 Risk (25%)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;100&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;[100] -1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;</summary>
    
    
    
    <category term="程设" scheme="https://www.c7w.tech/categories/%E7%A8%8B%E8%AE%BE/"/>
    
    <category term="程设/数据结构" scheme="https://www.c7w.tech/categories/%E7%A8%8B%E8%AE%BE/%E7%A8%8B%E8%AE%BE-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="数据结构" scheme="https://www.c7w.tech/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
</feed>
